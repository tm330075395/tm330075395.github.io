"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[6056],{51086:(n,e,_)=>{_.r(e),_.d(e,{assets:()=>a,contentTitle:()=>o,default:()=>c,frontMatter:()=>r,metadata:()=>s,toc:()=>d});var i=_(74848),t=_(28453);const r={sidebar_position:5},o="5. \u5feb\u901f\u5165\u95e8k230 AI\u63a8\u7406\u6d41\u7a0b",s={id:"CanaanK230/part4/Getstartedquicklyk230AIInferenceflow",title:"5. \u5feb\u901f\u5165\u95e8k230 AI\u63a8\u7406\u6d41\u7a0b",description:"\u672c\u7ae0\u6559\u5b66\u89c6\u9891\uff1a\u52d8\u667aK230\u5f00\u53d1\u677f\u4f7f\u7528\u6559\u7a0b-\u5feb\u901f\u5165\u95e8AI\u63a8\u7406\u6d41\u7a0b\u54d4\u54e9\u54d4\u54e9bilibili",source:"@site/docs/CanaanK230/part4/05-Getstartedquicklyk230AIInferenceflow.md",sourceDirName:"CanaanK230/part4",slug:"/CanaanK230/part4/Getstartedquicklyk230AIInferenceflow",permalink:"/docs/CanaanK230/part4/Getstartedquicklyk230AIInferenceflow",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/CanaanK230/part4/05-Getstartedquicklyk230AIInferenceflow.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{sidebar_position:5},sidebar:"canaanK230Sidebar",previous:{title:"4. K230 Fancy POC \u6982\u8ff0",permalink:"/docs/CanaanK230/part4/K230FancyPOCOverview"},next:{title:"6.\u6df1\u5165\u89e3\u6790AI\u5f00\u53d1\u6d41\u7a0b",permalink:"/docs/CanaanK230/part4/In-depthanalysisoftheAIdevelopmentprocess"}},a={},d=[{value:"5.1 \u57fa\u4e8eOpenCV(C++)\u7684AI\u63a8\u7406\u6d41\u7a0b",id:"51-\u57fa\u4e8eopencvc\u7684ai\u63a8\u7406\u6d41\u7a0b",level:2},{value:"5.1.1 \u89c6\u9891\u91c7\u96c6",id:"511-\u89c6\u9891\u91c7\u96c6",level:3},{value:"5.1.2 \u9884\u5904\u7406",id:"512-\u9884\u5904\u7406",level:3},{value:"5.1.3 \u6a21\u578b\u63a8\u7406",id:"513-\u6a21\u578b\u63a8\u7406",level:3},{value:"5.1.4 \u540e\u5904\u7406",id:"514-\u540e\u5904\u7406",level:3},{value:"5.1.5 \u663e\u793a",id:"515-\u663e\u793a",level:3},{value:"5.1.6 \u5b8c\u6574\u4ee3\u7801",id:"516-\u5b8c\u6574\u4ee3\u7801",level:3},{value:"5.2 \u57fa\u4e8eulab(MicroPython)\u7684AI\u63a8\u7406\u6d41\u7a0b",id:"52-\u57fa\u4e8eulabmicropython\u7684ai\u63a8\u7406\u6d41\u7a0b",level:2},{value:"5.2.1 \u89c6\u9891\u91c7\u96c6",id:"521-\u89c6\u9891\u91c7\u96c6",level:3},{value:"5.2.2 \u9884\u5904\u7406",id:"522-\u9884\u5904\u7406",level:3},{value:"5.2.3 \u6a21\u578b\u63a8\u7406",id:"523-\u6a21\u578b\u63a8\u7406",level:3},{value:"5.2.4 \u540e\u5904\u7406",id:"524-\u540e\u5904\u7406",level:3},{value:"5.2.5 \u663e\u793a",id:"525-\u663e\u793a",level:3},{value:"5.2.6 \u8d44\u6e90\u91ca\u653e",id:"526-\u8d44\u6e90\u91ca\u653e",level:3},{value:"5.2.7 \u5b8c\u6574\u4ee3\u7801",id:"527-\u5b8c\u6574\u4ee3\u7801",level:3}];function p(n){const e={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"5-\u5feb\u901f\u5165\u95e8k230-ai\u63a8\u7406\u6d41\u7a0b",children:"5. \u5feb\u901f\u5165\u95e8k230 AI\u63a8\u7406\u6d41\u7a0b"})}),"\n",(0,i.jsxs)(e.blockquote,{children:["\n",(0,i.jsxs)(e.p,{children:["\u672c\u7ae0\u6559\u5b66\u89c6\u9891\uff1a",(0,i.jsx)(e.a,{href:"https://www.bilibili.com/video/BV1tD421777Y/?spm_id_from=333.999.0.0",children:"\u52d8\u667aK230\u5f00\u53d1\u677f\u4f7f\u7528\u6559\u7a0b-\u5feb\u901f\u5165\u95e8AI\u63a8\u7406\u6d41\u7a0b_\u54d4\u54e9\u54d4\u54e9_bilibili"})]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"\u672c\u7ae0\u4ecb\u7ecd\u4e86K230 AI\u63a8\u7406\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u8ba9\u5927\u5bb6\u5bf9\u57fa\u4e8eK230\u7684AI\u63a8\u7406\u8fc7\u7a0b\u6709\u4e2a\u5927\u6982\u5370\u8c61\uff0c\u5b83\u5305\u62ec\u89c6\u9891\u91c7\u96c6\uff0c\u56fe\u50cf\u9884\u5904\u7406\uff0c\u6a21\u578b\u63a8\u7406\u3001\u540e\u5904\u7406\u3001\u663e\u793a\u7b49\u8fc7\u7a0b\u3002"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"\u89c6\u9891\u8f93\u5165\uff1aVI\uff08Video Input\uff09\uff0c\u89c6\u9891\u91c7\u96c6"}),"\n",(0,i.jsx)(e.li,{children:"\u89c6\u9891\u8f93\u51fa\uff1aVO\uff08Video Output\uff09\uff0c\u663e\u793a"}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"\u672c\u7ae0\u5305\u542b\u4e86K230 AI\u63a8\u7406\u6d41\u7a0b\u7684\u4e24\u79cd\u5b9e\u73b0\uff1a\u57fa\u4e8eOpenCV(c++)\u7684AI\u63a8\u7406\u3001\u57fa\u4e8eulab(MicroPython)\u7684AI\u63a8\u7406\uff0c\u5206\u522b\u5bf9\u5e94\u4e24\u4e2a\u5b50\u7ae0\u8282\uff0c\u5177\u4f53\u5b9e\u73b0\u8be6\u5b50\u7ae0\u8282\u4ecb\u7ecd\u3002"}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u8be6\u7ec6\u4ee3\u7801\u5b9e\u73b0"}),"\uff1a",(0,i.jsx)(e.a,{href:"https://github.com/JayL323/k230_AI_Demo_Code_Flow_Introduction",children:"k230_AI_Demo_Code_Flow_Introduction"})]}),"\n",(0,i.jsx)(e.h2,{id:"51-\u57fa\u4e8eopencvc\u7684ai\u63a8\u7406\u6d41\u7a0b",children:"5.1 \u57fa\u4e8eOpenCV(C++)\u7684AI\u63a8\u7406\u6d41\u7a0b"}),"\n",(0,i.jsx)(e.p,{children:"\u57fa\u4e8eOpenCV(C++)\u7684K230 AI\u63a8\u7406\uff0c\u7b80\u8981\u4ecb\u7ecd\u4e86\u4f7f\u7528c++\u8bed\u8a00\u5b9e\u73b0\u7684\u89c6\u9891\u91c7\u96c6\uff0c\u56fe\u50cf\u9884\u5904\u7406\uff08OpenCV\uff09\uff0c\u6a21\u578b\u63a8\u7406\u3001\u540e\u5904\u7406\u3001\u663e\u793a\u7b49\u8fc7\u7a0b\u3002"}),"\n",(0,i.jsx)(e.h3,{id:"511-\u89c6\u9891\u91c7\u96c6",children:"5.1.1 \u89c6\u9891\u91c7\u96c6"}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u89c6\u9891\u91c7\u96c6"}),"\uff1a\uff08\u89c6\u9891\u8f93\u5165\uff0cVI\uff09\u4e0e\u6444\u50cf\u5934\u76f8\u5173\uff0c\u672c\u5c0f\u8282\u7b80\u8981\u4ecb\u7ecd\u57fa\u4e8ec++\u7684\u6444\u50cf\u5934\u8bbe\u7f6e\u3001\u6444\u50cf\u5934\u542f\u52a8\u3001\u4ece\u6444\u50cf\u5934\u4e2d\u83b7\u53d6\u4e00\u5e27\u6570\u636e\u3001\u6444\u50cf\u5934\u505c\u6b62\u7684\u6574\u4f53\u6d41\u7a0b\uff1b\u8be6\u7ec6\u4ecb\u7ecd\u89c1",(0,i.jsx)(e.a,{href:"https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/mpp/K230_VICAP_API%E5%8F%82%E8%80%83.md",children:"K230_VICAP_API\u53c2\u8003.md"}),"\u3001",(0,i.jsx)(e.a,{href:"https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/mpp/K230_VICAP_SENSOR_%E5%8F%82%E6%95%B0%E5%88%86%E5%8C%BA%E5%8F%82%E8%80%83.md",children:"K230_VICAP_SENSOR_\u53c2\u6570\u5206\u533a\u53c2\u8003.md"}),"\u3001",(0,i.jsx)(e.a,{href:"https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/mpp/K230_Camera_Sensor%E9%80%82%E9%85%8D%E6%8C%87%E5%8D%97.md",children:"K230_Camera_Sensor\u9002\u914d\u6307\u5357.md"}),"\u3002"]}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"1. \u8bbe\u7f6e\u6444\u50cf\u5934\u5c5e\u6027"}),"\uff1a"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"\u8bbe\u7f6e\u7684sensor\u4e24\u8def\u8f93\u51fa\uff1b"}),"\n",(0,i.jsx)(e.li,{children:"\u4e00\u8def\u8f93\u51fa\u7528\u4e8e\u663e\u793a\uff0c\u8f93\u51fa\u5927\u5c0f\u8bbe\u7f6e1080p\uff0c\u56fe\u50cf\u683c\u5f0f\u4e3aPIXEL_FORMAT_YVU_PLANAR_420\uff0c\u76f4\u63a5\u7ed1\u5b9a\u5230vo\uff1b"}),"\n",(0,i.jsx)(e.li,{children:"\u53e6\u4e00\u8def\u8f93\u51fa\u7528\u4e8eAI\u8ba1\u7b97\uff0c\u8f93\u51fa\u5927\u5c0f720p\uff0c\u56fe\u50cf\u683c\u5f0f\u4e3aPIXEL_FORMAT_BGR_888_PLANAR\uff08\u5b9e\u9645\u4e3argb,chw,uint8\uff09\uff1b"}),"\n"]}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u521b\u5efa\u6444\u50cf\u5934\uff08sensor\uff09\u8f93\u51fa\u7f13\u5b58\uff08VB\uff09"}),"\uff1a\u7528\u4e8e\u5b58\u653e\u6444\u50cf\u5934\u4e24\u8def\u8f93\u51fa"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'//vi_vo.h\n/***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539***********************/\n#define SENSOR_CHANNEL (3)     // \u901a\u9053\u6570\n#define SENSOR_HEIGHT (720)    // sensor ch1\u8f93\u51fa\u9ad8\u5ea6\uff0cAI\u8f93\u5165\n#define SENSOR_WIDTH (1280)    // sensor ch1\u8f93\u51fa\u5bbd\u5ea6\uff0cAI\u8f93\u5165\n#define ISP_CHN0_WIDTH  (1920) // sensor ch0\u8f93\u51fa\u5bbd\u5ea6\uff0cvo\n#define ISP_CHN0_HEIGHT (1080) // sensor ch0\u8f93\u51fa\u9ad8\u5ea6\uff0cvo\n/*****************************************************************************/\n\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\nmemset(&config, 0, sizeof(config));\nconfig.max_pool_cnt = 64;\n//VB for YUV420SP output\nconfig.comm_pool[0].blk_cnt = 5;\nconfig.comm_pool[0].mode = VB_REMAP_MODE_NOCACHE;\nconfig.comm_pool[0].blk_size = VICAP_ALIGN_UP((ISP_CHN0_WIDTH * ISP_CHN0_HEIGHT * 3 / 2), VICAP_ALIGN_1K);\n\n//VB for RGB888 output\nconfig.comm_pool[1].blk_cnt = 5;\nconfig.comm_pool[1].mode = VB_REMAP_MODE_NOCACHE;\nconfig.comm_pool[1].blk_size = VICAP_ALIGN_UP((SENSOR_HEIGHT * SENSOR_WIDTH * 3 ), VICAP_ALIGN_1K);\n\nret = kd_mpi_vb_set_config(&config);\nif (ret) {\n    printf("vb_set_config failed ret:%d\\n", ret);\n    return ret;\n}\n/*****************************************************************************/\n'})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u8bbe\u7f6e\u6444\u50cf\u5934\u5c5e\u6027"}),"\uff1a\u8bbe\u7f6esensor_type\uff1b\u4e00\u822c\u65e0\u9700\u6362\u6444\u50cf\u5934\uff0c\u65e0\u9700\u4fee\u6539\u3002"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'//vi_vo.h\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\nvicap_dev = VICAP_DEV_ID_0;\nret = kd_mpi_vicap_get_sensor_info(sensor_type, &sensor_info);\nif (ret) {\n    printf("sample_vicap, the sensor type not supported!\\n");\n    return ret;\n}\n\n......\n\ndev_attr.cpature_frame = 0;\nmemcpy(&dev_attr.sensor_info, &sensor_info, sizeof(k_vicap_sensor_info));\n\nret = kd_mpi_vicap_set_dev_attr(vicap_dev, dev_attr);\nif (ret) {\n    printf("sample_vicap, kd_mpi_vicap_set_dev_attr failed.\\n");\n    return ret;\n}\n/*****************************************************************************/\n'})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u8bbe\u7f6e\u6444\u50cf\u5934\u901a\u90530\u5c5e\u6027"}),"\uff1a\u8bbe\u7f6e\u6444\u50cf\u5934\u901a\u90530\u5206\u8fa8\u7387\u4e3a1080p\uff0c\u683c\u5f0f\u4e3aPIXEL_FORMAT_YVU_PLANAR_420\uff1b\u5e76\u5c06\u6444\u50cf\u5934\u901a\u90530\u7ed1\u5b9a\u5230\u663e\u793a\uff1b\u4e00\u822c\u53ea\u9700\u8981\u5173\u6ce8",(0,i.jsx)(e.code,{children:"chn_attr.out_win.width"}),"\u3001",(0,i.jsx)(e.code,{children:"chn_attr.out_win.height"}),"\u3001",(0,i.jsx)(e.code,{children:"chn_attr.pix_format"}),"\u5373\u53ef\uff0c\u5176\u5b83\u4e0d\u7528\u4fee\u6539\u3002"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'//vi_vo.h\n/***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539***********************/\n#define ISP_CHN0_WIDTH  (1920) // sensor ch0\u8f93\u51fa\u5bbd\u5ea6\uff0cvo\n#define ISP_CHN0_HEIGHT (1080) // sensor ch0\u8f93\u51fa\u9ad8\u5ea6\uff0cvo\n/*****************************************************************************/\n\n/***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539******************/\n//set chn0 output yuv420sp\n......\nchn_attr.out_win.width = ISP_CHN0_WIDTH;\nchn_attr.out_win.height = ISP_CHN0_HEIGHT;\n......\nchn_attr.chn_enable = K_TRUE;\nchn_attr.pix_format = PIXEL_FORMAT_YVU_PLANAR_420;\n/*****************************************************************************/ \n......\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\nchn_attr.buffer_num = VICAP_MAX_FRAME_COUNT;        //at least 3 buffers for isp\nchn_attr.buffer_size = config.comm_pool[0].blk_size;\nvicap_chn = VICAP_CHN_ID_0;\n\nprintf("sample_vicap ...kd_mpi_vicap_set_chn_attr, buffer_size[%d]\\n", chn_attr.buffer_size);\nret = kd_mpi_vicap_set_chn_attr(vicap_dev, vicap_chn, chn_attr);\nif (ret) {\n    printf("sample_vicap, kd_mpi_vicap_set_chn_attr failed.\\n");\n    return ret;\n}\n\n//bind vicap chn 0 to vo\nvicap_mpp_chn.mod_id = K_ID_VI;\nvicap_mpp_chn.dev_id = vicap_dev;\nvicap_mpp_chn.chn_id = vicap_chn;\n\nvo_mpp_chn.mod_id = K_ID_VO;\nvo_mpp_chn.dev_id = K_VO_DISPLAY_DEV_ID;\nvo_mpp_chn.chn_id = K_VO_DISPLAY_CHN_ID1;\n\nsample_vicap_bind_vo(vicap_mpp_chn, vo_mpp_chn);\nprintf("sample_vicap ...dwc_dsi_init\\n");\n/*****************************************************************************/\n'})}),"\n",(0,i.jsx)(e.p,{children:"**\u8bbe\u7f6e\u6444\u50cf\u5934\u901a\u90531\u5c5e\u6027\uff1a**\u8bbe\u7f6e\u901a\u90531\u5206\u8fa8\u7387\u4e3a720p\uff0c\u683c\u5f0f\u4e3aPIXEL_FORMAT_BGR_888_PLANAR\u3002"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'//vi_vo.h\n/***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539***********************/\n#define SENSOR_CHANNEL (3)     // \u901a\u9053\u6570\n#define SENSOR_HEIGHT (720)    // sensor ch1\u8f93\u51fa\u9ad8\u5ea6\uff0cAI\u8f93\u5165\n#define SENSOR_WIDTH (1280)    // sensor ch1\u8f93\u51fa\u5bbd\u5ea6\uff0cAI\u8f93\u5165\n/*****************************************************************************/\n......\n/***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539******************/\n//set chn1 output rgb888p\n....\nchn_attr.out_win.width = SENSOR_WIDTH ;\nchn_attr.out_win.height = SENSOR_HEIGHT;\n\n......\nchn_attr.chn_enable = K_TRUE;\nchn_attr.pix_format = PIXEL_FORMAT_BGR_888_PLANAR;\n/*****************************************************************************/ \n\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\nchn_attr.buffer_num = VICAP_MAX_FRAME_COUNT;//at least 3 buffers for isp\nchn_attr.buffer_size = config.comm_pool[1].blk_size;\n\nprintf("sample_vicap ...kd_mpi_vicap_set_chn_attr, buffer_size[%d]\\n", chn_attr.buffer_size);\nret = kd_mpi_vicap_set_chn_attr(vicap_dev, VICAP_CHN_ID_1, chn_attr);\nif (ret) {\n    printf("sample_vicap, kd_mpi_vicap_set_chn_attr failed.\\n");\n    return ret;\n}\n/*****************************************************************************/\n'})}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"\u8bbe\u7f6e\u521d\u59cb\u5316\u3001\u5e76\u542f\u52a8\u6444\u50cf\u5934\uff1a"})}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'//vi_vo.h\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\nret = kd_mpi_vicap_init(vicap_dev);\nif (ret) {\n    printf("sample_vicap, kd_mpi_vicap_init failed.\\n");\n    // goto err_exit;\n}\n\nprintf("sample_vicap ...kd_mpi_vicap_start_stream\\n");\nret = kd_mpi_vicap_start_stream(vicap_dev);\nif (ret) {\n    printf("sample_vicap, kd_mpi_vicap_init failed.\\n");\n    // goto err_exit;\n}\n/*****************************************************************************/\n'})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u4f7f\u7528\u793a\u4f8b"}),"\uff1a"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"//main.cc\nvivcap_start();\n"})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"2. \u83b7\u53d6\u6444\u50cf\u5934\u56fe\u50cf"}),"\uff1a"]}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u6444\u50cf\u5934\u6570\u636e\u4e34\u65f6\u5730\u5740"}),"\uff1a\u521b\u5efavaddr\uff0c\u4e34\u65f6\u5b58\u653e\u6444\u50cf\u5934\u6700\u65b0\u6570\u636e\uff0c\u5b83\u4e0e\u6444\u50cf\u5934\u901a\u90531\u5927\u5c0f\u76f8\u540c\u3002"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'// main.cc\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n// alloc memory for sensor\nsize_t paddr = 0;\nvoid *vaddr = nullptr;\nsize_t size = SENSOR_CHANNEL * SENSOR_HEIGHT * SENSOR_WIDTH;\nint ret = kd_mpi_sys_mmz_alloc_cached(&paddr, &vaddr, "allocate", "anonymous", size);\nif (ret)\n{\n    std::cerr << "physical_memory_block::allocate failed: ret = " << ret << ", errno = " << strerror(errno) << std::endl;\n    std::abort();\n}\n/*****************************************************************************/\n'})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u8bfb\u53d6\u6700\u65b0\u5e27"}),"\uff1a"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"dump"}),"\uff1a\u4ece\u6444\u50cf\u5934\u901a\u90531\u8bfb\u53d6\u4e00\u5e27\u56fe\u50cf,\u5373\u4eceVB\u4e2ddump\u4e00\u5e27\u6570\u636e\u5230dump_info"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"\u6620\u5c04"}),"\uff1a\u5c06dump_info\u5bf9\u5e94DDR\u5730\u5740\uff08\u7269\u7406\u5730\u5740\uff09\u6620\u5c04\u5230\u5f53\u524d\u7cfb\u7edf\u5730\u5740\uff08\u865a\u62df\u5730\u5740\uff09\u8fdb\u884c\u8bbf\u95ee"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"\u8f6ccv::Mat"}),"\uff1a\u5c06\u6444\u50cf\u5934\u6570\u636e\u8f6c\u6362\u4e3acv::Mat\uff0csensor\uff08rgb,chw\uff09->cv::Mat\uff08bgr\uff0chwc\uff09\uff1b\u5c06\u6444\u50cf\u5934\u6570\u636e\u8f6c\u6362\u4e3a\u4e3acv::Mat\u4e0d\u662f\u5fc5\u987b\u7684\uff0c\u8fd9\u91cc\u53ea\u662f\u4e3a\u4e86\u4ee5\u5927\u5bb6\u6bd4\u8f83\u719f\u6089\u7684\u65b9\u5f0f\uff08cv::Mat\uff09\u8fdb\u884c\u8bb2\u89e3\u3002"]}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'//vi_vo.h\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n//VB for RGB888 output\nconfig.comm_pool[1].blk_cnt = 5;\nconfig.comm_pool[1].mode = VB_REMAP_MODE_NOCACHE;\nconfig.comm_pool[1].blk_size = VICAP_ALIGN_UP((SENSOR_HEIGHT * SENSOR_WIDTH * 3 ), VICAP_ALIGN_1K);\n/*****************************************************************************/\n\n//main.cc\nwhile (!isp_stop)\n{\n    cv::Mat ori_img;\n    //sensor to cv::Mat\n    {\n        /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n        //\u4ece\u6444\u50cf\u5934\u901a\u90531\u8bfb\u53d6\u4e00\u5e27\u56fe\u50cf,\u5373\u4eceVB\u4e2ddump\u4e00\u5e27\u6570\u636e\u5230dump_info\n        memset(&dump_info, 0 , sizeof(k_video_frame_info));\n        ret = kd_mpi_vicap_dump_frame(vicap_dev, VICAP_CHN_ID_1, VICAP_DUMP_YUV, &dump_info, 1000);\n        if (ret) {\n            printf("sample_vicap...kd_mpi_vicap_dump_frame failed.\\n");\n            continue;\n        }\n\n        //\u5c06dump_info\u5bf9\u5e94DDR\u5730\u5740\uff08\u7269\u7406\u5730\u5740\uff09\u6620\u5c04\u5230\u5f53\u524d\u7cfb\u7edf\uff08\u865a\u62df\u5730\u5740\uff09\u8fdb\u884c\u8bbf\u95ee\n        //vbvaddr\u662f\u5b9e\u65f6\u6539\u53d8\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u6700\u597d\u628a\u6700\u65b0\u6570\u636e\u62f7\u8d1d\u5230\u3010\u56fa\u5b9a\u5730\u5740\u3011vaddr\uff0c\u4ee5\u4fbf\u5176\u5b83\u90e8\u5206\u8fdb\u884c\u8bbf\u95ee\n        auto vbvaddr = kd_mpi_sys_mmap_cached(dump_info.v_frame.phys_addr[0], size);\n        memcpy(vaddr, (void *)vbvaddr, SENSOR_HEIGHT * SENSOR_WIDTH * 3); \n        kd_mpi_sys_munmap(vbvaddr, size);\n        /*****************************************************************************/\n        \n        //\u5c06\u6444\u50cf\u5934\u6570\u636e\u8f6c\u6362\u4e3a\u4e3acv::Mat,sensor\uff08rgb,chw\uff09->cv::Mat\uff08bgr\uff0chwc\uff09\n        cv::Mat image_r = cv::Mat(SENSOR_HEIGHT,SENSOR_WIDTH, CV_8UC1, vaddr);\n        cv::Mat image_g = cv::Mat(SENSOR_HEIGHT,SENSOR_WIDTH, CV_8UC1, vaddr+SENSOR_HEIGHT*SENSOR_WIDTH);\n        cv::Mat image_b = cv::Mat(SENSOR_HEIGHT,SENSOR_WIDTH, CV_8UC1, vaddr+2*SENSOR_HEIGHT*SENSOR_WIDTH);\n        std::vector<cv::Mat> color_vec(3);\n        color_vec.clear();\n        color_vec.push_back(image_b);\n        color_vec.push_back(image_g);\n        color_vec.push_back(image_r);\n        cv::merge(color_vec, ori_img);\n    }\n    //\u4f7f\u7528\u5f53\u524d\u5e27\u6570\u636e\n    ......\n    ......\n    {\n        /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n        // \u91ca\u653esensor\u5f53\u524d\u5e27\n        ret = kd_mpi_vicap_dump_release(vicap_dev, VICAP_CHN_ID_1, &dump_info);\n        if (ret) {\n            printf("sample_vicap...kd_mpi_vicap_dump_release failed.\\n");\n        }\n        /*****************************************************************************/\n    }\n}\n'})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"3. \u505c\u6b62\u6444\u50cf\u5934"}),"\uff1a"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'//vi_vo.h\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\nint vivcap_stop()\n{\n    // \u6444\u50cf\u5934\u505c\u6b62\n    printf("sample_vicap ...kd_mpi_vicap_stop_stream\\n");\n    int ret = kd_mpi_vicap_stop_stream(vicap_dev);\n    if (ret) {\n        printf("sample_vicap, kd_mpi_vicap_init failed.\\n");\n        return ret;\n    }\n\n    // \u6444\u50cf\u5934\u8d44\u6e90\u91ca\u653e\n    ret = kd_mpi_vicap_deinit(vicap_dev);\n    if (ret) {\n        printf("sample_vicap, kd_mpi_vicap_deinit failed.\\n");\n        return ret;\n    }\n\n    kd_mpi_vo_disable_video_layer(K_VO_LAYER1);\n\n    vicap_mpp_chn.mod_id = K_ID_VI;\n    vicap_mpp_chn.dev_id = vicap_dev;\n    vicap_mpp_chn.chn_id = vicap_chn;\n\n    vo_mpp_chn.mod_id = K_ID_VO;\n    vo_mpp_chn.dev_id = K_VO_DISPLAY_DEV_ID;\n    vo_mpp_chn.chn_id = K_VO_DISPLAY_CHN_ID1;\n\n    // vi vo\u89e3\u7ed1\n    sample_vicap_unbind_vo(vicap_mpp_chn, vo_mpp_chn);\n\n    /*Allow one frame time for the VO to release the VB block*/\n    k_u32 display_ms = 1000 / 33;\n    usleep(1000 * display_ms);\n\n    // \u9000\u51favb\n    ret = kd_mpi_vb_exit();\n    if (ret) {\n        printf("sample_vicap, kd_mpi_vb_exit failed.\\n");\n        return ret;\n    }\n\n    return 0;\n}\n/*****************************************************************************/\n'})}),"\n",(0,i.jsx)(e.p,{children:"\u53ea\u9700\u5728main.cc\u4e2d\u8c03\u7528\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"//main.cc\nvivcap_start();\n......\nvivcap_stop();\n"})}),"\n",(0,i.jsx)(e.h3,{id:"512-\u9884\u5904\u7406",children:"5.1.2 \u9884\u5904\u7406"}),"\n",(0,i.jsx)(e.p,{children:"\u5bf9\u5f53\u524d\u5e27\u6570\u636e\u8fdb\u884cresize\u5904\u7406\u3002"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'//main.cc\nwhile (!isp_stop)\n{\n    cv::Mat ori_img;        //ori\uff1auint8,chw,rgb\n    //sensor to cv::Mat\n    {\n        ......\n    }\n    /***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539******************/\n    // pre_process\uff0ccv::Mat((1280,720),bgr,hwc)->kmodel((224,224),rgb,hwc)\n    cv::Mat pre_process_img;\n    {\n        cv::Mat rgb_img;\n        cv::cvtColor(ori_img, rgb_img, cv::COLOR_BGR2RGB);\n        cv::resize(rgb_img, pre_process_img, cv::Size(kmodel_input_width, kmodel_input_height), cv::INTER_LINEAR);\n    }\n    /*****************************************************************************/\n\n    //\u5df2\u5728ai_base.cc\u4e2d\u7ed9\u51fa\u901a\u7528\u5b9e\u73b0\uff0c\u5e76\u4e14\u5c06\u5728\u7b2c6\u7ae0\u7ed9\u51fa\u5f00\u6e90\u4ee3\u7801\n    /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n    // set kmodel input\n    {\n        runtime_tensor tensor0 = kmodel_interp.input_tensor(0).expect("cannot get input tensor");\n        auto in_buf = tensor0.impl()->to_host().unwrap()->buffer().as_host().unwrap().map(map_access_::map_write).unwrap().buffer();\n        memcpy(reinterpret_cast<unsigned char *>(in_buf.data()), pre_process_img.data,sizeof(uint8_t)* kmodel_input_height * kmodel_input_width * 3);\n        hrt::sync(tensor0, sync_op_t::sync_write_back, true).expect("sync write_back failed");\n    }\n    /*****************************************************************************/ \n    ......\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"513-\u6a21\u578b\u63a8\u7406",children:"5.1.3 \u6a21\u578b\u63a8\u7406"}),"\n",(0,i.jsx)(e.p,{children:"\u8bbe\u7f6e\u597d\u6a21\u578b\u8f93\u5165\u540e\uff0c\u8fdb\u884c\u6a21\u578b\u63a8\u7406\uff0c\u5f97\u5230\u6a21\u578b\u63a8\u7406\u7ed3\u679c\u3002"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'//main.cc\nstring kmodel_path = argv[1];\ncout<<kmodel_path<<endl;\nfloat cls_thresh=0.5;\n\n//\u5df2\u5728ai_base.cc\u4e2d\u7ed9\u51fa\u901a\u7528\u5b9e\u73b0\uff0c\u5e76\u4e14\u5c06\u5728\u7b2c6\u7ae0\u7ed9\u51fa\u5f00\u6e90\u4ee3\u7801\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n// kmodel\u89e3\u91ca\u5668\uff0c\u4ecekmodel\u6587\u4ef6\u6784\u5efa\uff0c\u8d1f\u8d23\u6a21\u578b\u7684\u52a0\u8f7d\u3001\u8f93\u5165\u8f93\u51fa\u8bbe\u7f6e\u548c\u63a8\u7406\ninterpreter kmodel_interp;        \n// load model\nstd::ifstream ifs(kmodel_path, std::ios::binary);\nkmodel_interp.load_model(ifs).expect("Invalid kmodel");\n\n// inputs init\nfor (size_t i = 0; i < kmodel_interp.inputs_size(); i++)\n{\n    auto desc = kmodel_interp.input_desc(i);\n    auto shape = kmodel_interp.input_shape(i);\n    auto tensor = host_runtime_tensor::create(desc.datatype, shape, hrt::pool_shared).expect("cannot create input tensor");\n    kmodel_interp.input_tensor(i, tensor).expect("cannot set input tensor");\n} \nauto shape0 = kmodel_interp.input_shape(0);      //nhwc\nint kmodel_input_height = shape0[1];\nint kmodel_input_width = shape0[2];\n\n// outputs init\nfor (size_t i = 0; i < kmodel_interp.outputs_size(); i++)\n{\n    auto desc = kmodel_interp.output_desc(i);\n    auto shape = kmodel_interp.output_shape(i);\n    auto tensor = host_runtime_tensor::create(desc.datatype, shape, hrt::pool_shared).expect("cannot create output tensor");\n    kmodel_interp.output_tensor(i, tensor).expect("cannot set output tensor");\n}\n/*****************************************************************************/ \n    \nwhile (!isp_stop)\n{\n    cv::Mat ori_img;\n    //sensor to cv::Mat\n    {\n        ......\n    }\n\n    // pre_process\n    cv::Mat pre_process_img;\n    {\n        ......\n    }\n\n    // set kmodel input\n    {\n        ......\n    }\n\n    //\u5df2\u5728ai_base.cc\u4e2d\u7ed9\u51fa\u901a\u7528\u5b9e\u73b0\uff0c\u5e76\u4e14\u5c06\u5728\u7b2c6\u7ae0\u7ed9\u51fa\u5f00\u6e90\u4ee3\u7801\n    /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n    // kmodel run\n    kmodel_interp.run().expect("error occurred in running model");\n\n    // get kmodel output\n    vector<float *> k_outputs;\n    {\n        for (int i = 0; i < kmodel_interp.outputs_size(); i++)\n        {\n            auto out = kmodel_interp.output_tensor(i).expect("cannot get output tensor");\n            auto buf = out.impl()->to_host().unwrap()->buffer().as_host().unwrap().map(map_access_::map_read).unwrap().buffer();\n            float *p_out = reinterpret_cast<float *>(buf.data());\n            k_outputs.push_back(p_out);\n        }\n    }\n    /*****************************************************************************/\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"514-\u540e\u5904\u7406",children:"5.1.4 \u540e\u5904\u7406"}),"\n",(0,i.jsx)(e.p,{children:"\u5bf9\u6a21\u578b\u7ed3\u679c\u8fdb\u884c\u540e\u5904\u7406\uff0c\u5e76\u7ed3\u679c\u653e\u5230results\u4e2d\u3002"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"//main.cc\nvector<cls_res> results;\nwhile (!isp_stop)\n{\n    cv::Mat ori_img;\n    //sensor to cv::Mat\n    {\n        ......\n    }\n\n    // pre_process\n    cv::Mat pre_process_img;\n    {\n        ......\n    }\n\n    // set kmodel input\n    {\n        ......\n    }\n\n    // kmodel run\n    ......\n\n    // get kmodel output\n    vector<float *> k_outputs;\n    {\n        ......\n    }\n\n    //post process\n    results.clear();\n    {\n        /***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539******************/\n        float* output0 = k_outputs[0];\n        //softmax\n        float sum = 0.0;\n        for (int i = 0; i < labels.size(); i++){\n            sum += exp(output0[i]);\n        }\n\n        int max_index;\n        for (int i = 0; i < labels.size(); i++)\n        {\n            output0[i] = exp(output0[i]) / sum;\n        }\n        max_index = std::max_element(output0,output0+labels.size()) - output0; \n        cls_res b;\n        if (output0[max_index] >= cls_thresh)\n        {\n            b.label = labels[max_index];\n            b.score = output0[max_index];\n            results.push_back(b);\n        }\n        /*****************************************************************************/   \n    }\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"515-\u663e\u793a",children:"5.1.5 \u663e\u793a"}),"\n",(0,i.jsxs)(e.p,{children:["\u663e\u793a\uff08\u89c6\u9891\u8f93\u51fa\uff0cVO\uff09\u4e0edisplay\u76f8\u5173\uff0c\u672c\u5c0f\u8282\u7b80\u8981\u4ecb\u7ecd\u57fa\u4e8ec++\u7684\u663e\u793a\u8bbe\u7f6e\u3001\u663e\u793a\u53e0\u52a0\u7684\u6574\u4f53\u6d41\u7a0b\uff1b\u8be6\u7ec6\u4ecb\u7ecd\u53c2\u89c1",(0,i.jsx)(e.a,{href:"https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/mpp/K230_%E8%A7%86%E9%A2%91%E8%BE%93%E5%87%BA_API%E5%8F%82%E8%80%83.md",children:"K230_\u89c6\u9891\u8f93\u51fa_API\u53c2\u8003.md"})]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"\u663e\u793a\u8bbe\u7f6e\uff1a\u8bbe\u7f6e\u663e\u793a\u5927\u5c0f\uff0c\u683c\u5f0f"}),"\n",(0,i.jsx)(e.li,{children:"\u663e\u793a\u53e0\u52a0\uff1a\u663e\u793a\u75312\u4e2a\u56fe\u5c42\u6784\u6210\uff0c\u5176\u4e2d\u4e0b\u8fb9\u7684\u56fe\u5c42\uff08\u539f\u56fe\u56fe\u5c42\uff09\u76f4\u63a5\u663e\u793a\u6444\u50cf\u5934\u8f93\u51fa\uff0c\u4e0a\u8fb9\u7684\u56fe\u5c42\uff08osd\u56fe\u5c42\uff09\u7528\u4e8e\u753b\u6846\u3001\u753b\u70b9\uff0c\u5199\u6587\u5b57\u7b49\u3002"}),"\n"]}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"1. \u663e\u793a\u8bbe\u7f6e"}),"\uff1a\u8bbe\u7f6e\u663e\u793a\u5927\u5c0f\uff0c\u683c\u5f0f\u3002"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"//vi_vo.h\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\nstatic k_s32 sample_connector_init(void)\n{\n    ......\n    k_connector_type connector_type = LT9611_MIPI_4LAN_1920X1080_30FPS;\n    ......\n}\n\nstatic k_s32 vo_layer_vdss_bind_vo_config(void)\n{\n    ......\n    sample_connector_init();\n\n    // config lyaer\n    info.act_size.width = ISP_CHN0_WIDTH;//ISP_CHN0_HEIGHT;//1080;//640;//1080;\n    info.act_size.height = ISP_CHN0_HEIGHT;//ISP_CHN0_WIDTH;//1920;//480;//1920;\n    info.format = PIXEL_FORMAT_YVU_PLANAR_420;\n    ......\n}\n/*****************************************************************************/ \n"})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"2. \u663e\u793a\u53e0\u52a0"}),"\uff1a\u7531\u4e8e\u6444\u50cf\u5934\u548c\u663e\u793a\u7684\u901a\u9053\u8fdb\u884c\u4e86\u7ed1\u5b9a\uff0c\u6211\u4eec\u65e0\u6cd5\u5bf9vo\u8fdb\u884c\u76f4\u63a5\u64cd\u4f5c\uff0c\u56e0\u6b64\u91c7\u7528\u53e0\u52a0\u7684\u65b9\u5f0f\u8fdb\u884c\u663e\u793a\u3002"]}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u539f\u56fe\u56fe\u5c42"}),"\uff1a\u7531\u4e8e\u6444\u50cf\u5934\uff08vi\uff09\u901a\u90530\u7ed1\u5b9a\u4e86\u663e\u793a\uff08vo\uff09\u7684\u901a\u90531\uff1b\u968f\u7740\u6444\u50cf\u5934\u7684\u542f\u52a8\uff0c\u6444\u50cf\u5934\u901a\u90530\u7684\u6570\u636e\u4f1a\u81ea\u52a8\u6d41\u5230vo\u7684\u901a\u90531\u3002"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'//vi_vo.h\n......\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n//bind vicap chn 0 to vo\nvicap_mpp_chn.mod_id = K_ID_VI;\nvicap_mpp_chn.dev_id = vicap_dev;\nvicap_mpp_chn.chn_id = vicap_chn;\n\nvo_mpp_chn.mod_id = K_ID_VO;\nvo_mpp_chn.dev_id = K_VO_DISPLAY_DEV_ID;\nvo_mpp_chn.chn_id = K_VO_DISPLAY_CHN_ID1;\n\nsample_vicap_bind_vo(vicap_mpp_chn, vo_mpp_chn);\nprintf("sample_vicap ...dwc_dsi_init\\n");\n/*****************************************************************************/ \n......\n'})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"osd\u56fe\u5c42"}),"\uff1acv::Mat\u4e0a\u753b\u6846\u3001\u753b\u70b9\u3001\u5199\u6587\u5b57\u4e4b\u540e\uff0c\u5c06\u6570\u636e\u63d2\u5165vo\u5bf9\u5e94\u901a\u9053\u3002"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'// vi_vo.h\n#define osd_id                              K_VO_OSD3\n/***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539******************/\n#define ISP_CHN0_WIDTH                      (1920) // sensor ch0\u8f93\u51fa\u5bbd\u5ea6\uff0cvo\n#define ISP_CHN0_HEIGHT                     (1080) // sensor ch0\u8f93\u51fa\u9ad8\u5ea6\uff0cvo\n#define osd_width                           (1920)\n#define osd_height                          (1080)\n/*****************************************************************************/\n.....\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\nk_vb_blk_handle vo_insert_frame(k_video_frame_info *vf_info, void **pic_vaddr)\n{\n    k_u64 phys_addr = 0;\n    k_u32 *virt_addr;\n    k_vb_blk_handle handle;\n    k_s32 size;\n\n    if (vf_info == NULL)\n        return K_FALSE;\n\n    if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_ABGR_8888 || vf_info->v_frame.pixel_format == PIXEL_FORMAT_ARGB_8888)\n        size = vf_info->v_frame.height * vf_info->v_frame.width * 4;\n    else if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_RGB_565 || vf_info->v_frame.pixel_format == PIXEL_FORMAT_BGR_565)\n        size = vf_info->v_frame.height * vf_info->v_frame.width * 2;\n    else if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_ABGR_4444 || vf_info->v_frame.pixel_format == PIXEL_FORMAT_ARGB_4444)\n        size = vf_info->v_frame.height * vf_info->v_frame.width * 2;\n    else if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_RGB_888 || vf_info->v_frame.pixel_format == PIXEL_FORMAT_BGR_888)\n        size = vf_info->v_frame.height * vf_info->v_frame.width * 3;\n    else if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_ARGB_1555 || vf_info->v_frame.pixel_format == PIXEL_FORMAT_ABGR_1555)\n        size = vf_info->v_frame.height * vf_info->v_frame.width * 2;\n    else if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_YVU_PLANAR_420)\n        size = vf_info->v_frame.height * vf_info->v_frame.width * 3 / 2;\n\n    size = size + 4096;         // \u5f3a\u52364K \uff0c\u540e\u8fb9\u5f97\u5220\u4e86\n\n    printf("vb block size is %x \\n", size);\n\n    handle = kd_mpi_vb_get_block(g_pool_id, size, NULL);\n    if (handle == VB_INVALID_HANDLE)\n    {\n        printf("%s get vb block error\\n", __func__);\n        return K_FAILED;\n    }\n\n    phys_addr = kd_mpi_vb_handle_to_phyaddr(handle);\n    if (phys_addr == 0)\n    {\n        printf("%s get phys addr error\\n", __func__);\n        return K_FAILED;\n    }\n\n    virt_addr = (k_u32 *)kd_mpi_sys_mmap(phys_addr, size);\n    // virt_addr = (k_u32 *)kd_mpi_sys_mmap_cached(phys_addr, size);\n\n    if (virt_addr == NULL)\n    {\n        printf("%s mmap error\\n", __func__);\n        return K_FAILED;\n    }\n\n    vf_info->mod_id = K_ID_VO;\n    vf_info->pool_id = g_pool_id;\n    vf_info->v_frame.phys_addr[0] = phys_addr;\n    if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_YVU_PLANAR_420)\n        vf_info->v_frame.phys_addr[1] = phys_addr + (vf_info->v_frame.height * vf_info->v_frame.stride[0]);\n    *pic_vaddr = virt_addr;\n\n    printf("phys_addr is %lx g_pool_id is %d \\n", phys_addr, g_pool_id);\n\n    return handle;\n}\n/*****************************************************************************/\n'})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u4f7f\u7528\u793a\u4f8b"}),"\uff1a"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'// main.cc\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n// osd create\nk_video_frame_info vf_info;\nvoid *pic_vaddr = NULL;       \nmemset(&vf_info, 0, sizeof(vf_info));\nvf_info.v_frame.width = osd_width;\nvf_info.v_frame.height = osd_height;\nvf_info.v_frame.stride[0] = osd_width;\nvf_info.v_frame.pixel_format = PIXEL_FORMAT_ARGB_8888;\nblock = vo_insert_frame(&vf_info, &pic_vaddr);\n/*****************************************************************************/ \n\nwhile (!isp_stop)\n{\n    cv::Mat ori_img;\n    // sensor to cv::Mat\n    // pre_process\n    // set kmodel input\n    // kmodel run\n    // get kmodel output\n    // post process\n    results.clear();\n    {\n        ......\n    }\n\n    // draw result to vo\n    {\n        // draw osd\n        {\n            cv::Mat osd_frame(osd_height, osd_width, CV_8UC4, cv::Scalar(0, 0, 0, 0));\n            /***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539******************/\n            {\n                //draw cls\n                double fontsize = (osd_frame.cols * osd_frame.rows * 1.0) / (1100 * 1200);\n                for(int i = 0; i < results.size(); i++)\n                {   \n                    std::string text = "class: " + results[i].label + ", score: " + std::to_string(round(results[i].score * 100) / 100.0).substr(0, 4);\n\n                    cv::putText(osd_frame, text, cv::Point(1, 40), cv::FONT_HERSHEY_SIMPLEX, 0.8, cv::Scalar(255, 255, 255, 0), 2);\n\n                    std::cout << text << std::endl;\n                }\n            }\n            \n            /*************************************************************************/\n            \n            /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n            memcpy(pic_vaddr, osd_frame.data, osd_width * osd_height * 4);\n        }\n\n        // insert osd to vo\n        {\n            kd_mpi_vo_chn_insert_frame(osd_id+3, &vf_info);\n            printf("kd_mpi_vo_chn_insert_frame success \\n");\n        }\n        /*****************************************************************************/ \n    }\n    ......\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"516-\u5b8c\u6574\u4ee3\u7801",children:"5.1.6 \u5b8c\u6574\u4ee3\u7801"}),"\n",(0,i.jsx)(e.p,{children:"\u5177\u4f53\u600e\u4e48\u64cd\u4f5c\u8fd0\u884c\uff0c\u8bf7\u53c2\u8003\u7b2c6\u7ae0\uff0c\u8fd9\u91cc\u7740\u91cd\u4ecb\u7ecd\u4ee3\u7801\u6d41\u7a0b\u3002"}),"\n",(0,i.jsx)(e.p,{children:"vi_vo.h"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'/* Copyright (c) 2023, Canaan Bright Sight Co., Ltd\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n * 1. Redistributions of source code must retain the above copyright\n * notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n * notice, this list of conditions and the following disclaimer in the\n * documentation and/or other materials provided with the distribution.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND\n * CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,\n * INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR\n * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n * BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include <chrono>\n#include <fstream>\n#include <iostream>\n#include <thread>\n#include <atomic>\n\n#include "mpi_sys_api.h"\n\n/* vicap */\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <string.h>\n#include <sys/mman.h>\n\n#include "k_module.h"\n#include "k_type.h"\n#include "k_vb_comm.h"\n#include "k_video_comm.h"\n#include "k_sys_comm.h"\n#include "mpi_vb_api.h"\n#include "mpi_vicap_api.h"\n#include "mpi_isp_api.h"\n#include "mpi_sys_api.h"\n#include "k_vo_comm.h"\n#include "mpi_vo_api.h"\n\n#include "vo_test_case.h"\n\n#include "k_connector_comm.h"\n#include "mpi_connector_api.h"\n#include "k_autoconf_comm.h"\n\n/***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539*******************/\n#if defined(CONFIG_BOARD_K230_CANMV)\n#define SENSOR_CHANNEL (3)                // \u901a\u9053\u6570\n#define SENSOR_HEIGHT (720)               // sensor ch1\u8f93\u51fa\u9ad8\u5ea6\uff0cAI\u8f93\u5165\n#define SENSOR_WIDTH (1280)               // sensor ch1\u8f93\u51fa\u5bbd\u5ea6\uff0cAI\u8f93\u5165\n#define ISP_CHN0_WIDTH  (1920)            // sensor ch0\u8f93\u51fa\u5bbd\u5ea6\uff0cvo\n#define ISP_CHN0_HEIGHT (1080)            // sensor ch0\u8f93\u51fa\u9ad8\u5ea6\uff0cvo\n#define vicap_install_osd                   (1)\n#define osd_id                              K_VO_OSD3\n#define osd_width                           (1920)\n#define osd_height                          (1080)\n#else\n#define SENSOR_CHANNEL (3)                \n#define SENSOR_HEIGHT (1280)  \n#define SENSOR_WIDTH (720)   \n#define ISP_CHN0_WIDTH  (1088)\n#define ISP_CHN0_HEIGHT (1920)\n#define vicap_install_osd                   (1)\n#define osd_id                              K_VO_OSD3\n#define osd_width                           (1080)\n#define osd_height                          (1920)\n#endif\n/*****************************************************************************/    \n\n/***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\nk_vb_config config;\nk_vicap_dev vicap_dev;\nk_vicap_chn vicap_chn;\nk_vicap_dev_attr dev_attr;\nk_vicap_chn_attr chn_attr;\nk_vicap_sensor_info sensor_info;\nk_vicap_sensor_type sensor_type;\nk_mpp_chn vicap_mpp_chn;\nk_mpp_chn vo_mpp_chn;\n\nk_video_frame_info dump_info;\n\nk_vo_draw_frame vo_frame = (k_vo_draw_frame) {\n    1,\n    16,\n    16,\n    128,\n    128,\n    1\n};\n\nstatic k_vb_blk_handle block;\nk_u32 g_pool_id;\n\nint vo_creat_layer_test(k_vo_layer chn_id, layer_info *info)\n{\n    k_vo_video_layer_attr attr;\n\n    // check layer\n    if ((chn_id >= K_MAX_VO_LAYER_NUM) || ((info->func & K_VO_SCALER_ENABLE) && (chn_id != K_VO_LAYER0))\n            || ((info->func != 0) && (chn_id == K_VO_LAYER2)))\n    {\n        printf("input layer num failed \\n");\n        return -1 ;\n    }\n\n    // check scaler\n\n    // set offset\n    attr.display_rect = info->offset;\n    // set act\n    attr.img_size = info->act_size;\n    // sget size\n    info->size = info->act_size.height * info->act_size.width * 3 / 2;\n    //set pixel format\n    attr.pixel_format = info->format;\n    if (info->format != PIXEL_FORMAT_YVU_PLANAR_420)\n    {\n        printf("input pix format failed \\n");\n        return -1;\n    }\n    // set stride\n    attr.stride = (info->act_size.width / 8 - 1) + ((info->act_size.height - 1) << 16);\n    // set function\n    attr.func = info->func;\n    // set scaler attr\n    attr.scaler_attr = info->attr;\n\n    // set video layer atrr\n    kd_mpi_vo_set_video_layer_attr(chn_id, &attr);\n\n    // enable layer\n    kd_mpi_vo_enable_video_layer(chn_id);\n\n    return 0;\n}\n\nk_vb_blk_handle vo_insert_frame(k_video_frame_info *vf_info, void **pic_vaddr)\n{\n    k_u64 phys_addr = 0;\n    k_u32 *virt_addr;\n    k_vb_blk_handle handle;\n    k_s32 size;\n\n    if (vf_info == NULL)\n        return K_FALSE;\n\n    if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_ABGR_8888 || vf_info->v_frame.pixel_format == PIXEL_FORMAT_ARGB_8888)\n        size = vf_info->v_frame.height * vf_info->v_frame.width * 4;\n    else if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_RGB_565 || vf_info->v_frame.pixel_format == PIXEL_FORMAT_BGR_565)\n        size = vf_info->v_frame.height * vf_info->v_frame.width * 2;\n    else if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_ABGR_4444 || vf_info->v_frame.pixel_format == PIXEL_FORMAT_ARGB_4444)\n        size = vf_info->v_frame.height * vf_info->v_frame.width * 2;\n    else if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_RGB_888 || vf_info->v_frame.pixel_format == PIXEL_FORMAT_BGR_888)\n        size = vf_info->v_frame.height * vf_info->v_frame.width * 3;\n    else if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_ARGB_1555 || vf_info->v_frame.pixel_format == PIXEL_FORMAT_ABGR_1555)\n        size = vf_info->v_frame.height * vf_info->v_frame.width * 2;\n    else if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_YVU_PLANAR_420)\n        size = vf_info->v_frame.height * vf_info->v_frame.width * 3 / 2;\n\n    size = size + 4096;         // \u5f3a\u52364K \uff0c\u540e\u8fb9\u5f97\u5220\u4e86\n\n    printf("vb block size is %x \\n", size);\n\n    handle = kd_mpi_vb_get_block(g_pool_id, size, NULL);\n    if (handle == VB_INVALID_HANDLE)\n    {\n        printf("%s get vb block error\\n", __func__);\n        return K_FAILED;\n    }\n\n    phys_addr = kd_mpi_vb_handle_to_phyaddr(handle);\n    if (phys_addr == 0)\n    {\n        printf("%s get phys addr error\\n", __func__);\n        return K_FAILED;\n    }\n\n    virt_addr = (k_u32 *)kd_mpi_sys_mmap(phys_addr, size);\n    // virt_addr = (k_u32 *)kd_mpi_sys_mmap_cached(phys_addr, size);\n\n    if (virt_addr == NULL)\n    {\n        printf("%s mmap error\\n", __func__);\n        return K_FAILED;\n    }\n\n    vf_info->mod_id = K_ID_VO;\n    vf_info->pool_id = g_pool_id;\n    vf_info->v_frame.phys_addr[0] = phys_addr;\n    if (vf_info->v_frame.pixel_format == PIXEL_FORMAT_YVU_PLANAR_420)\n        vf_info->v_frame.phys_addr[1] = phys_addr + (vf_info->v_frame.height * vf_info->v_frame.stride[0]);\n    *pic_vaddr = virt_addr;\n\n    printf("phys_addr is %lx g_pool_id is %d \\n", phys_addr, g_pool_id);\n\n    return handle;\n}\n\nk_u32 vo_creat_osd_test(k_vo_osd osd, osd_info *info)\n{\n    k_vo_video_osd_attr attr;\n\n    // set attr\n    attr.global_alptha = info->global_alptha;\n\n    if (info->format == PIXEL_FORMAT_ABGR_8888 || info->format == PIXEL_FORMAT_ARGB_8888)\n    {\n        info->size = info->act_size.width  * info->act_size.height * 4;\n        info->stride  = info->act_size.width * 4 / 8;\n    }\n    else if (info->format == PIXEL_FORMAT_RGB_565 || info->format == PIXEL_FORMAT_BGR_565)\n    {\n        info->size = info->act_size.width  * info->act_size.height * 2;\n        info->stride  = info->act_size.width * 2 / 8;\n    }\n    else if (info->format == PIXEL_FORMAT_RGB_888 || info->format == PIXEL_FORMAT_BGR_888)\n    {\n        info->size = info->act_size.width  * info->act_size.height * 3;\n        info->stride  = info->act_size.width * 3 / 8;\n    }\n    else if(info->format == PIXEL_FORMAT_ARGB_4444 || info->format == PIXEL_FORMAT_ABGR_4444)\n    {\n        info->size = info->act_size.width  * info->act_size.height * 2;\n        info->stride  = info->act_size.width * 2 / 8;\n    }\n    else if(info->format == PIXEL_FORMAT_ARGB_1555 || info->format == PIXEL_FORMAT_ABGR_1555)\n    {\n        info->size = info->act_size.width  * info->act_size.height * 2;\n        info->stride  = info->act_size.width * 2 / 8;\n    }\n    else\n    {\n        printf("set osd pixel format failed  \\n");\n    }\n\n    attr.stride = info->stride;\n    attr.pixel_format = info->format;\n    attr.display_rect = info->offset;\n    attr.img_size = info->act_size;\n    kd_mpi_vo_set_video_osd_attr(osd, &attr);\n\n    kd_mpi_vo_osd_enable(osd);\n\n    return 0;\n}\n\nvoid sample_vicap_install_osd(void)\n{\n    osd_info osd;\n\n    osd.act_size.width = osd_width ;\n    osd.act_size.height = osd_height;\n    osd.offset.x = 0;\n    osd.offset.y = 0;\n    osd.global_alptha = 0xff;\n    // osd.global_alptha = 0x32;\n    osd.format = PIXEL_FORMAT_ARGB_8888;//PIXEL_FORMAT_ARGB_4444; //PIXEL_FORMAT_ARGB_1555;//PIXEL_FORMAT_ARGB_8888;\n\n    vo_creat_osd_test(osd_id, &osd);\n}\n\nvoid vo_osd_release_block(void)\n{\n    if(vicap_install_osd == 1)\n    {\n        kd_mpi_vo_osd_disable(osd_id);\n        kd_mpi_vb_release_block(block);\n    }\n    \n}\n\nstatic k_s32 sample_connector_init(void)\n{\n    k_u32 ret = 0;\n    k_s32 connector_fd;\n#if defined(CONFIG_BOARD_K230_CANMV)\n    k_connector_type connector_type = LT9611_MIPI_4LAN_1920X1080_30FPS;// HX8377_V2_MIPI_4LAN_1080X1920_30FPS;\n#else\n    k_connector_type connector_type = HX8377_V2_MIPI_4LAN_1080X1920_30FPS;\n#endif\n    k_connector_info connector_info;\n\n    memset(&connector_info, 0, sizeof(k_connector_info));\n\n    //connector get sensor info\n    ret = kd_mpi_get_connector_info(connector_type, &connector_info);\n    if (ret) {\n        printf("sample_vicap, the sensor type not supported!\\n");\n        return ret;\n    }\n\n    connector_fd = kd_mpi_connector_open(connector_info.connector_name);\n    if (connector_fd < 0) {\n        printf("%s, connector open failed.\\n", __func__);\n        return K_ERR_VO_NOTREADY;\n    }\n\n    // set connect power\n    kd_mpi_connector_power_set(connector_fd, K_TRUE);\n    // connector init\n    kd_mpi_connector_init(connector_fd, connector_info);\n\n    return 0;\n}\n\nstatic k_s32 vo_layer_vdss_bind_vo_config(void)\n{\n    layer_info info;\n\n    k_vo_layer chn_id = K_VO_LAYER1;\n\n    memset(&info, 0, sizeof(info));\n\n    sample_connector_init();\n\n    // config lyaer\n    info.act_size.width = ISP_CHN0_WIDTH;//ISP_CHN0_HEIGHT;//1080;//640;//1080;\n    info.act_size.height = ISP_CHN0_HEIGHT;//ISP_CHN0_WIDTH;//1920;//480;//1920;\n    info.format = PIXEL_FORMAT_YVU_PLANAR_420;\n    info.func = 0;//K_ROTATION_180;////K_ROTATION_90;\n    info.global_alptha = 0xff;\n    info.offset.x = 0;//(1080-w)/2,\n    info.offset.y = 0;//(1920-h)/2;\n    vo_creat_layer_test(chn_id, &info);\n\n    if(vicap_install_osd == 1)\n        sample_vicap_install_osd();\n\n    //exit ;\n    return 0;\n}\n\nstatic void sample_vicap_bind_vo(k_mpp_chn vicap_mpp_chn, k_mpp_chn vo_mpp_chn)\n{\n    k_s32 ret;\n\n    ret = kd_mpi_sys_bind(&vicap_mpp_chn, &vo_mpp_chn);\n    if (ret) {\n        printf("kd_mpi_sys_unbind failed:0x%x\\n", ret);\n    }\n\n    return;\n}\n\nstatic void sample_vicap_unbind_vo(k_mpp_chn vicap_mpp_chn, k_mpp_chn vo_mpp_chn)\n{\n    k_s32 ret;\n\n    ret = kd_mpi_sys_unbind(&vicap_mpp_chn, &vo_mpp_chn);\n    if (ret) {\n        printf("kd_mpi_sys_unbind failed:0x%x\\n", ret);\n    }\n\n    return;\n}\n\nint vivcap_start()\n{\n    k_s32 ret = 0;\n\n    k_u32 pool_id;\n    k_vb_pool_config pool_config;\n\n    printf("sample_vicap ...\\n");\n\n#if defined(CONFIG_BOARD_K230_CANMV)\n    sensor_type = OV_OV5647_MIPI_CSI0_1920X1080_30FPS_10BIT_LINEAR;\n    kd_mpi_vicap_set_mclk(VICAP_MCLK0, VICAP_PLL0_CLK_DIV4, 16, 1);\n#else\n    sensor_type = IMX335_MIPI_2LANE_RAW12_2592X1944_30FPS_LINEAR;\n#endif\n    vicap_dev = VICAP_DEV_ID_0;\n\n    memset(&config, 0, sizeof(config));\n    config.max_pool_cnt = 64;\n    //VB for YUV420SP output\n    config.comm_pool[0].blk_cnt = 5;\n    config.comm_pool[0].mode = VB_REMAP_MODE_NOCACHE;\n    config.comm_pool[0].blk_size = VICAP_ALIGN_UP((ISP_CHN0_WIDTH * ISP_CHN0_HEIGHT * 3 / 2), VICAP_ALIGN_1K);\n   \n    //VB for RGB888 output\n    config.comm_pool[1].blk_cnt = 5;\n    config.comm_pool[1].mode = VB_REMAP_MODE_NOCACHE;\n    config.comm_pool[1].blk_size = VICAP_ALIGN_UP((SENSOR_HEIGHT * SENSOR_WIDTH * 3 ), VICAP_ALIGN_1K);\n\n    ret = kd_mpi_vb_set_config(&config);\n    if (ret) {\n        printf("vb_set_config failed ret:%d\\n", ret);\n        return ret;\n    }\n\n    k_vb_supplement_config supplement_config;\n    memset(&supplement_config, 0, sizeof(supplement_config));\n    supplement_config.supplement_config |= VB_SUPPLEMENT_JPEG_MASK;\n\n    ret = kd_mpi_vb_set_supplement_config(&supplement_config);\n    if (ret) {\n        printf("vb_set_supplement_config failed ret:%d\\n", ret);\n        return ret;\n    }\n\n    ret = kd_mpi_vb_init();\n    if (ret) {\n        printf("vb_init failed ret:%d\\n", ret);\n        return ret;\n    }\n    printf("sample_vicap ...kd_mpi_vicap_get_sensor_info\\n");\n\n    // dwc_dsi_init();\n    vo_layer_vdss_bind_vo_config();\n\n    if(vicap_install_osd == 1)\n    {\n        memset(&pool_config, 0, sizeof(pool_config));\n        pool_config.blk_size = VICAP_ALIGN_UP((osd_width * osd_height * 4 * 2), VICAP_ALIGN_1K);\n        pool_config.blk_cnt = 4;\n        pool_config.mode = VB_REMAP_MODE_NOCACHE;\n        pool_id = kd_mpi_vb_create_pool(&pool_config);      // osd0 - 3 argb 320 x 240\n        g_pool_id = pool_id;\n\n        printf("--------aa--------------g_pool_id is %d pool_id is %d \\n",g_pool_id, pool_id);\n    }\n\n    memset(&sensor_info, 0, sizeof(k_vicap_sensor_info));\n    ret = kd_mpi_vicap_get_sensor_info(sensor_type, &sensor_info);\n    if (ret) {\n        printf("sample_vicap, the sensor type not supported!\\n");\n        return ret;\n    }\n\n    memset(&dev_attr, 0, sizeof(k_vicap_dev_attr));\n    dev_attr.acq_win.h_start = 0;\n    dev_attr.acq_win.v_start = 0;\n#if defined (CONFIG_BOARD_K230_CANMV)\n    dev_attr.acq_win.width = ISP_CHN0_WIDTH;\n    dev_attr.acq_win.height = ISP_CHN0_HEIGHT;\n#else\n    dev_attr.acq_win.width = 2592;//SENSOR_HEIGHT;\n    dev_attr.acq_win.height = 1944;//SENSOR_WIDTH;\n#endif\n    dev_attr.mode = VICAP_WORK_ONLINE_MODE;\n\n    dev_attr.pipe_ctrl.data = 0xFFFFFFFF;\n    dev_attr.pipe_ctrl.bits.af_enable = 0;\n    dev_attr.pipe_ctrl.bits.ahdr_enable = 0;\n\n\n    dev_attr.cpature_frame = 0;\n    memcpy(&dev_attr.sensor_info, &sensor_info, sizeof(k_vicap_sensor_info));\n\n    ret = kd_mpi_vicap_set_dev_attr(vicap_dev, dev_attr);\n    if (ret) {\n        printf("sample_vicap, kd_mpi_vicap_set_dev_attr failed.\\n");\n        return ret;\n    }\n\n    memset(&chn_attr, 0, sizeof(k_vicap_chn_attr));\n\n    //set chn0 output yuv420sp\n    chn_attr.out_win.h_start = 0;\n    chn_attr.out_win.v_start = 0;\n    chn_attr.out_win.width = ISP_CHN0_WIDTH;\n    chn_attr.out_win.height = ISP_CHN0_HEIGHT;\n\n\n#if defined(CONFIG_BOARD_K230_CANMV)\n    chn_attr.crop_win = dev_attr.acq_win;\n#else\n    // chn_attr.crop_win = dev_attr.acq_win;\n    chn_attr.crop_win.h_start = 768;\n    chn_attr.crop_win.v_start = 16;\n    chn_attr.crop_win.width = ISP_CHN0_WIDTH;\n    chn_attr.crop_win.height = ISP_CHN0_HEIGHT;\n#endif\n\n    chn_attr.scale_win = chn_attr.out_win;\n    chn_attr.crop_enable = K_FALSE;\n    chn_attr.scale_enable = K_FALSE;\n    // chn_attr.dw_enable = K_FALSE;\n    chn_attr.chn_enable = K_TRUE;\n    chn_attr.pix_format = PIXEL_FORMAT_YVU_PLANAR_420;\n    chn_attr.buffer_num = VICAP_MAX_FRAME_COUNT;//at least 3 buffers for isp\n    chn_attr.buffer_size = config.comm_pool[0].blk_size;\n    vicap_chn = VICAP_CHN_ID_0;\n\n    printf("sample_vicap ...kd_mpi_vicap_set_chn_attr, buffer_size[%d]\\n", chn_attr.buffer_size);\n    ret = kd_mpi_vicap_set_chn_attr(vicap_dev, vicap_chn, chn_attr);\n    if (ret) {\n        printf("sample_vicap, kd_mpi_vicap_set_chn_attr failed.\\n");\n        return ret;\n    }\n\n    //bind vicap chn 0 to vo\n    vicap_mpp_chn.mod_id = K_ID_VI;\n    vicap_mpp_chn.dev_id = vicap_dev;\n    vicap_mpp_chn.chn_id = vicap_chn;\n\n    vo_mpp_chn.mod_id = K_ID_VO;\n    vo_mpp_chn.dev_id = K_VO_DISPLAY_DEV_ID;\n    vo_mpp_chn.chn_id = K_VO_DISPLAY_CHN_ID1;\n\n    sample_vicap_bind_vo(vicap_mpp_chn, vo_mpp_chn);\n    printf("sample_vicap ...dwc_dsi_init\\n");\n\n    //set chn1 output rgb888p\n    chn_attr.out_win.h_start = 0;\n    chn_attr.out_win.v_start = 0;\n    chn_attr.out_win.width = SENSOR_WIDTH ;\n    chn_attr.out_win.height = SENSOR_HEIGHT;\n    // chn_attr.crop_win = dev_attr.acq_win;\n\n#if defined(CONFIG_BOARD_K230_CANMV)\n    chn_attr.crop_win = dev_attr.acq_win;\n#else   \n    chn_attr.crop_win.h_start = 768;\n    chn_attr.crop_win.v_start = 16;\n    chn_attr.crop_win.width = ISP_CHN0_WIDTH;\n    chn_attr.crop_win.height = ISP_CHN0_HEIGHT;\n#endif\n\n    chn_attr.scale_win = chn_attr.out_win;\n    chn_attr.crop_enable = K_FALSE;\n    chn_attr.scale_enable = K_FALSE;\n    // chn_attr.dw_enable = K_FALSE;\n    chn_attr.chn_enable = K_TRUE;\n    chn_attr.pix_format = PIXEL_FORMAT_BGR_888_PLANAR;\n    chn_attr.buffer_num = VICAP_MAX_FRAME_COUNT;//at least 3 buffers for isp\n    chn_attr.buffer_size = config.comm_pool[1].blk_size;\n\n    printf("sample_vicap ...kd_mpi_vicap_set_chn_attr, buffer_size[%d]\\n", chn_attr.buffer_size);\n    ret = kd_mpi_vicap_set_chn_attr(vicap_dev, VICAP_CHN_ID_1, chn_attr);\n    if (ret) {\n        printf("sample_vicap, kd_mpi_vicap_set_chn_attr failed.\\n");\n        return ret;\n    }\n\n    printf("sample_vicap ...kd_mpi_vicap_init\\n");\n    ret = kd_mpi_vicap_init(vicap_dev);\n    if (ret) {\n        printf("sample_vicap, kd_mpi_vicap_init failed.\\n");\n        // goto err_exit;\n    }\n\n    printf("sample_vicap ...kd_mpi_vicap_start_stream\\n");\n    ret = kd_mpi_vicap_start_stream(vicap_dev);\n    if (ret) {\n        printf("sample_vicap, kd_mpi_vicap_init failed.\\n");\n        // goto err_exit;\n    }\n\n    return ret;\n}\n\nint vivcap_stop()\n{\n    printf("sample_vicap ...kd_mpi_vicap_stop_stream\\n");\n    int ret = kd_mpi_vicap_stop_stream(vicap_dev);\n    if (ret) {\n        printf("sample_vicap, kd_mpi_vicap_init failed.\\n");\n        return ret;\n    }\n\n    ret = kd_mpi_vicap_deinit(vicap_dev);\n    if (ret) {\n        printf("sample_vicap, kd_mpi_vicap_deinit failed.\\n");\n        return ret;\n    }\n\n    kd_mpi_vo_disable_video_layer(K_VO_LAYER1);\n\n    vicap_mpp_chn.mod_id = K_ID_VI;\n    vicap_mpp_chn.dev_id = vicap_dev;\n    vicap_mpp_chn.chn_id = vicap_chn;\n\n    vo_mpp_chn.mod_id = K_ID_VO;\n    vo_mpp_chn.dev_id = K_VO_DISPLAY_DEV_ID;\n    vo_mpp_chn.chn_id = K_VO_DISPLAY_CHN_ID1;\n\n    sample_vicap_unbind_vo(vicap_mpp_chn, vo_mpp_chn);\n\n    /*Allow one frame time for the VO to release the VB block*/\n    k_u32 display_ms = 1000 / 33;\n    usleep(1000 * display_ms);\n\n    ret = kd_mpi_vb_exit();\n    if (ret) {\n        printf("sample_vicap, kd_mpi_vb_exit failed.\\n");\n        return ret;\n    }\n\n    return 0;\n}\n\nvoid yuv_rotate_90(char *des, char *src,int width,int height)\n{\n    int n = 0;\n    int hw = width>>1;\n    int hh = height>>1;\n    int size = width * height;\n    int hsize = size>>2;\n\n    int pos = 0;\n\n    for(int i = width-1;i >= 0;i--)\n    {\n        pos = 0;\n        for(int j= 0;j < height;j++)\n        {\n            des[n++]= src[pos+i];\n            pos += width;\n        }\n    }\n\n}\n/****************************************************************************/\n'})}),"\n",(0,i.jsx)(e.p,{children:"main.cc"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'/* Copyright (c) 2023, Canaan Bright Sight Co., Ltd\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n * 1. Redistributions of source code must retain the above copyright\n * notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n * notice, this list of conditions and the following disclaimer in the\n * documentation and/or other materials provided with the distribution.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND\n * CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,\n * INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR\n * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n * BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#include <iostream>\n#include <thread>\n#include <map>\n#include <nncase/runtime/runtime_tensor.h>\n#include <nncase/runtime/interpreter.h>\n#include <nncase/runtime/runtime_op_utility.h>\n#include <opencv2/highgui.hpp>\n#include <opencv2/imgcodecs.hpp>\n#include <opencv2/imgproc.hpp>\n\n#include "vi_vo.h"\n\nusing namespace nncase;\nusing namespace nncase::runtime;\n\nusing cv::Mat;\nusing std::cerr;\nusing std::cout;\nusing std::endl;\nusing namespace std;\n\nauto cache = cv::Mat::zeros(1, 1, CV_32FC1);\n/**\n * @brief \u5206\u7c7b\u7ed3\u679c\u7ed3\u6784\n */\ntypedef struct cls_res\n{\n    float score;//\u5206\u7c7b\u5206\u6570\n    string label;//\u5206\u7c7b\u6807\u7b7e\u7ed3\u679c\n}cls_res;\n\nstd::atomic<bool> isp_stop(false);\n\nvoid video_proc_cls(char *argv[])\n{\n    \n    /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n    vivcap_start();\n\n    // osd set\n    k_video_frame_info vf_info;\n    void *pic_vaddr = NULL;       \n\n    memset(&vf_info, 0, sizeof(vf_info));\n\n    vf_info.v_frame.width = osd_width;\n    vf_info.v_frame.height = osd_height;\n    vf_info.v_frame.stride[0] = osd_width;\n    vf_info.v_frame.pixel_format = PIXEL_FORMAT_ARGB_8888;\n    block = vo_insert_frame(&vf_info, &pic_vaddr);\n\n    // alloc memory for sensor\n    size_t paddr = 0;\n    void *vaddr = nullptr;\n    size_t size = SENSOR_CHANNEL * SENSOR_HEIGHT * SENSOR_WIDTH;\n    int ret = kd_mpi_sys_mmz_alloc_cached(&paddr, &vaddr, "allocate", "anonymous", size);\n    if (ret)\n    {\n        std::cerr << "physical_memory_block::allocate failed: ret = " << ret << ", errno = " << strerror(errno) << std::endl;\n        std::abort();\n    }\n    /*****************************************************************************/ \n\n    string kmodel_path = argv[1];\n    cout<<"kmodel_path : "<<kmodel_path<<endl;\n    float cls_thresh=0.5;\n\n    /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n    // \u6211\u4eec\u5df2\u7ecf\u628a\u76f8\u5173\u5b9e\u73b0\u5c01\u88c5\u5230ai_base.cc\uff0c\u8fd9\u91cc\u53ea\u662f\u4e3a\u4e86\u4ecb\u7ecd\u8d77\u6765\u6bd4\u8f83\u7b80\u5355\n    interpreter kmodel_interp;        \n    // load model\n    std::ifstream ifs(kmodel_path, std::ios::binary);\n    kmodel_interp.load_model(ifs).expect("Invalid kmodel");\n\n    // inputs init\n    for (size_t i = 0; i < kmodel_interp.inputs_size(); i++)\n    {\n        auto desc = kmodel_interp.input_desc(i);\n        auto shape = kmodel_interp.input_shape(i);\n        auto tensor = host_runtime_tensor::create(desc.datatype, shape, hrt::pool_shared).expect("cannot create input tensor");\n        kmodel_interp.input_tensor(i, tensor).expect("cannot set input tensor");\n    } \n    auto shape0 = kmodel_interp.input_shape(0);      //nhwc\n    int kmodel_input_height = shape0[1];\n    int kmodel_input_width = shape0[2];\n\n    // outputs init\n    for (size_t i = 0; i < kmodel_interp.outputs_size(); i++)\n    {\n        auto desc = kmodel_interp.output_desc(i);\n        auto shape = kmodel_interp.output_shape(i);\n        auto tensor = host_runtime_tensor::create(desc.datatype, shape, hrt::pool_shared).expect("cannot create output tensor");\n        kmodel_interp.output_tensor(i, tensor).expect("cannot set output tensor");\n    }\n    /*****************************************************************************/ \n\n    vector<cls_res> results;\n    std::vector<std::string> labels = {"bocai","changqiezi","huluobo","xihongshi","xilanhua"};\n    \n    while (!isp_stop)\n    {\n        cv::Mat ori_img;\n        //sensor to cv::Mat\n        {\n            /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n            //\u4ece\u6444\u50cf\u5934\u8bfb\u53d6\u4e00\u5e27\u56fe\u50cf\n            memset(&dump_info, 0 , sizeof(k_video_frame_info));\n            ret = kd_mpi_vicap_dump_frame(vicap_dev, VICAP_CHN_ID_1, VICAP_DUMP_YUV, &dump_info, 1000);\n            if (ret) {\n                printf("sample_vicap...kd_mpi_vicap_dump_frame failed.\\n");\n                continue;\n            }\n\n            //\u5c06\u6444\u50cf\u5934\u5f53\u524d\u5e27\u5bf9\u5e94DDR\u5730\u5740\u6620\u5c04\u5230\u5f53\u524d\u7cfb\u7edf\u8fdb\u884c\u8bbf\u95ee\n            auto vbvaddr = kd_mpi_sys_mmap_cached(dump_info.v_frame.phys_addr[0], size);\n            memcpy(vaddr, (void *)vbvaddr, SENSOR_HEIGHT * SENSOR_WIDTH * 3); \n            kd_mpi_sys_munmap(vbvaddr, size);\n                /*****************************************************************************/ \n            \n            //\u5c06\u6444\u50cf\u5934\u6570\u636e\u8f6c\u6362\u4e3a\u4e3acv::Mat,sensor\uff08rgb,chw\uff09->cv::Mat\uff08bgr\uff0chwc\uff09\n            cv::Mat image_r = cv::Mat(SENSOR_HEIGHT,SENSOR_WIDTH, CV_8UC1, vaddr);\n            cv::Mat image_g = cv::Mat(SENSOR_HEIGHT,SENSOR_WIDTH, CV_8UC1, vaddr+SENSOR_HEIGHT*SENSOR_WIDTH);\n            cv::Mat image_b = cv::Mat(SENSOR_HEIGHT,SENSOR_WIDTH, CV_8UC1, vaddr+2*SENSOR_HEIGHT*SENSOR_WIDTH);\n            std::vector<cv::Mat> color_vec(3);\n            color_vec.clear();\n            color_vec.push_back(image_b);\n            color_vec.push_back(image_g);\n            color_vec.push_back(image_r);\n            cv::merge(color_vec, ori_img);\n        }\n\n        /***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539******************/\n        // pre_process\n        cv::Mat pre_process_img;\n        {\n            cv::Mat rgb_img;\n            cv::cvtColor(ori_img, rgb_img, cv::COLOR_BGR2RGB);\n            cv::resize(rgb_img, pre_process_img, cv::Size(kmodel_input_width, kmodel_input_height), cv::INTER_LINEAR);\n        }\n        /*****************************************************************************/  \n\n        /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n        // set kmodel input\n        {\n            runtime_tensor tensor0 = kmodel_interp.input_tensor(0).expect("cannot get input tensor");\n            auto in_buf = tensor0.impl()->to_host().unwrap()->buffer().as_host().unwrap().map(map_access_::map_write).unwrap().buffer();\n            memcpy(reinterpret_cast<unsigned char *>(in_buf.data()), pre_process_img.data,sizeof(uint8_t)* kmodel_input_height * kmodel_input_width * 3);\n            hrt::sync(tensor0, sync_op_t::sync_write_back, true).expect("sync write_back failed");\n        }\n        \n\n        // kmodel run\n        kmodel_interp.run().expect("error occurred in running model");\n\n        // get kmodel output\n        vector<float *> k_outputs;\n        {\n            for (int i = 0; i < kmodel_interp.outputs_size(); i++)\n            {\n                auto out = kmodel_interp.output_tensor(i).expect("cannot get output tensor");\n                auto buf = out.impl()->to_host().unwrap()->buffer().as_host().unwrap().map(map_access_::map_read).unwrap().buffer();\n                float *p_out = reinterpret_cast<float *>(buf.data());\n                k_outputs.push_back(p_out);\n            }\n        }\n        /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n\n        /***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539******************/\n        //post process\n        results.clear();\n        {\n            \n            float* output0 = k_outputs[0];\n            float sum = 0.0;\n            for (int i = 0; i < labels.size(); i++){\n                sum += exp(output0[i]);\n            }\n            \n            int max_index;\n            for (int i = 0; i < labels.size(); i++)\n            {\n                output0[i] = exp(output0[i]) / sum;\n            }\n            max_index = std::max_element(output0,output0+labels.size()) - output0; \n            cls_res b;\n            if (output0[max_index] >= cls_thresh)\n            {\n                b.label = labels[max_index];\n                b.score = output0[max_index];\n                results.push_back(b);\n            }\n        }\n        /*****************************************************************************/    \n\n        // draw result to vo\n        {\n            {\n                cv::Mat osd_frame(osd_height, osd_width, CV_8UC4, cv::Scalar(0, 0, 0, 0));\n                {\n         /***************************unfixed\uff1a\u4e0d\u540cAI Demo\u53ef\u80fd\u9700\u8981\u4fee\u6539******************/\n                    //draw cls\n                    double fontsize = (osd_frame.cols * osd_frame.rows * 1.0) / (1100 * 1200);\n                    for(int i = 0; i < results.size(); i++)\n                    {   \n                        std::string text = "class: " + results[i].label + ", score: " + std::to_string(round(results[i].score * 100) / 100.0).substr(0, 4);\n\n                        cv::putText(osd_frame, text, cv::Point(1, 40), cv::FONT_HERSHEY_SIMPLEX, 0.8, cv::Scalar(255, 255, 255, 0), 2);\n\n                        std::cout << text << std::endl;\n                    }\n                    /*****************************************************************************/\n                }\n\n           /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n                memcpy(pic_vaddr, osd_frame.data, osd_width * osd_height * 4);\n            }\n\n            // insert osd to vo\n            {\n                kd_mpi_vo_chn_insert_frame(osd_id+3, &vf_info);  //K_VO_OSD0\n                printf("kd_mpi_vo_chn_insert_frame success \\n");\n            }\n            \n        }\n        \n        {\n            // \u91ca\u653esensor\u5f53\u524d\u5e27\n            ret = kd_mpi_vicap_dump_release(vicap_dev, VICAP_CHN_ID_1, &dump_info);\n            if (ret) {\n                printf("sample_vicap...kd_mpi_vicap_dump_release failed.\\n");\n            }\n        }\n        /*****************************************************************************/ \n    }\n    \n    /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n    vo_osd_release_block();\n    vivcap_stop();\n\n    // free memory\n    ret = kd_mpi_sys_mmz_free(paddr, vaddr);\n    if (ret)\n    {\n        std::cerr << "free failed: ret = " << ret << ", errno = " << strerror(errno) << std::endl;\n        std::abort();\n    }\n    /*****************************************************************************/ \n}\n\nint main(int argc, char *argv[])\n{\n     std::cout << "case " << argv[0] << " built at " << __DATE__ << " " << __TIME__ << std::endl;\n    if (argc != 2)\n    {\n        cout << "\u6a21\u578b\u63a8\u7406\u65f6\u4f20\u53c2\u8bf4\u660e\uff1a"\n         << "<kmodel_path>" << endl\n         << "Options:" << endl\n         << "  kmodel_path     Kmodel\u7684\u8def\u5f84\\n"\n         << "\\n"\n         << endl;\n        return -1;\n    }\n\n    /***************************fixed\uff1a\u65e0\u9700\u4fee\u6539***********************************/\n    std::thread thread_isp(video_proc_cls, argv);\n    while (getchar() != \'q\')\n    {\n        usleep(10000);\n    }\n\n    isp_stop = true;\n    thread_isp.join();\n    /*****************************************************************************/ \n    return 0;\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"52-\u57fa\u4e8eulabmicropython\u7684ai\u63a8\u7406\u6d41\u7a0b",children:"5.2 \u57fa\u4e8eulab(MicroPython)\u7684AI\u63a8\u7406\u6d41\u7a0b"}),"\n",(0,i.jsx)(e.p,{children:"\u57fa\u4e8eulab\uff08MicroPython\uff09\u7684K230 AI\u63a8\u7406\uff0c\u7b80\u8981\u4ecb\u7ecd\u4e86\u4f7f\u7528MicroPython\u8bed\u8a00\u5b9e\u73b0\u7684\u89c6\u9891\u91c7\u96c6\uff0c\u56fe\u50cf\u9884\u5904\u7406\uff08ulab\uff09\uff0c\u6a21\u578b\u63a8\u7406\u3001\u540e\u5904\u7406\uff08ulab\uff09\u3001\u663e\u793a\u7b49\u8fc7\u7a0b\u3002"}),"\n",(0,i.jsx)(e.h3,{id:"521-\u89c6\u9891\u91c7\u96c6",children:"5.2.1 \u89c6\u9891\u91c7\u96c6"}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u89c6\u9891\u91c7\u96c6"}),"\uff1a\uff08\u89c6\u9891\u8f93\u5165\uff0cVI\uff09\u4e0e\u6444\u50cf\u5934\u76f8\u5173\uff0c\u672c\u5c0f\u8282\u7b80\u8981\u4ecb\u7ecd\u57fa\u4e8eMicropython\u7684\u6444\u50cf\u5934\u8bbe\u7f6e\u3001\u6444\u50cf\u5934\u542f\u52a8\u3001\u4ece\u6444\u50cf\u5934\u4e2d\u83b7\u53d6\u4e00\u5e27\u6570\u636e\u3001\u6444\u50cf\u5934\u505c\u6b62\u7684\u6574\u4f53\u6d41\u7a0b\u3002"]}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u521b\u5efa\u6444\u50cf\u5934sensor\u5bf9\u8c61\uff0c\u5e76\u8bbe\u7f6e\u591a\u8def\u8f93\u51fa\u683c\u5f0f\u548c\u5927\u5c0f"}),"\uff1a"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"\u8bbe\u7f6e\u7684sensor\u4e24\u8def\u8f93\u51fa\uff1b"}),"\n",(0,i.jsx)(e.li,{children:"\u4e00\u8def\u8f93\u51fa\u7528\u4e8e\u663e\u793a\uff0c\u8f93\u51fa\u5927\u5c0f\u8bbe\u7f6e1080p\uff0c\u56fe\u50cf\u683c\u5f0f\u4e3aPIXEL_FORMAT_YVU_PLANAR_420\uff0c\u76f4\u63a5\u7ed1\u5b9a\u5230vo\uff1b"}),"\n",(0,i.jsx)(e.li,{children:"\u53e6\u4e00\u8def\u8f93\u51fa\u7528\u4e8eAI\u8ba1\u7b97\uff0c\u8f93\u51fa\u5927\u5c0f\uff081280,720\uff09,\u56fe\u50cf\u683c\u5f0f\u4e3aPIXEL_FORMAT_RGB_888_PLANAR\uff1b"}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'import os\nfrom media.sensor import * #\u5bfc\u5165sensor\u6a21\u5757\uff0c\u4f7f\u7528sensor\u76f8\u5173\u63a5\u53e3\nfrom media.display import * #\u5bfc\u5165display\u6a21\u5757\uff0c\u4f7f\u7528display\u76f8\u5173\u63a5\u53e3\nfrom media.media import * #\u5bfc\u5165media\u6a21\u5757\uff0c\u4f7f\u7528meida\u76f8\u5173\u63a5\u53e3\nfrom time import *\nimport gc\n\n# \u663e\u793a\u8f93\u51fa\u5927\u5c0f\nDISPLAY_WIDTH = ALIGN_UP(1920, 16)\nDISPLAY_HEIGHT = 1080\n# AI\u83b7\u53d6\u7684RGB888P\u7684\u56fe\u50cf\u5927\u5c0f\nOUT_RGB888P_WIDTH = ALIGN_UP(1280, 16)\nOUT_RGB888P_HEIGH = 720\n\ndef sensor_init():\n    # \u521d\u59cb\u5316\u5e76\u914d\u7f6esensor\n    sensor = Sensor()\n    sensor.reset()\n    # \u8bbe\u7f6e\u955c\u50cf\n    sensor.set_hmirror(False)\n    # \u8bbe\u7f6e\u7ffb\u8f6c\n    sensor.set_vflip(False)\n    # \u901a\u90530\u76f4\u63a5\u7ed9\u5230\u663e\u793aVO\uff0c\u683c\u5f0f\u4e3aYUV420\n    sensor.set_framesize(width = DISPLAY_WIDTH, height = DISPLAY_HEIGHT)\n    sensor.set_pixformat(PIXEL_FORMAT_YUV_SEMIPLANAR_420)\n    # \u901a\u90532\u7ed9\u5230AI\u505a\u7b97\u6cd5\u5904\u7406\uff0c\u683c\u5f0f\u4e3aRGB888\n    sensor.set_framesize(width = OUT_RGB888P_WIDTH , height = OUT_RGB888P_HEIGH, chn=CAM_CHN_ID_2)\n    sensor.set_pixformat(PIXEL_FORMAT_RGB_888_PLANAR, chn=CAM_CHN_ID_2)\n\t# \u7ed1\u5b9a\u901a\u90530\u7684\u8f93\u51fa\u5230vo\n    sensor_bind_info = sensor.bind_info(x = 0, y = 0, chn = CAM_CHN_ID_0)\n    Display.bind_layer(**sensor_bind_info, layer = Display.LAYER_VIDEO1)\n    # \u8bbe\u7f6e\u4e3aLT9611\u663e\u793a\uff0c\u9ed8\u8ba41920x1080\n    Display.init(Display.LT9611, to_ide = True)\n    try:\n        # media\u521d\u59cb\u5316\n        MediaManager.init()\n        # \u542f\u52a8sensor\n        sensor.run()\n        rgb888p_img = None\n        while  True:\n            #\u6355\u83b7\u6444\u50cf\u5934\u6570\u636e\n            rgb888p_img = sensor.snapshot(chn=CAM_CHN_ID_2)\n            #************\u62ff\u5230\u4e00\u5e27\u56fe\u50cf\u540e\u53ef\u4ee5\u8fdb\u884c\u540e\u7eedAI\u8fc7\u7a0b************\n            #                      ......\n            #***************************************************\n    except Exception as e:\n        print(f"An error occurred during running: {e}")\n    finally:\n        os.exitpoint(os.EXITPOINT_ENABLE_SLEEP)\n        #\u505c\u6b62\u6444\u50cf\u5934\u8f93\u51fa\n        sensor.stop()\n        #\u53bb\u521d\u59cb\u5316\u663e\u793a\u8bbe\u5907\n        Display.deinit()\n        #\u91ca\u653e\u5a92\u4f53\u7f13\u51b2\u533a\n        MediaManager.deinit()\n        gc.collect()\n        nn.shrink_memory_pool()\n    return 0\n\nsensor_init()\n'})}),"\n",(0,i.jsx)(e.h3,{id:"522-\u9884\u5904\u7406",children:"5.2.2 \u9884\u5904\u7406"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'import os\nfrom media.sensor import * #\u5bfc\u5165camera\u6a21\u5757\uff0c\u4f7f\u7528camera\u76f8\u5173\u63a5\u53e3\nfrom media.display import * #\u5bfc\u5165display\u6a21\u5757\uff0c\u4f7f\u7528display\u76f8\u5173\u63a5\u53e3\nfrom media.media import * #\u5bfc\u5165media\u6a21\u5757\uff0c\u4f7f\u7528meida\u76f8\u5173\u63a5\u53e3\nfrom time import *\nimport time\nimport nncase_runtime as nn #\u5bfc\u5165nn\u6a21\u5757\uff0c\u4f7f\u7528nn\u76f8\u5173\u63a5\u53e3\nimport ulab.numpy as np #\u5bfc\u5165np\u6a21\u5757\uff0c\u4f7f\u7528np\u76f8\u5173\u63a5\u53e3\nimport gc\n\n# \u663e\u793a\u8f93\u51fa\u5927\u5c0f\nDISPLAY_WIDTH = ALIGN_UP(1920, 16)\nDISPLAY_HEIGHT = 1080\n# AI\u83b7\u53d6\u7684RGB888P\u7684\u56fe\u50cf\u5927\u5c0f\nOUT_RGB888P_WIDTH = ALIGN_UP(1280, 16)\nOUT_RGB888P_HEIGH = 720\n\ndef cls_test():\n    print("cls_test start")\n    #\u521d\u59cb\u5316AI2D\n    ai2d = nn.ai2d()\n    # \u8bbe\u7f6eai2d\u7684\u8f93\u5165\u8f93\u51fa\u6570\u636e\u683c\u5f0f\u548c\u6570\u636e\u7c7b\u578b\n    ai2d.set_dtype(nn.ai2d_format.NCHW_FMT,nn.ai2d_format.NCHW_FMT,np.uint8, np.uint8)\n    # \u8bbe\u7f6eresize\u9884\u5904\u7406\n    ai2d.set_resize_param(True, nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel )\n    # \u6784\u5efa\u9884\u5904\u7406,\u53c2\u6570\u4e3a\u8f93\u5165\u8f93\u51fatensor\u7684shape\n    ai2d_builder = ai2d.build([1,3,OUT_RGB888P_HEIGH,OUT_RGB888P_WIDTH], [1,3,224,224])\n\n    # \u521d\u59cb\u5316\u5e76\u914d\u7f6esensor\n    sensor = Sensor()\n    sensor.reset()\n    # \u8bbe\u7f6e\u955c\u50cf\n    sensor.set_hmirror(False)\n    # \u8bbe\u7f6e\u7ffb\u8f6c\n    sensor.set_vflip(False)\n    # \u901a\u90530\u76f4\u63a5\u7ed9\u5230\u663e\u793aVO\uff0c\u683c\u5f0f\u4e3aYUV420\n    sensor.set_framesize(width = DISPLAY_WIDTH, height = DISPLAY_HEIGHT)\n    sensor.set_pixformat(PIXEL_FORMAT_YUV_SEMIPLANAR_420)\n    # \u901a\u90532\u7ed9\u5230AI\u505a\u7b97\u6cd5\u5904\u7406\uff0c\u683c\u5f0f\u4e3aRGB888\n    sensor.set_framesize(width = OUT_RGB888P_WIDTH , height = OUT_RGB888P_HEIGH, chn=CAM_CHN_ID_2)\n    sensor.set_pixformat(PIXEL_FORMAT_RGB_888_PLANAR, chn=CAM_CHN_ID_2)\n\t# \u7ed1\u5b9a\u901a\u90530\u7684\u8f93\u51fa\u5230vo\n    sensor_bind_info = sensor.bind_info(x = 0, y = 0, chn = CAM_CHN_ID_0)\n    Display.bind_layer(**sensor_bind_info, layer = Display.LAYER_VIDEO1)\n    # \u8bbe\u7f6e\u4e3aLT9611\u663e\u793a\uff0c\u9ed8\u8ba41920x1080\n    Display.init(Display.LT9611, to_ide = True)\n\n    try:\n        # media\u521d\u59cb\u5316\n        MediaManager.init()\n        # \u542f\u52a8sensor\n        sensor.run()\n        rgb888p_img = None\n        while  True:\n            #\u6355\u83b7\u6444\u50cf\u5934\u6570\u636e\n            rgb888p_img = sensor.snapshot(chn=CAM_CHN_ID_2)\n            # for rgb888planar\n            if rgb888p_img.format() == image.RGBP888:\n                # image\u8f6cnumpy.ndarray\n                ai2d_input = rgb888p_img.to_numpy_ref()\n                # \u4ecenumpy.ndarray\u521b\u5efatensor\n                ai2d_input_tensor = nn.from_numpy(ai2d_input)\n                # \u521d\u59cb\u5316\u9884\u5904\u7406\u8f93\u51fa\n                data = np.ones((1,3,224,224),dtype=np.uint8)\n                # numpy.ndarray\u8f6ctensor\n                ai2d_out = nn.from_numpy(data)\n                # \u6267\u884c\u9884\u5904\u7406\n                ai2d_builder.run(ai2d_input_tensor, ai2d_out)\n                # tensor\u8f6cnumpy.ndarray\n                ai2d_out_np=ai2d_out.to_numpy()\n                # \u6253\u5370\u9884\u5904\u7406\u5f62\u72b6\n                print(ai2d_out_np.shape)\n    except Exception as e:\n        print(f"An error occurred during running: {e}")\n    finally:\n        os.exitpoint(os.EXITPOINT_ENABLE_SLEEP)\n        #\u505c\u6b62\u6444\u50cf\u5934\u8f93\u51fa\n        sensor.stop()\n        #\u53bb\u521d\u59cb\u5316\u663e\u793a\u8bbe\u5907\n        Display.deinit()\n        #\u91ca\u653e\u5a92\u4f53\u7f13\u51b2\u533a\n        MediaManager.deinit()\n        gc.collect()\n        time.sleep(1)\n        nn.shrink_memory_pool()\n    print("cls_test end")\n    return 0\n\ncls_test()\n'})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u6ce8"}),"\uff1a\u5bf9\u4e8e\u8be5\u5206\u7c7b\u6a21\u578b\u6765\u8bf4\uff0c\u9700\u8981\u5148\u62ff\u5230\u539f\u56fe\uff0c\u518d\u5c06\u539f\u56feresize\u5230\uff08224,224\uff09\u5927\u5c0f\uff0c\u4e4b\u540e\u518d\u5582\u7ed9\u6a21\u578b\uff1b\u5bf9\u4e8emicropython\u5f00\u53d1\uff0cresize\u53ef\u4ee5\u4f7f\u7528ai2d\u6a21\u5757\u5b9e\u73b0\u3002"]}),"\n",(0,i.jsx)(e.p,{children:"\u6211\u4eec\u4e5f\u53ef\u4ee5\u5c06\u5582\u7ed9AI\u7684\u6444\u50cf\u5934\u6570\u636e\u5206\u8fa8\u7387\u76f4\u63a5\u8bbe\u7f6e\u4e3a\uff08224,224\uff09\uff0c\u4ee3\u7801\u5982\u4e0b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'import os\nfrom media.sensor import * #\u5bfc\u5165camera\u6a21\u5757\uff0c\u4f7f\u7528camera\u76f8\u5173\u63a5\u53e3\nfrom media.display import * #\u5bfc\u5165display\u6a21\u5757\uff0c\u4f7f\u7528display\u76f8\u5173\u63a5\u53e3\nfrom media.media import * #\u5bfc\u5165media\u6a21\u5757\uff0c\u4f7f\u7528meida\u76f8\u5173\u63a5\u53e3\nfrom time import *\nimport time\nimport nncase_runtime as nn #\u5bfc\u5165nn\u6a21\u5757\uff0c\u4f7f\u7528nn\u76f8\u5173\u63a5\u53e3\nimport ulab.numpy as np #\u5bfc\u5165np\u6a21\u5757\uff0c\u4f7f\u7528np\u76f8\u5173\u63a5\u53e3\nimport gc\n\nDISPLAY_WIDTH = ALIGN_UP(1920, 16)\nDISPLAY_HEIGHT = 1080\n\nOUT_RGB888P_WIDTH = ALIGN_UP(224, 16)\nOUT_RGB888P_HEIGH = 224\n\ndef cls_test():\n    print("cls_test start")\n    # \u521d\u59cb\u5316\u5e76\u914d\u7f6esensor\n    sensor = Sensor()\n    sensor.reset()\n    # \u8bbe\u7f6e\u955c\u50cf\n    sensor.set_hmirror(False)\n    # \u8bbe\u7f6e\u7ffb\u8f6c\n    sensor.set_vflip(False)\n    # \u901a\u90530\u76f4\u63a5\u7ed9\u5230\u663e\u793aVO\uff0c\u683c\u5f0f\u4e3aYUV420\n    sensor.set_framesize(width = DISPLAY_WIDTH, height = DISPLAY_HEIGHT)\n    sensor.set_pixformat(PIXEL_FORMAT_YUV_SEMIPLANAR_420)\n    # \u901a\u90532\u7ed9\u5230AI\u505a\u7b97\u6cd5\u5904\u7406\uff0c\u683c\u5f0f\u4e3aRGB888\n    sensor.set_framesize(width = OUT_RGB888P_WIDTH , height = OUT_RGB888P_HEIGH, chn=CAM_CHN_ID_2)\n    sensor.set_pixformat(PIXEL_FORMAT_RGB_888_PLANAR, chn=CAM_CHN_ID_2)\n\t# \u7ed1\u5b9a\u901a\u90530\u7684\u8f93\u51fa\u5230vo\n    sensor_bind_info = sensor.bind_info(x = 0, y = 0, chn = CAM_CHN_ID_0)\n    Display.bind_layer(**sensor_bind_info, layer = Display.LAYER_VIDEO1)\n    # \u8bbe\u7f6e\u4e3aLT9611\u663e\u793a\uff0c\u9ed8\u8ba41920x1080\n    Display.init(Display.LT9611, to_ide = True)\n\n    try:\n        # media\u521d\u59cb\u5316\n        MediaManager.init()\n        # \u542f\u52a8sensor\n        sensor.run()\n        rgb888p_img = None\n        while  True:\n            #\u6355\u83b7\u6444\u50cf\u5934\u6570\u636e\n            rgb888p_img = sensor.snapshot(chn=CAM_CHN_ID_2)\n            # for rgb888planar\n            if rgb888p_img.format() == image.RGBP888:\n                input_img=rgb888p_img.to_numpy_ref()\n                # \u6253\u5370\u5f62\u72b6\n                print(input_img.shape)\n    except Exception as e:\n        print(f"An error occurred during running: {e}")\n    finally:\n        os.exitpoint(os.EXITPOINT_ENABLE_SLEEP)\n        #\u505c\u6b62\u6444\u50cf\u5934\u8f93\u51fa\n        sensor.stop()\n        #\u53bb\u521d\u59cb\u5316\u663e\u793a\u8bbe\u5907\n        Display.deinit()\n        #\u91ca\u653e\u5a92\u4f53\u7f13\u51b2\u533a\n        MediaManager.deinit()\n        gc.collect()\n        time.sleep(1)\n        nn.shrink_memory_pool()\n    print("cls_test end")\n    return 0\n\ncls_test()\n'})}),"\n",(0,i.jsx)(e.h3,{id:"523-\u6a21\u578b\u63a8\u7406",children:"5.2.3 \u6a21\u578b\u63a8\u7406"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'import os\nfrom media.sensor import * #\u5bfc\u5165camera\u6a21\u5757\uff0c\u4f7f\u7528camera\u76f8\u5173\u63a5\u53e3\nfrom media.display import * #\u5bfc\u5165display\u6a21\u5757\uff0c\u4f7f\u7528display\u76f8\u5173\u63a5\u53e3\nfrom media.media import * #\u5bfc\u5165media\u6a21\u5757\uff0c\u4f7f\u7528meida\u76f8\u5173\u63a5\u53e3\nfrom time import *\nimport time\nimport nncase_runtime as nn #\u5bfc\u5165nn\u6a21\u5757\uff0c\u4f7f\u7528nn\u76f8\u5173\u63a5\u53e3\nimport ulab.numpy as np #\u5bfc\u5165np\u6a21\u5757\uff0c\u4f7f\u7528np\u76f8\u5173\u63a5\u53e3\nimport gc\n\n# \u663e\u793a\u8f93\u51fa\u5927\u5c0f\nDISPLAY_WIDTH = ALIGN_UP(1920, 16)\nDISPLAY_HEIGHT = 1080\n# AI\u83b7\u53d6\u7684RGB888P\u7684\u56fe\u50cf\u5927\u5c0f\nOUT_RGB888P_WIDTH = ALIGN_UP(1280, 16)\nOUT_RGB888P_HEIGH = 720\n\nkmodel_path="/sdcard/app/tests/ai_test_kmodel/veg_cls.kmodel"\n\ndef cls_test():\n    print("cls_test start")\n    #\u521d\u59cb\u5316AI2D\n    ai2d = nn.ai2d()\n    # \u8bbe\u7f6eai2d\u7684\u8f93\u5165\u8f93\u51fa\u6570\u636e\u683c\u5f0f\u548c\u6570\u636e\u7c7b\u578b\n    ai2d.set_dtype(nn.ai2d_format.NCHW_FMT,nn.ai2d_format.NCHW_FMT,np.uint8, np.uint8)\n    # \u8bbe\u7f6eresize\u9884\u5904\u7406\n    ai2d.set_resize_param(True, nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel )\n    # \u6784\u5efa\u9884\u5904\u7406,\u53c2\u6570\u4e3a\u8f93\u5165\u8f93\u51fatensor\u7684shape\n    ai2d_builder = ai2d.build([1,3,OUT_RGB888P_HEIGH,OUT_RGB888P_WIDTH], [1,3,224,224])\n    # \u521d\u59cb\u5316kpu\n    kpu=nn.kpu()\n    # \u52a0\u8f7d\u6a21\u578b\n    kpu.load_kmodel(kmodel_path)\n    \n    # \u521d\u59cb\u5316\u5e76\u914d\u7f6esensor\n    sensor = Sensor()\n    sensor.reset()\n    # \u8bbe\u7f6e\u955c\u50cf\n    sensor.set_hmirror(False)\n    # \u8bbe\u7f6e\u7ffb\u8f6c\n    sensor.set_vflip(False)\n    # \u901a\u90530\u76f4\u63a5\u7ed9\u5230\u663e\u793aVO\uff0c\u683c\u5f0f\u4e3aYUV420\n    sensor.set_framesize(width = DISPLAY_WIDTH, height = DISPLAY_HEIGHT)\n    sensor.set_pixformat(PIXEL_FORMAT_YUV_SEMIPLANAR_420)\n    # \u901a\u90532\u7ed9\u5230AI\u505a\u7b97\u6cd5\u5904\u7406\uff0c\u683c\u5f0f\u4e3aRGB888\n    sensor.set_framesize(width = OUT_RGB888P_WIDTH , height = OUT_RGB888P_HEIGH, chn=CAM_CHN_ID_2)\n    sensor.set_pixformat(PIXEL_FORMAT_RGB_888_PLANAR, chn=CAM_CHN_ID_2)\n\t# \u7ed1\u5b9a\u901a\u90530\u7684\u8f93\u51fa\u5230vo\n    sensor_bind_info = sensor.bind_info(x = 0, y = 0, chn = CAM_CHN_ID_0)\n    Display.bind_layer(**sensor_bind_info, layer = Display.LAYER_VIDEO1)\n    # \u8bbe\u7f6e\u4e3aLT9611\u663e\u793a\uff0c\u9ed8\u8ba41920x1080\n    Display.init(Display.LT9611, to_ide = True)\n\n    try:\n        # media\u521d\u59cb\u5316\n        MediaManager.init()\n        # \u542f\u52a8sensor\n        sensor.run()\n        rgb888p_img = None\n        \n        # \u521d\u59cb\u5316\u9884\u5904\u7406\u8f93\u51fa\n        data = np.ones((1,3,224,224),dtype=np.uint8)\n        # numpy.ndarray\u8f6ctensor\n        ai2d_out = nn.from_numpy(data)\n        # \u5c06ai2d\u9884\u5904\u7406\u7684\u8f93\u51fa\u7ed1\u5b9a\u5230kmodel\u7684\u8f93\u5165\u4e0a\uff0c\u5373ai2d\u9884\u5904\u7406\u8f93\u51fa\u548ckpu\u7684\u8f93\u51fa\u5171\u7528\u4e00\u4e2atensor\n        kpu.set_input_tensor(0,ai2d_out)\n        while  True:\n            #\u6355\u83b7\u6444\u50cf\u5934\u6570\u636e\n            rgb888p_img = sensor.snapshot(chn=CAM_CHN_ID_2)\n            # for rgb888planar\n            if rgb888p_img.format() == image.RGBP888:\n                # image\u8f6cnumpy.ndarray\n                ai2d_input = rgb888p_img.to_numpy_ref()\n                # \u4ecenumpy.ndarray\u521b\u5efatensor\n                ai2d_input_tensor = nn.from_numpy(ai2d_input)\n                # \u6267\u884c\u9884\u5904\u7406\n                ai2d_builder.run(ai2d_input_tensor, ai2d_out)\n                # kpu\u63a8\u7406\n                kpu.run()\n                \n                # \u83b7\u53d6kmodel\u7684\u63a8\u7406\u8f93\u51fatensor,\u8f93\u51fa\u53ef\u80fd\u4e3a\u591a\u4e2a\uff0c\u56e0\u6b64\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u5217\u8868\n                results=[]\n                for i in range(kpu.outputs_size()):\n                    # \u83b7\u53d6kmodel\u7684\u7b2ci\u4e2a\u8f93\u51fa\n                    output_data = kpu.get_output_tensor(i)\n                    # tensor\u8f6cnumpy.ndarray\n                    result = output_data.to_numpy()\n                    # \u6253\u5370\u5f62\u72b6\n                    print(result.shape)\n                    # \u52a0\u5165\u5217\u8868\n                    results.append(result)\n                    del output_data\n                \n    except Exception as e:\n        print(f"An error occurred during running: {e}")\n    finally:\n        os.exitpoint(os.EXITPOINT_ENABLE_SLEEP)\n        del ai2d_input_tensor\n        del ai2d_out\n        #\u505c\u6b62\u6444\u50cf\u5934\u8f93\u51fa\n        sensor.stop()\n        #\u53bb\u521d\u59cb\u5316\u663e\u793a\u8bbe\u5907\n        Display.deinit()\n        #\u91ca\u653e\u5a92\u4f53\u7f13\u51b2\u533a\n        MediaManager.deinit()\n        gc.collect()\n        time.sleep(1)\n        nn.shrink_memory_pool()\n    print("cls_test end")\n    return 0\n\ncls_test()\n'})}),"\n",(0,i.jsx)(e.p,{children:"\u6ce8\u610f\uff1a\u5bf9\u4e8etensor\u7c7b\u578b\u7684\u6570\u636e\uff0c\u7533\u8bf7\u540e\u8bf7\u624b\u52a8\u91ca\u653e\u3002"}),"\n",(0,i.jsx)(e.h3,{id:"524-\u540e\u5904\u7406",children:"5.2.4 \u540e\u5904\u7406"}),"\n",(0,i.jsx)(e.p,{children:"\u5bf9\u6a21\u578b\u7ed3\u679c\u8fdb\u884c\u540e\u5904\u7406\uff0c\u8fd9\u91cc\u4ee5\u5206\u7c7b\u4e3a\u4f8b\uff0c\u5373\u5bf9\u8f93\u51fa\u5148\u505asoftmax\u518d\u505aargmax\u5f97\u5230\u7c7b\u522b\u7d22\u5f15\u3002"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'import os\nfrom media.sensor import * #\u5bfc\u5165camera\u6a21\u5757\uff0c\u4f7f\u7528camera\u76f8\u5173\u63a5\u53e3\nfrom media.display import * #\u5bfc\u5165display\u6a21\u5757\uff0c\u4f7f\u7528display\u76f8\u5173\u63a5\u53e3\nfrom media.media import * #\u5bfc\u5165media\u6a21\u5757\uff0c\u4f7f\u7528meida\u76f8\u5173\u63a5\u53e3\nfrom time import *\nimport time\nimport nncase_runtime as nn #\u5bfc\u5165nn\u6a21\u5757\uff0c\u4f7f\u7528nn\u76f8\u5173\u63a5\u53e3\nimport ulab.numpy as np #\u5bfc\u5165np\u6a21\u5757\uff0c\u4f7f\u7528np\u76f8\u5173\u63a5\u53e3\nimport gc\n\n# \u663e\u793a\u8f93\u51fa\u5927\u5c0f\nDISPLAY_WIDTH = ALIGN_UP(1920, 16)\nDISPLAY_HEIGHT = 1080\n# AI\u83b7\u53d6\u7684RGB888P\u7684\u56fe\u50cf\u5927\u5c0f\nOUT_RGB888P_WIDTH = ALIGN_UP(1280, 16)\nOUT_RGB888P_HEIGH = 720\n\nkmodel_path="/sdcard/app/tests/ai_test_kmodel/veg_cls.kmodel"\n\n# softmax\u51fd\u6570\ndef softmax(x):\n    exp_x = np.exp(x - np.max(x))\n    return exp_x / np.sum(exp_x)\n\ndef cls_test():\n    print("cls_test start")\n    #\u521d\u59cb\u5316AI2D\n    ai2d = nn.ai2d()\n    # \u8bbe\u7f6eai2d\u7684\u8f93\u5165\u8f93\u51fa\u6570\u636e\u683c\u5f0f\u548c\u6570\u636e\u7c7b\u578b\n    ai2d.set_dtype(nn.ai2d_format.NCHW_FMT,nn.ai2d_format.NCHW_FMT,np.uint8, np.uint8)\n    # \u8bbe\u7f6eresize\u9884\u5904\u7406\n    ai2d.set_resize_param(True, nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel )\n    # \u6784\u5efa\u9884\u5904\u7406,\u53c2\u6570\u4e3a\u8f93\u5165\u8f93\u51fatensor\u7684shape\n    ai2d_builder = ai2d.build([1,3,OUT_RGB888P_HEIGH,OUT_RGB888P_WIDTH], [1,3,224,224])\n    # \u521d\u59cb\u5316kpu\n    kpu=nn.kpu()\n    # \u52a0\u8f7d\u6a21\u578b\n    kpu.load_kmodel(kmodel_path)\n    \n    # \u521d\u59cb\u5316\u5e76\u914d\u7f6esensor\n    sensor = Sensor()\n    sensor.reset()\n    # \u8bbe\u7f6e\u955c\u50cf\n    sensor.set_hmirror(False)\n    # \u8bbe\u7f6e\u7ffb\u8f6c\n    sensor.set_vflip(False)\n    # \u901a\u90530\u76f4\u63a5\u7ed9\u5230\u663e\u793aVO\uff0c\u683c\u5f0f\u4e3aYUV420\n    sensor.set_framesize(width = DISPLAY_WIDTH, height = DISPLAY_HEIGHT)\n    sensor.set_pixformat(PIXEL_FORMAT_YUV_SEMIPLANAR_420)\n    # \u901a\u90532\u7ed9\u5230AI\u505a\u7b97\u6cd5\u5904\u7406\uff0c\u683c\u5f0f\u4e3aRGB888\n    sensor.set_framesize(width = OUT_RGB888P_WIDTH , height = OUT_RGB888P_HEIGH, chn=CAM_CHN_ID_2)\n    sensor.set_pixformat(PIXEL_FORMAT_RGB_888_PLANAR, chn=CAM_CHN_ID_2)\n\t# \u7ed1\u5b9a\u901a\u90530\u7684\u8f93\u51fa\u5230vo\n    sensor_bind_info = sensor.bind_info(x = 0, y = 0, chn = CAM_CHN_ID_0)\n    Display.bind_layer(**sensor_bind_info, layer = Display.LAYER_VIDEO1)\n    # \u8bbe\u7f6e\u4e3aLT9611\u663e\u793a\uff0c\u9ed8\u8ba41920x1080\n    Display.init(Display.LT9611, to_ide = True)\n\n    try:\n        # media\u521d\u59cb\u5316\n        MediaManager.init()\n        # \u542f\u52a8sensor\n        sensor.run()\n        rgb888p_img = None\n        \n        # \u521d\u59cb\u5316\u9884\u5904\u7406\u8f93\u51fa\n        data = np.ones((1,3,224,224),dtype=np.uint8)\n        # numpy.ndarray\u8f6ctensor\n        ai2d_out = nn.from_numpy(data)\n        # \u5c06ai2d\u9884\u5904\u7406\u7684\u8f93\u51fa\u7ed1\u5b9a\u5230kmodel\u7684\u8f93\u5165\u4e0a\uff0c\u5373ai2d\u9884\u5904\u7406\u8f93\u51fa\u548ckpu\u7684\u8f93\u51fa\u5171\u7528\u4e00\u4e2atensor\n        kpu.set_input_tensor(0,ai2d_out)\n        while  True:\n            #\u6355\u83b7\u6444\u50cf\u5934\u6570\u636e\n            rgb888p_img = sensor.snapshot(chn=CAM_CHN_ID_2)\n            # for rgb888planar\n            if rgb888p_img.format() == image.RGBP888:\n                # image\u8f6cnumpy.ndarray\n                ai2d_input = rgb888p_img.to_numpy_ref()\n                # \u4ecenumpy.ndarray\u521b\u5efatensor\n                ai2d_input_tensor = nn.from_numpy(ai2d_input)\n                # \u6267\u884c\u9884\u5904\u7406\n                ai2d_builder.run(ai2d_input_tensor, ai2d_out)\n                # kpu\u63a8\u7406\n                kpu.run()\n                \n                # \u83b7\u53d6kmodel\u7684\u63a8\u7406\u8f93\u51fatensor,\u8f93\u51fa\u53ef\u80fd\u4e3a\u591a\u4e2a\uff0c\u56e0\u6b64\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u5217\u8868\n                results=[]\n                for i in range(kpu.outputs_size()):\n                    # \u83b7\u53d6kmodel\u7684\u7b2ci\u4e2a\u8f93\u51fa\n                    output_data = kpu.get_output_tensor(i)\n                    # tensor\u8f6cnumpy.ndarray\n                    result = output_data.to_numpy()\n                    # \u52a0\u5165\u5217\u8868\n                    results.append(result)\n                    del output_data\n                #******************\u540e\u5904\u7406********************\n                # softmax+argmax\n                softmax_res=softmax(results[0][0])\n                res_idx=np.argmax(softmax_res)\n                # \u6253\u5370\u7c7b\u522b\u7d22\u5f15\n                print(res_idx)\n    except Exception as e:\n        print(f"An error occurred during running: {e}")\n    finally:\n        os.exitpoint(os.EXITPOINT_ENABLE_SLEEP)\n        del ai2d_input_tensor\n        del ai2d_out\n        #\u505c\u6b62\u6444\u50cf\u5934\u8f93\u51fa\n        sensor.stop()\n        #\u53bb\u521d\u59cb\u5316\u663e\u793a\u8bbe\u5907\n        Display.deinit()\n        #\u91ca\u653e\u5a92\u4f53\u7f13\u51b2\u533a\n        MediaManager.deinit()\n        gc.collect()\n        time.sleep(1)\n        nn.shrink_memory_pool()\n    print("cls_test end")\n    return 0\n\ncls_test()\n'})}),"\n",(0,i.jsx)(e.h3,{id:"525-\u663e\u793a",children:"5.2.5 \u663e\u793a"}),"\n",(0,i.jsx)(e.p,{children:"\u663e\u793a\uff08\u89c6\u9891\u8f93\u51fa\uff0cVO\uff09\u4e0edisplay\u76f8\u5173\uff0c\u672c\u5c0f\u8282\u7b80\u8981\u4ecb\u7ecd\u57fa\u4e8eMicropython\u7684\u663e\u793a\u8bbe\u7f6e\u3001\u8d44\u6e90\u91ca\u653e\u3001\u663e\u793a\u53e0\u52a0\u7684\u6574\u4f53\u6d41\u7a0b\u3002"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"\u663e\u793a\u8bbe\u7f6e\uff1a\u8bbe\u7f6e\u663e\u793a\u5927\u5c0f\uff0c\u683c\u5f0f"}),"\n",(0,i.jsx)(e.li,{children:"\u663e\u793a\u53e0\u52a0\uff1a\u663e\u793a\u75312\u4e2a\u56fe\u5c42\u6784\u6210\uff0c\u5176\u4e2d\u4e0b\u8fb9\u7684\u56fe\u5c42\uff08\u539f\u56fe\u56fe\u5c42\uff09\u76f4\u63a5\u663e\u793a\u6444\u50cf\u5934\u8f93\u51fa\uff0c\u4e0a\u8fb9\u7684\u56fe\u5c42\uff08osd\u56fe\u5c42\uff09\u7528\u4e8e\u753b\u6846\u3001\u753b\u70b9\uff0c\u5199\u6587\u5b57\u7b49\u3002"}),"\n",(0,i.jsx)(e.li,{children:"\u8d44\u6e90\u91ca\u653e\uff1a\u91ca\u653e\u663e\u793a\u76f8\u5173\u8d44\u6e90"}),"\n"]}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u663e\u793a\u793a\u4f8b"}),"\uff1a"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'import os\nfrom media.sensor import * #\u5bfc\u5165camera\u6a21\u5757\uff0c\u4f7f\u7528camera\u76f8\u5173\u63a5\u53e3\nfrom media.display import * #\u5bfc\u5165display\u6a21\u5757\uff0c\u4f7f\u7528display\u76f8\u5173\u63a5\u53e3\nfrom media.media import * #\u5bfc\u5165media\u6a21\u5757\uff0c\u4f7f\u7528meida\u76f8\u5173\u63a5\u53e3\nfrom time import *\nimport time\nimport nncase_runtime as nn #\u5bfc\u5165nn\u6a21\u5757\uff0c\u4f7f\u7528nn\u76f8\u5173\u63a5\u53e3\nimport ulab.numpy as np #\u5bfc\u5165np\u6a21\u5757\uff0c\u4f7f\u7528np\u76f8\u5173\u63a5\u53e3\nimport gc\n\n# \u663e\u793a\u8f93\u51fa\u5927\u5c0f\nDISPLAY_WIDTH = ALIGN_UP(1920, 16)\nDISPLAY_HEIGHT = 1080\n# AI\u83b7\u53d6\u7684RGB888P\u7684\u56fe\u50cf\u5927\u5c0f\nOUT_RGB888P_WIDTH = ALIGN_UP(1280, 16)\nOUT_RGB888P_HEIGH = 720\n\nkmodel_path="/sdcard/app/tests/ai_test_kmodel/veg_cls.kmodel"\nlabels=["\u83e0\u83dc","\u957f\u8304\u5b50","\u7ea2\u82cb\u83dc","\u80e1\u841d\u535c","\u897f\u7ea2\u67ff","\u897f\u84dd\u82b1"]\n\n# softmax\u51fd\u6570\ndef softmax(x):\n    exp_x = np.exp(x - np.max(x))\n    return exp_x / np.sum(exp_x)\n\n\ndef cls_test():\n    print("cls_test start")\n    #\u521d\u59cb\u5316AI2D\n    ai2d = nn.ai2d()\n    # \u8bbe\u7f6eai2d\u7684\u8f93\u5165\u8f93\u51fa\u6570\u636e\u683c\u5f0f\u548c\u6570\u636e\u7c7b\u578b\n    ai2d.set_dtype(nn.ai2d_format.NCHW_FMT,nn.ai2d_format.NCHW_FMT,np.uint8, np.uint8)\n    # \u8bbe\u7f6eresize\u9884\u5904\u7406\n    ai2d.set_resize_param(True, nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel )\n    # \u6784\u5efa\u9884\u5904\u7406,\u53c2\u6570\u4e3a\u8f93\u5165\u8f93\u51fatensor\u7684shape\n    ai2d_builder = ai2d.build([1,3,OUT_RGB888P_HEIGH,OUT_RGB888P_WIDTH], [1,3,224,224])\n    # \u521d\u59cb\u5316kpu\n    kpu=nn.kpu()\n    # \u52a0\u8f7d\u6a21\u578b\n    kpu.load_kmodel(kmodel_path)\n    \n    # \u521d\u59cb\u5316\u5e76\u914d\u7f6esensor\n    sensor = Sensor()\n    sensor.reset()\n    # \u8bbe\u7f6e\u955c\u50cf\n    sensor.set_hmirror(False)\n    # \u8bbe\u7f6e\u7ffb\u8f6c\n    sensor.set_vflip(False)\n    # \u901a\u90530\u76f4\u63a5\u7ed9\u5230\u663e\u793aVO\uff0c\u683c\u5f0f\u4e3aYUV420\n    sensor.set_framesize(width = DISPLAY_WIDTH, height = DISPLAY_HEIGHT)\n    sensor.set_pixformat(PIXEL_FORMAT_YUV_SEMIPLANAR_420)\n    # \u901a\u90532\u7ed9\u5230AI\u505a\u7b97\u6cd5\u5904\u7406\uff0c\u683c\u5f0f\u4e3aRGB888\n    sensor.set_framesize(width = OUT_RGB888P_WIDTH , height = OUT_RGB888P_HEIGH, chn=CAM_CHN_ID_2)\n    sensor.set_pixformat(PIXEL_FORMAT_RGB_888_PLANAR, chn=CAM_CHN_ID_2)\n\t# \u7ed1\u5b9a\u901a\u90530\u7684\u8f93\u51fa\u5230vo\n    sensor_bind_info = sensor.bind_info(x = 0, y = 0, chn = CAM_CHN_ID_0)\n    Display.bind_layer(**sensor_bind_info, layer = Display.LAYER_VIDEO1)\n    # \u8bbe\u7f6e\u4e3aLT9611\u663e\u793a\uff0c\u9ed8\u8ba41920x1080\n    Display.init(Display.LT9611, to_ide = True)\n    \n    #\u521b\u5efaOSD\u56fe\u50cf\n    osd_img = image.Image(DISPLAY_WIDTH, DISPLAY_HEIGHT, image.ARGB8888)\n\n    try:\n        # media\u521d\u59cb\u5316\n        MediaManager.init()\n        # \u542f\u52a8sensor\n        sensor.run()\n        rgb888p_img = None\n        \n        # \u521d\u59cb\u5316\u9884\u5904\u7406\u8f93\u51fa\n        data = np.ones((1,3,224,224),dtype=np.uint8)\n        # numpy.ndarray\u8f6ctensor\n        ai2d_out = nn.from_numpy(data)\n        # \u5c06ai2d\u9884\u5904\u7406\u7684\u8f93\u51fa\u7ed1\u5b9a\u5230kmodel\u7684\u8f93\u5165\u4e0a\uff0c\u5373ai2d\u9884\u5904\u7406\u8f93\u51fa\u548ckpu\u7684\u8f93\u51fa\u5171\u7528\u4e00\u4e2atensor\n        kpu.set_input_tensor(0,ai2d_out)\n        while  True:\n            #\u6355\u83b7\u6444\u50cf\u5934\u6570\u636e\n            rgb888p_img = sensor.snapshot(chn=CAM_CHN_ID_2)\n            # for rgb888planar\n            if rgb888p_img.format() == image.RGBP888:\n                #*************************\u9884\u5904\u7406***********************\n                # image\u8f6cnumpy.ndarray\n                ai2d_input = rgb888p_img.to_numpy_ref()\n                # \u4ecenumpy.ndarray\u521b\u5efatensor\n                ai2d_input_tensor = nn.from_numpy(ai2d_input)\n                # \u6267\u884c\u9884\u5904\u7406\n                ai2d_builder.run(ai2d_input_tensor, ai2d_out)\n                #************************\u6a21\u578b\u63a8\u7406**********************\n                # kpu\u63a8\u7406\n                kpu.run()\n                \n                # \u83b7\u53d6kmodel\u7684\u63a8\u7406\u8f93\u51fatensor,\u8f93\u51fa\u53ef\u80fd\u4e3a\u591a\u4e2a\uff0c\u56e0\u6b64\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u5217\u8868\n                results=[]\n                for i in range(kpu.outputs_size()):\n                    # \u83b7\u53d6kmodel\u7684\u7b2ci\u4e2a\u8f93\u51fa\n                    output_data = kpu.get_output_tensor(i)\n                    # tensor\u8f6cnumpy.ndarray\n                    result = output_data.to_numpy()\n                    # \u52a0\u5165\u5217\u8868\n                    results.append(result)\n                    del output_data\n                #******************\u540e\u5904\u7406********************\n                # softmax+argmax\n                softmax_res=softmax(results[0][0])\n                res_idx=np.argmax(softmax_res)\n                #******************\u663e\u793a*********************\n                # \u7c7b\u522b\u540d\u79f0\n                label=labels[res_idx]\n                # \u7c7b\u522b\u5206\u6570\n                score=softmax_res[res_idx]\n                # \u7ed8\u5236\u6587\u5b57\n                text=label+" "+str(score)\n                # \u6e05\u7406osd_img\n                osd_img.clear()\n                # \u8c03\u7528draw_string_advanced()\u5728(5,5)\u4f4d\u7f6e\uff0c\u7ed8\u5236text\uff0c\u6587\u5b57\u5927\u5c0f\u4e3a32\uff0c\u989c\u8272\u4e3a(0,255,0)\n                osd_img.draw_string_advanced(5,5,32,text,color=(0,255,0))\n                Display.show_image(osd_img, 0, 0, Display.LAYER_OSD3)\n    except Exception as e:\n        print(f"An error occurred during running: {e}")\n    finally:\n        os.exitpoint(os.EXITPOINT_ENABLE_SLEEP)\n        del ai2d_input_tensor\n        del ai2d_out\n        del kpu\n        #\u505c\u6b62\u6444\u50cf\u5934\u8f93\u51fa\n        sensor.stop()\n        #\u53bb\u521d\u59cb\u5316\u663e\u793a\u8bbe\u5907\n        Display.deinit()\n        #\u91ca\u653e\u5a92\u4f53\u7f13\u51b2\u533a\n        MediaManager.deinit()\n        gc.collect()\n        time.sleep(1)\n        nn.shrink_memory_pool()\n    print("cls_test end")\n    return 0\n\ncls_test()\n'})}),"\n",(0,i.jsx)(e.h3,{id:"526-\u8d44\u6e90\u91ca\u653e",children:"5.2.6 \u8d44\u6e90\u91ca\u653e"}),"\n",(0,i.jsx)(e.p,{children:"\u5927\u6838\u5185\u5b58\u5305\u62ec\u4e24\u4e2a\u90e8\u5206\uff0c\u4e00\u4e2a\u662f\u7cfb\u7edf\u5185\u5b58\uff0c\u4e00\u4e2a\u662f GC \u5185\u5b58\uff0c\u524d\u8005\u4e3b\u8981\u7528\u6765\u7ed9\u6a21\u578b\u8fd8\u6709\u7cfb\u7edf\u5185\u7684\u4e00\u4e9b\u529f\u80fd\u4f7f\u7528\uff0c\u5305\u62ec\u6444\u50cf\u5934\u548c\u5c4f\u5e55\u7684\u7f13\u51b2\u533a\u3001kmodel\u53ca\u5176\u8f93\u5165\u8f93\u51fa\u90fd\u6765\u81ea\u8fd9\u91cc\uff08mmz\uff0c\u7528del\u91ca\u653e\uff09\uff1b\u540e\u8005\u662f\u89e3\u6790\u5668\u5c42\u9762\u7533\u8bf7\u7684\u5185\u5b58\uff0c\u53ef\u4ee5\u7ed9\u4ee3\u7801\u7684\u53d8\u91cf\u4f7f\u7528\uff08\u7528gc.collect()\u91ca\u653e\uff09\u3002"}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"1. gc\u8d44\u6e90\u91ca\u653e"}),"\uff1a"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"#classification.py\nimport gc\nimport os\n \ndef func_a():\n    a = []\n    for i in range(10000):\n        a.append(i)\n \nfunc_a()\nprint(gc.mem_free() / 1024 / 1024) #stack mem\nprint(gc.mem_alloc() / 1024 / 1024)\ngc.collect()\nprint(gc.mem_alloc() / 1024 / 1024)\n"})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"2.\u7cfb\u7edf\u5185\u5b58\u91ca\u653e"}),"\uff1a"]}),"\n",(0,i.jsx)(e.p,{children:"kmodel\u6a21\u5757\u90e8\u5206\uff0ckmodel\u7684input_tensor\u3001output_tensor\uff0c\u53ca\u5176\u672c\u8eab\u90fd\u662fmmz\u7533\u8bf7\u7684\u5185\u5b58\uff0c\u9700\u8981\u624b\u52a8\u91ca\u653e"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"del ai2d_input_tensor\ndel ai2d_out\ndel kpu\nnn.shrink_memory_pool()       #\u4ee5\u514d\u6f0f\u6389\u67d0\u4e2adel,\u904d\u5386\u6240\u6709kmodel\u76f8\u5173\u5185\u5b58\uff0c\u5e76\u91ca\u653e\n"})}),"\n",(0,i.jsx)(e.p,{children:"\u6444\u50cf\u5934\u3001\u663e\u793a\u53ca\u5176media\u7f13\u51b2\u533a\u91ca\u653e\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"#\u505c\u6b62\u6444\u50cf\u5934\u8f93\u51fa\nsensor.stop()\n#\u53bb\u521d\u59cb\u5316\u663e\u793a\u8bbe\u5907\nDisplay.deinit()\n#\u91ca\u653e\u5a92\u4f53\u7f13\u51b2\u533a\nMediaManager.deinit()\n"})}),"\n",(0,i.jsx)(e.h3,{id:"527-\u5b8c\u6574\u4ee3\u7801",children:"5.2.7 \u5b8c\u6574\u4ee3\u7801"}),"\n",(0,i.jsxs)(e.p,{children:["\u8fd9\u91cc\u7ed9\u51fa\u5b8c\u6574\u4ee3\u7801\uff0c\u8bf7\u53c2\u8003\u4e0a\u8ff0\u6bcf\u4e00\u6b65\u4ee3\u7801\u4e4b\u95f4\u7684\u53d8\u5316\u3002\u5bf9\u4e8eAI\u5f00\u53d1\u7684\u6b65\u9aa4\u6211\u4eec\u8fdb\u884c\u4e86\u5c01\u88c5\uff0c\u76f8\u5173\u7c7b\u5728/sdcard/app/libs\u4e0b\u9762\uff0c\u5f00\u53d1\u6b65\u9aa4\u8bf7\u53c2\u8003\uff1a",(0,i.jsx)(e.a,{href:"https://developer.canaan-creative.com/k230_canmv/main/zh/example/AI_Demo%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3.html",children:"AI Demo\u8bf4\u660e\u6587\u6863 \u2014 K230 CanMV \u6587\u6863 (canaan-creative.com)"})]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:'import os\nfrom media.sensor import * #\u5bfc\u5165camera\u6a21\u5757\uff0c\u4f7f\u7528camera\u76f8\u5173\u63a5\u53e3\nfrom media.display import * #\u5bfc\u5165display\u6a21\u5757\uff0c\u4f7f\u7528display\u76f8\u5173\u63a5\u53e3\nfrom media.media import * #\u5bfc\u5165media\u6a21\u5757\uff0c\u4f7f\u7528meida\u76f8\u5173\u63a5\u53e3\nfrom time import *\nimport time\nimport nncase_runtime as nn #\u5bfc\u5165nn\u6a21\u5757\uff0c\u4f7f\u7528nn\u76f8\u5173\u63a5\u53e3\nimport ulab.numpy as np #\u5bfc\u5165np\u6a21\u5757\uff0c\u4f7f\u7528np\u76f8\u5173\u63a5\u53e3\nimport gc\n\n# \u663e\u793a\u8f93\u51fa\u5927\u5c0f\nDISPLAY_WIDTH = ALIGN_UP(1920, 16)\nDISPLAY_HEIGHT = 1080\n# AI\u83b7\u53d6\u7684RGB888P\u7684\u56fe\u50cf\u5927\u5c0f\nOUT_RGB888P_WIDTH = ALIGN_UP(1280, 16)\nOUT_RGB888P_HEIGH = 720\n\nkmodel_path="/sdcard/app/tests/ai_test_kmodel/veg_cls.kmodel"\nlabels=["\u83e0\u83dc","\u957f\u8304\u5b50","\u7ea2\u82cb\u83dc","\u80e1\u841d\u535c","\u897f\u7ea2\u67ff","\u897f\u84dd\u82b1"]\n\n# softmax\u51fd\u6570\ndef softmax(x):\n    exp_x = np.exp(x - np.max(x))\n    return exp_x / np.sum(exp_x)\n\n\ndef cls_test():\n    print("cls_test start")\n    #\u521d\u59cb\u5316AI2D\n    ai2d = nn.ai2d()\n    # \u8bbe\u7f6eai2d\u7684\u8f93\u5165\u8f93\u51fa\u6570\u636e\u683c\u5f0f\u548c\u6570\u636e\u7c7b\u578b\n    ai2d.set_dtype(nn.ai2d_format.NCHW_FMT,nn.ai2d_format.NCHW_FMT,np.uint8, np.uint8)\n    # \u8bbe\u7f6eresize\u9884\u5904\u7406\n    ai2d.set_resize_param(True, nn.interp_method.tf_bilinear, nn.interp_mode.half_pixel )\n    # \u6784\u5efa\u9884\u5904\u7406,\u53c2\u6570\u4e3a\u8f93\u5165\u8f93\u51fatensor\u7684shape\n    ai2d_builder = ai2d.build([1,3,OUT_RGB888P_HEIGH,OUT_RGB888P_WIDTH], [1,3,224,224])\n    # \u521d\u59cb\u5316kpu\n    kpu=nn.kpu()\n    # \u52a0\u8f7d\u6a21\u578b\n    kpu.load_kmodel(kmodel_path)\n    \n    # \u521d\u59cb\u5316\u5e76\u914d\u7f6esensor\n    sensor = Sensor()\n    sensor.reset()\n    # \u8bbe\u7f6e\u955c\u50cf\n    sensor.set_hmirror(False)\n    # \u8bbe\u7f6e\u7ffb\u8f6c\n    sensor.set_vflip(False)\n    # \u901a\u90530\u76f4\u63a5\u7ed9\u5230\u663e\u793aVO\uff0c\u683c\u5f0f\u4e3aYUV420\n    sensor.set_framesize(width = DISPLAY_WIDTH, height = DISPLAY_HEIGHT)\n    sensor.set_pixformat(PIXEL_FORMAT_YUV_SEMIPLANAR_420)\n    # \u901a\u90532\u7ed9\u5230AI\u505a\u7b97\u6cd5\u5904\u7406\uff0c\u683c\u5f0f\u4e3aRGB888\n    sensor.set_framesize(width = OUT_RGB888P_WIDTH , height = OUT_RGB888P_HEIGH, chn=CAM_CHN_ID_2)\n    sensor.set_pixformat(PIXEL_FORMAT_RGB_888_PLANAR, chn=CAM_CHN_ID_2)\n\t# \u7ed1\u5b9a\u901a\u90530\u7684\u8f93\u51fa\u5230vo\n    sensor_bind_info = sensor.bind_info(x = 0, y = 0, chn = CAM_CHN_ID_0)\n    Display.bind_layer(**sensor_bind_info, layer = Display.LAYER_VIDEO1)\n    # \u8bbe\u7f6e\u4e3aLT9611\u663e\u793a\uff0c\u9ed8\u8ba41920x1080\n    Display.init(Display.LT9611, to_ide = True)\n    \n    #\u521b\u5efaOSD\u56fe\u50cf\n    osd_img = image.Image(DISPLAY_WIDTH, DISPLAY_HEIGHT, image.ARGB8888)\n\n    try:\n        # media\u521d\u59cb\u5316\n        MediaManager.init()\n        # \u542f\u52a8sensor\n        sensor.run()\n        rgb888p_img = None\n        \n        # \u521d\u59cb\u5316\u9884\u5904\u7406\u8f93\u51fa\n        data = np.ones((1,3,224,224),dtype=np.uint8)\n        # numpy.ndarray\u8f6ctensor\n        ai2d_out = nn.from_numpy(data)\n        # \u5c06ai2d\u9884\u5904\u7406\u7684\u8f93\u51fa\u7ed1\u5b9a\u5230kmodel\u7684\u8f93\u5165\u4e0a\uff0c\u5373ai2d\u9884\u5904\u7406\u8f93\u51fa\u548ckpu\u7684\u8f93\u51fa\u5171\u7528\u4e00\u4e2atensor\n        kpu.set_input_tensor(0,ai2d_out)\n        while  True:\n            #\u6355\u83b7\u6444\u50cf\u5934\u6570\u636e\n            rgb888p_img = sensor.snapshot(chn=CAM_CHN_ID_2)\n            # for rgb888planar\n            if rgb888p_img.format() == image.RGBP888:\n                #*************************\u9884\u5904\u7406***********************\n                # image\u8f6cnumpy.ndarray\n                ai2d_input = rgb888p_img.to_numpy_ref()\n                # \u4ecenumpy.ndarray\u521b\u5efatensor\n                ai2d_input_tensor = nn.from_numpy(ai2d_input)\n                # \u6267\u884c\u9884\u5904\u7406\n                ai2d_builder.run(ai2d_input_tensor, ai2d_out)\n                #************************\u6a21\u578b\u63a8\u7406**********************\n                # kpu\u63a8\u7406\n                kpu.run()\n                \n                # \u83b7\u53d6kmodel\u7684\u63a8\u7406\u8f93\u51fatensor,\u8f93\u51fa\u53ef\u80fd\u4e3a\u591a\u4e2a\uff0c\u56e0\u6b64\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u5217\u8868\n                results=[]\n                for i in range(kpu.outputs_size()):\n                    # \u83b7\u53d6kmodel\u7684\u7b2ci\u4e2a\u8f93\u51fa\n                    output_data = kpu.get_output_tensor(i)\n                    # tensor\u8f6cnumpy.ndarray\n                    result = output_data.to_numpy()\n                    # \u52a0\u5165\u5217\u8868\n                    results.append(result)\n                    del output_data\n                #******************\u540e\u5904\u7406********************\n                # softmax+argmax\n                softmax_res=softmax(results[0][0])\n                res_idx=np.argmax(softmax_res)\n                #******************\u663e\u793a*********************\n                # \u7c7b\u522b\u540d\u79f0\n                label=labels[res_idx]\n                # \u7c7b\u522b\u5206\u6570\n                score=softmax_res[res_idx]\n                # \u7ed8\u5236\u6587\u5b57\n                text=label+" "+str(score)\n                # \u6e05\u7406osd_img\n                osd_img.clear()\n                # \u8c03\u7528draw_string_advanced()\u5728(5,5)\u4f4d\u7f6e\uff0c\u7ed8\u5236text\uff0c\u6587\u5b57\u5927\u5c0f\u4e3a32\uff0c\u989c\u8272\u4e3a(0,255,0)\n                osd_img.draw_string_advanced(5,5,32,text,color=(0,255,0))\n                Display.show_image(osd_img, 0, 0, Display.LAYER_OSD3)\n    except Exception as e:\n        print(f"An error occurred during running: {e}")\n    finally:\n        os.exitpoint(os.EXITPOINT_ENABLE_SLEEP)\n        del ai2d_input_tensor\n        del ai2d_out\n        #\u505c\u6b62\u6444\u50cf\u5934\u8f93\u51fa\n        sensor.stop()\n        #\u53bb\u521d\u59cb\u5316\u663e\u793a\u8bbe\u5907\n        Display.deinit()\n        #\u91ca\u653e\u5a92\u4f53\u7f13\u51b2\u533a\n        MediaManager.deinit()\n        gc.collect()\n        time.sleep(1)\n    print("cls_test end")\n    return 0\n\ncls_test()\n'})})]})}function c(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(p,{...n})}):p(n)}},28453:(n,e,_)=>{_.d(e,{R:()=>o,x:()=>s});var i=_(96540);const t={},r=i.createContext(t);function o(n){const e=i.useContext(r);return i.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:o(n.components),i.createElement(r.Provider,{value:e},n.children)}}}]);