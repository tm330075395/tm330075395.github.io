<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-CanaanK230/part4/In-depthanalysisoftheAIdevelopmentprocess" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">6.深入解析AI开发流程 | 正点原子</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://tm330075395.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://tm330075395.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://tm330075395.github.io/docs/CanaanK230/part4/In-depthanalysisoftheAIdevelopmentprocess"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="6.深入解析AI开发流程 | 正点原子"><meta data-rh="true" name="description" content="本章教学视频：勘智K230开发板教程-深入解析AI开发流程哔哩哔哩bilibili"><meta data-rh="true" property="og:description" content="本章教学视频：勘智K230开发板教程-深入解析AI开发流程哔哩哔哩bilibili"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://tm330075395.github.io/docs/CanaanK230/part4/In-depthanalysisoftheAIdevelopmentprocess"><link data-rh="true" rel="alternate" href="https://tm330075395.github.io/docs/CanaanK230/part4/In-depthanalysisoftheAIdevelopmentprocess" hreflang="en"><link data-rh="true" rel="alternate" href="https://tm330075395.github.io/docs/CanaanK230/part4/In-depthanalysisoftheAIdevelopmentprocess" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="正点原子 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="正点原子 Atom Feed"><link rel="stylesheet" href="/assets/css/styles.ce37c9a8.css">
<script src="/assets/js/runtime~main.fcaa3de9.js" defer="defer"></script>
<script src="/assets/js/main.252b8acf.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">My Site</b></a><a class="navbar__item navbar__link" href="/docs/intro">Tutorial</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/CanaanK230/Userdoc">CanMV-K230教程</a><a href="http://www.alientek.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">正点原子官网<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="http://www.openedv.com/forum.php" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">论坛<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/tm330075395/tm330075395.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/CanaanK230/Userdoc">文档阅读指南</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/1开发板上手指南-1">1.开发板上手指南</a><button aria-label="Expand sidebar category &#x27;1.开发板上手指南&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/2开发环境搭建指南-1">2.开发环境搭建指南</a><button aria-label="Expand sidebar category &#x27;2.开发环境搭建指南&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/3嵌入式应用开发指南-1">3.嵌入式应用开发指南</a><button aria-label="Expand sidebar category &#x27;3.嵌入式应用开发指南&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/category/4ai应用开发指南-1">4.AI应用开发指南</a><button aria-label="Collapse sidebar category &#x27;4.AI应用开发指南&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/CanaanK230/part4/Introduction">1. 介绍</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/CanaanK230/part4/K230Development">2 开发基础</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/CanaanK230/part4/K230AIDemoOverview">3. K230 AI Demo 概述</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/CanaanK230/part4/K230FancyPOCOverview">4. K230 Fancy POC 概述</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/CanaanK230/part4/Getstartedquicklyk230AIInferenceflow">5. 快速入门k230 AI推理流程</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/CanaanK230/part4/In-depthanalysisoftheAIdevelopmentprocess">6.深入解析AI开发流程</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/CanaanK230/part4/Introductiontodevelopmenttools">7. 开发工具简介</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/CanaanK230/part4/Developedusinganonlinecloudtrainingplatform">8. 使用在线云训练平台开发</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/CanaanK230/part4/DevelopedwithAICube">9. 使用AI Cube开发</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/CanaanK230/part4/Source-levelapplicationdevelopment">10. 源码级应用开发</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/CanaanK230/part4/CanCollectorPlus">11. CanCollectorPlus</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/CanaanK230/part4/SDKcorrespondstotheNNCASEversion">12. SDK和nncase版本对应</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/CanaanK230/part4/reference">13. 参考</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/5micropython应用开发指南-1">5.MicroPython应用开发指南</a><button aria-label="Expand sidebar category &#x27;5.MicroPython应用开发指南&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/6系统开发指南-1">6.系统开发指南</a><button aria-label="Expand sidebar category &#x27;6.系统开发指南&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/7sdk-api参考指南-1">7.SDK API参考指南</a><button aria-label="Expand sidebar category &#x27;7.SDK API参考指南&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/8常见问题-1">8.常见问题</a><button aria-label="Expand sidebar category &#x27;8.常见问题&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/4ai应用开发指南-1"><span itemprop="name">4.AI应用开发指南</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">6.深入解析AI开发流程</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>6.深入解析AI开发流程</h1></header>
<blockquote>
<p>本章教学视频：<a href="https://www.bilibili.com/video/BV1um411k7qd/?spm_id_from=333.999.0.0&amp;vd_source=44017c249f4b4c572672eb7cd1c45d17" target="_blank" rel="noopener noreferrer">勘智K230开发板教程-深入解析AI开发流程_哔哩哔哩_bilibili</a></p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="61-概述">6.1 概述<a href="#61-概述" class="hash-link" aria-label="Direct link to 6.1 概述" title="Direct link to 6.1 概述">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1常规ai开发流程">1.常规AI开发流程<a href="#1常规ai开发流程" class="hash-link" aria-label="Direct link to 1.常规AI开发流程" title="Direct link to 1.常规AI开发流程">​</a></h3>
<p>AI开发流程可分为<strong>训练迭代</strong>和<strong>部署上线</strong>两个方面：</p>
<ul>
<li><strong>训练迭代</strong>，即从选定特定数据集、模型结构、损失函数和评价指标入手，通过模型参数的不断优化，致力于实现尽可能接近或超越领域内最先进技术（SOTA）的结果。</li>
<li><strong>部署上线</strong>，即把训练好的模型在特定环境中推理运行的过程，更多关注于部署场景、部署方式、吞吐率和延迟。</li>
</ul>
<p>AI模型通常通过PyTorch、TensorFlow、飞桨等深度学习框架训练完成，但直接使用训练模型推理有两个问题：直接通过这些模型来进行推理需要依赖这些训练框架，用起来比较复杂；不同的硬件的对算子的底层优化方式可能不同，相同模型运行在不同硬件上效率并不高，特别是对延时要求严格的线上场景；由此，经过工业界和学术界数年的探索，AI开发流程有了一条主流的流水线。</p>
<p><img decoding="async" loading="lazy" alt="image-20240228110135631" src="/assets/images/image-20240228110135631-55b9514864188725ce0ecfe7a8ec5217.png" width="532" height="310" class="img_ev3q"></p>
<p>这一条流水线解决了模型部署中的两大问题：使用对接深度学习框架和推理引擎的<strong>中间表示</strong>，开发者不必担心如何在新环境中运行各个复杂的框架；通过中间表示的网络结构优化、推理引擎对运算的底层优化，模型的运算效率大幅提升。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2基于k230的ai开发流程">2.基于K230的AI开发流程<a href="#2基于k230的ai开发流程" class="hash-link" aria-label="Direct link to 2.基于K230的AI开发流程" title="Direct link to 2.基于K230的AI开发流程">​</a></h3>
<p><img decoding="async" loading="lazy" alt="image-20240228-095423" src="/assets/images/20240228-095423-f4b4e51dea44efaf98907c850a07e686.jpg" width="995" height="260" class="img_ev3q"></p>
<p>基于K230的AI开发流程与主流AI开发流程类似，也是先训练，再部署。训练时开发者可以使用<strong>常见深度学习框架</strong>，eg：Pytorch、TensorFlow、飞桨等来定义网络结构，并通过训练确定网络中的参数。之后，模型的结构和参数会被转换成一种只描述网络结构的<strong>中间表示</strong>，eg：onnx、tflite，一些针对网络结构的优化会在中间表示上进行。最终，将中间表示转换成特定的文件格式（kmodel），并利用面向K230的推理引擎（K230Runtime），在K230硬件平台上实现模型的高效运行。</p>
<p>相信大家都对训练过程非常熟悉，因此本文着重介绍部署过程。选择开源repo<a href="https://github.com/biubug6/Pytorch_Retinaface" target="_blank" rel="noopener noreferrer">人脸检测</a>、<a href="https://github.com/Xiaoccer/MobileFaceNet_Pytorch" target="_blank" rel="noopener noreferrer">人脸识别</a>（稍后会详细解释两者含义），这两个开源repo都提供了基于Pytorch训练好的模型；因此，本文以Pytorch模型为例，对AI模型在K230的部署过程展开叙述。</p>
<p><img decoding="async" loading="lazy" alt="pytorch2onnx2kmodel" src="/assets/images/pytorch2onnx2kmodel-76392da03de05db53787a9efdc4f383a.png" width="809" height="191" class="img_ev3q"></p>
<p>对于Pytorch模型来说，从训练好到部署到K230上，会经过三种文件格式：pth/ckpt-&gt;onnx-&gt;kmodel，每转成新的文件格式之后，我们都需要验证转换模型的正确性，以保证成功部署。</p>
<ol>
<li>已经训练好的Pytorch模型，我们会用pth推理脚本验证它的正确性；</li>
<li>验证pth/ckpt没有问题后，转onnx；</li>
<li>转onnx后，验证onnx模型的正确性，需要使用ONNXRuntime来验证，验证流程与Pytorch推理流程类似，包括加载onnx、读取图像/视频流、图像/视频帧预处理、onnx run、后处理、显示结果；</li>
<li>验证onnx没有问题，将其转换为kmodel；</li>
<li>此时使用K230Runtime来验证kmodel的正确性，验证流程与ONNXRuntime推理流程类似，包括加载kmodel、读取图像/视频流、图像/视频帧预处理、kmodel run、后处理、显示结果；</li>
<li>kmodel推理流程正确了，我们AI模型就可以成功部署了。</li>
</ol>
<p>PyTorch模型从训练到在K230上部署经过三个阶段：pth/ckpt验证（通常已验证）、onnx验证（使用ONNXRuntime），最后是kmodel验证（使用K230Runtime）。每个阶段都需要确保模型的正确性，以保证成功部署。验证流程包括加载模型、处理输入数据、运行推理、处理输出结果，最终确保K230上的AI模型部署成功。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="62-环境搭建">6.2 环境搭建<a href="#62-环境搭建" class="hash-link" aria-label="Direct link to 6.2 环境搭建" title="Direct link to 6.2 环境搭建">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="621-快速上手">6.2.1 快速上手<a href="#621-快速上手" class="hash-link" aria-label="Direct link to 6.2.1 快速上手" title="Direct link to 6.2.1 快速上手">​</a></h3>
<p>以Windows环境为例，进行快速上手说明。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6211-canmv-k230接口说明">6.2.1.1 CanMV-K230接口说明<a href="#6211-canmv-k230接口说明" class="hash-link" aria-label="Direct link to 6.2.1.1 CanMV-K230接口说明" title="Direct link to 6.2.1.1 CanMV-K230接口说明">​</a></h4>
<p>说明：CanMV-K230主板电源和串口(与电脑通讯)共用一个TypeC口，如图中⑤所示：</p>
<p><img decoding="async" loading="lazy" alt="canmv_board" src="/assets/images/canmv_board-fe160a6cf0648e8730728da9c3dfd496.png" width="1879" height="807" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6212-canmv-k230连接示例">6.2.1.2 CanMV-K230连接示例<a href="#6212-canmv-k230连接示例" class="hash-link" aria-label="Direct link to 6.2.1.2 CanMV-K230连接示例" title="Direct link to 6.2.1.2 CanMV-K230连接  示例">​</a></h4>
<p>请准备如下硬件，然后按照下图连接：</p>
<ul>
<li>CanMV-K230</li>
<li>TypeC USB线 至少1根</li>
<li>网线一根(可选)</li>
<li>HDMI线一根</li>
<li>SD卡（若是PC没有SD卡插槽，则需要SD卡读卡器）</li>
<li>支持HDMI的显示器</li>
</ul>
<p><img decoding="async" loading="lazy" alt="canmv_connect_demo.png" src="/assets/images/canmv_connect_demo-e32666628c7317088e4516eb3d5d4a8f.png" width="1584" height="944" class="img_ev3q"></p>
<p>按照上图连接之后，需要在SD卡中烧录镜像，下一小节将会介绍如何烧录镜像。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6213-镜像烧录">6.2.1.3 镜像烧录<a href="#6213-镜像烧录" class="hash-link" aria-label="Direct link to 6.2.1.3 镜像烧录" title="Direct link to 6.2.1.3 镜像烧录">​</a></h4>
<p><strong>Linux:</strong></p>
<p>在TF卡插到宿主机之前，输入：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ls -l /dev/sd\*</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>查看当前的存储设备。</p>
<p>将TF卡插入宿主机后，再次输入：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ls -l /dev/sd\*</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>查看此时的存储设备，新增加的就是TF卡设备节点。</p>
<p>假设/dev/sdc就是TF卡设备节点，执行如下命令烧录TF卡：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo dd if=sysimage-sdcard.img of=/dev/sdc bs=1M oflag=sync</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Windows:</strong></p>
<p>Windows下可通过rufus工具对TF卡进行烧录，<a href="http://rufus.ie/downloads/" target="_blank" rel="noopener noreferrer">rufus工具下载地址</a>。</p>
<p>1）将TF卡插入PC，然后启动rufus工具，点击工具界面的”选择”按钮，选择待烧写的固件。</p>
<p><img decoding="async" loading="lazy" alt="rufus-flash-from-file" src="/assets/images/rufus_select-d7997d7eaf258b707f384880887bda39.png" width="1533" height="806" class="img_ev3q"></p>
<p>2）点击“开始”按钮开始烧写，烧写过程有进度条展示，烧写结束后会提示“准备就绪”。</p>
<p><img decoding="async" loading="lazy" alt="rufus-flash" src="/assets/images/rufus_start-0365da8e19357ce420c4bd9ce05c93ba.png" width="591" height="792" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="rufus-sure" src="data:image/png;base64,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" width="682" height="259" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="rufus-warning" src="/assets/images/rufus_warning-02b4676d68826fbaa6733fd16c8bb305.png" width="685" height="284" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="rufus_finish" src="/assets/images/rufus_finish-ee9f7245b8722c20d46c1dd7a35e003d.png" width="593" height="804" class="img_ev3q"></p>
<blockquote>
<p>说明1：<code>sysimage-sdcard.img.gz</code>文件时最好先解压缩，烧录解压缩后的文件。</p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6214-串口驱动安装及上电验证">6.2.1.4 串口驱动安装及上电验证<a href="#6214-串口驱动安装及上电验证" class="hash-link" aria-label="Direct link to 6.2.1.4 串口驱动安装及上电验证" title="Direct link to 6.2.1.4 串口驱动安装及上电验证">​</a></h4>
<p>K230 主板通过USB提供两路调试串口，windows下使用调试串口，需要安装USB转串口驱动程序，驱动<a href="https://ftdichip.com/wp-content/uploads/2021/11/CDM-v2.12.36.4.U-WHQL-Certified.zip" target="_blank" rel="noopener noreferrer">下载链接</a>。</p>
<p>安装驱动之后，如何验证驱动是否安装成功？先将CanMV-K230开发板按照6.2.1.2图示连接，然后将连接电源的type c连接线连接到PC USB口，可以发现两个USB串口设备，如下图所示：</p>
<p><img decoding="async" loading="lazy" alt="image-20240131110201060" src="/assets/images/image-20240131110201060-a50ffac0d3f3b83198161bc13b1690ed.png" width="1125" height="783" class="img_ev3q"></p>
<p>同时HDMI连接的显示器会显示人脸检测结果。</p>
<p><img decoding="async" loading="lazy" alt="image-20240131112814667" src="/assets/images/image-20240131112814667-3bcf7ffdfb6de8c3b44f66c6c11a95c3.png" width="1137" height="759" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6215-串口调试">6.2.1.5 串口调试<a href="#6215-串口调试" class="hash-link" aria-label="Direct link to 6.2.1.5 串口调试" title="Direct link to 6.2.1.5 串口调试">​</a></h4>
<p>安装完驱动之后，<a href="https://mobaxterm.mobatek.net/download.html" target="_blank" rel="noopener noreferrer">下载</a>串口调试工具，安装之后，创建串口窗口。</p>
<p><strong>连接小核</strong>：对于AI Demo来说，小核主要负责网络相关工作。</p>
<p><img decoding="async" loading="lazy" alt="image-20240201141045153" src="/assets/images/image-20240201141045153-b7667be3f7a008ce5748e255cd211ab5.png" width="1920" height="1020" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="image-20240201141234952" src="/assets/images/image-20240201141234952-f11eceb1f1874b32422afe2941e05d9e.png" width="1920" height="1020" class="img_ev3q"></p>
<p>输入root登录，进入小核</p>
<p><strong>连接大核</strong>：大核主要负责和AI相关工作</p>
<p><img decoding="async" loading="lazy" alt="image-20240201141139709" src="/assets/images/image-20240201141139709-b28f0e17c8b5aa2b838927b5a16cd6d4.png" width="1920" height="1020" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="image-20240201140752999" src="/assets/images/image-20240201140752999-497e0f34e97ce76fd979df4a4b0f8881.png" width="1920" height="1020" class="img_ev3q"></p>
<p>按q，回车，退出当前人脸检测demo。</p>
<p><strong>如何重新启动人脸检测demo?</strong></p>
<p><img decoding="async" loading="lazy" alt="image-20240201143138314" src="/assets/images/image-20240201143138314-8ce2133e8fd85f57634ebbeab24d159a.png" width="1154" height="384" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="622-编译环境搭建">6.2.2 编译环境搭建<a href="#622-编译环境搭建" class="hash-link" aria-label="Direct link to 6.2.2 编译环境搭建" title="Direct link to 6.2.2 编译环境搭建">​</a></h3>
<p>编译环境搭建涉及<a href="https://github.com/kendryte/k230_sdk" target="_blank" rel="noopener noreferrer">sdk</a>、<a href="https://github.com/kendryte/nncase" target="_blank" rel="noopener noreferrer">nncase</a>，sdk和nncase有一定的对应关系。我们今天以sdk v1.3.0，nncase v2.7.0为例，进行讲解。k230 sdk和nncase版本的对应关系请参考下述链接：</p>
<p><a href="https://developer.canaan-creative.com/k230/dev/zh/03_other/K230_SDK_nncase%E7%89%88%E6%9C%AC%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB.html" target="_blank" rel="noopener noreferrer"><strong>K230 SDK nncase版本对应关系 — K230 文档 (canaan-creative.com)</strong></a></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6221-docker容器构建">6.2.2.1 docker容器构建<a href="#6221-docker容器构建" class="hash-link" aria-label="Direct link to 6.2.2.1 docker容器构建" title="Direct link to 6.2.2.1 docker容器构建">​</a></h4>
<p>参考：<a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/K230_SDK_%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E.md" target="_blank" rel="noopener noreferrer">K230_SDK_使用说明.md</a></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#以sdk v1.3为例，搭建软件环境</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone -b v1.3 https://github.com/kendryte/k230_sdk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd k230_sdk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">make prepare_sourcecode</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#手动构建名为v1.3_0219的docker image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker build -f tools/docker/Dockerfile -t v1.3_0219 tools/docker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#创建名为v1.3_0219_lj的docker容器</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker run -u root --name v1.3_0219_lj -it -v $(pwd):$(pwd) -v $(pwd)/toolchain:/opt/toolchain -w $(pwd) v1.3_0219 /bin/bash</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>注意：</strong></p>
<p>（1）<code>make prepare_sourcecode</code> 会自动下载Linux和RT-Smart toolchain, buildroot package, AI package等. 请确保该命令执行成功并没有Error产生，下载时间和速度以实际网速为准。</p>
<p>以CanMV-K230开发板为例，手动构建镜像（或直接用官网提供<a href="https://kendryte-download.canaan-creative.com/developer/k230/k230_canmv_sdcard_v1.3_nncase_v2.7.0.img.gz" target="_blank" rel="noopener noreferrer">v1.3 CanMV-K230镜像</a>）：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">make CONF=k230_canmv_defconfig            #生成镜像sysimage-sdcard.img.gz</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#ls k230_sdk/output/k230_canmv_defconfig/images/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">drwxr-xr-x 4 root root       169 Feb 21 14:57 ./</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">drwxr-xr-x 6 root root        79 Feb 20 11:53 ../</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">drwxr-xr-x 5 root root       138 Feb 21 14:57 big-core/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lrwxrwxrwx 1 root root        22 Feb 21 14:57 k230_canmv_sdcard_v1.3_nncase_v2.7.0.img.gz -&gt; sysimage-sdcard.img.gz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">drwxr-xr-x 7 root root      4096 Feb 21 14:57 little-core/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-rw-rw- 1 root root 486556160 Feb 21 14:57 sysimage-sdcard.img</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-rw-rw- 1 root root  56831464 Feb 21 14:57 sysimage-sdcard.img.gz</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6222-nncase安装">6.2.2.2 nncase安装<a href="#6222-nncase安装" class="hash-link" aria-label="Direct link to 6.2.2.2 nncase安装" title="Direct link to 6.2.2.2 nncase安装">​</a></h4>
<p><a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/ai/K230_nncase_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md" target="_blank" rel="noopener noreferrer">nncase</a>是一个为 AI 加速器设计的神经网络编译器, 目前支持的AI设备（ target）有K230/k210/k510等。nncase主要由4部分组成：</p>
<ul>
<li><strong>编译模型APIs(Python)</strong>：用于在PC上将神经网络模型（onnx、tflite等）编译为kmodel，即<strong>生成kmodel</strong>。</li>
<li><strong>模拟器APIs(Python)</strong>：用于在PC上模拟推理kmodel，验证nncase模拟推理结果和原模型（onnx、tflite）的推理结果是否一致，即<strong>Simulator验证</strong>。</li>
<li><strong>KPU运行时APIs(C++)</strong>：用于在AI设备加载kmodel，使用KPU Runtime进行推理， 获取输出数据等，即<strong>上板推理验证</strong>。</li>
<li><strong>AI2D 运行时APIs(C++)</strong>：用于在AI设备配置AI2D的参数，生成相关寄存器配置，执行AI2D计算等；常用AI2D计算包括Affine、Crop、Resize、Padding等，可以加速图像的 预处理操作，即<strong>上板预处理</strong>。</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#以sdk v1.3为例</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#nncase发布版本：https://github.com/kendryte/nncase/releases</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#在docker容器中，查看sdk对应的nncase版本</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cat src/big/nncase/riscv64/nncase/include/nncase/version.h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#安装对应版本nncase</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install -i https://pypi.org/simple nncase==2.7.0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install nncase-kpu==2.7.0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="63-demo构建流程解析">6.3 demo构建流程解析<a href="#63-demo构建流程解析" class="hash-link" aria-label="Direct link to 6.3 demo构建流程解析" title="Direct link to 6.3 demo构建流程解析">​</a></h2>
<p>上一章中，我们展示了人脸检测demo，那如何基于K230开发自己的AI Demo。接下来以人脸检测、人脸识别Demo为例，对基于K230的AI开发流程进行详细的描述。</p>
<p>由于我找的这两个Demo是基于Pytorch训练的，因此整体的流程以Pytorch为例，进行展开。针对Pytorch，基于K230的AI开发流程由训练和部署两个部分组成，其中训练包括Pytorch训练模型，部署包括PyTorch到ONNX转换、使用ONNXRuntime进行推理、ONNX到kmodel转换、使用K230Runtime进行推理。</p>
<ol>
<li><strong>PyTorch训练模型：</strong>
<ul>
<li>使用PyTorch框架定义并训练人脸检测和人脸识别模型。训练完成后，保存模型参数到.pth文件。</li>
</ul>
</li>
<li><strong>PyTorch到ONNX转换：</strong>
<ul>
<li>利用PyTorch工具，将训练好的模型转换为ONNX格式。这一步会针对网络结构进行一些优化。</li>
</ul>
</li>
<li><strong>使用ONNXRuntime进行推理：</strong>
<ul>
<li>在PC上加载ONNX模型，并利用ONNXRuntime进行推理，以验证onnx模型的正确性和性能。ONNXRuntime推理的主要流程包括预处理、运行、后处理。</li>
</ul>
</li>
<li><strong>ONNX到kmodel转换：</strong>
<ul>
<li>利用K230支持的转换工具，将ONNX模型转换为K230可用的kmodel格式。这一步会优化模型以适应K230，生成在K230上能高效运行的模型。</li>
</ul>
</li>
<li><strong>使用K230Runtime进行推理：</strong>
<ul>
<li>在K230上加载kmodel，使用K230Runtime进行推理。这确保模型在K230的运行效果。K230Runtime推理的主要流程包括预处理、运行、后处理。</li>
</ul>
</li>
</ol>
<p><img decoding="async" loading="lazy" src="https://developer.canaan-creative.com/ai_docs/zh/main/_images/pytorch2onnx2kmodel.png" alt="pytorch2onnx2kmodel" class="img_ev3q"></p>
<p>整个流程通过将PyTorch模型经由ONNX中间格式，最终优化为适合K230的kmodel格式，实现了从PC端到K230的无缝部署。从pth/ckpt-&gt;onnx-&gt;kmodel，模型文件有3种文件格式，各种文件格式推理流程一一对应，因此转换完成后，我们需要在对应的推理流程下，验证转换模型的准确性。</p>
<p><a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/" target="_blank" rel="noopener noreferrer">demo构建的完整代码</a>已发布到github上，感兴趣者可以自行下载。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#运行环境：常规pc环境</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── onnx_related               </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ├── onnx_export            #导出onnx</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    │   ├── face_detection_convert_to_onnx.py       #对应3.1.1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    │   ├── face_recognition_convert_to_onnx.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    │   └── readme.txt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    └── onnx_inference         #onnx推理流程</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ├── face_detection     #人脸检测onnx推理流程   #对应3.1.2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        └── face_recognition   #人脸识别onnx推理流程</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 编译环境：k230 docker编译环境，运行环境：K230开发板</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── kmodel_related     </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── kmodel_export         #导出kmodel，</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │   ├── build_model.sh    #生成kmodel脚本</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │   ├── face_detection    #对应3.1.3+3.1.4.1（两者都是python写的，为了写起来简单，把两者放在一起，逻辑上放到3.1.4更好）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │   ├── face_recognition</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │   ├── k230_kmodel       #生成kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │   └── k230_utils        #生成其它辅助文件，bin、图片等</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └── kmodel_inference      #kmodel推理             </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│       ├── build_app.sh      #生成可执行文件脚本</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│       ├── cmake</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│       ├── CMakeLists.txt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│       ├── face_detection    #人脸检测kmodel推理流程，对应3.1.4.2+3.1.4.3（两者都是c++写的）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│       ├── face_recognition  #人脸识别kmodel推理流程</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│       ├── k230_bin          #生成的可执行文件、kmodel，上板执行脚本等</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│       ├── main_nncase       #kmodel上板验证工具</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│       ├── shell</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│       └── test_demo  </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="631-人脸检测demo">6.3.1 人脸检测demo<a href="#631-人脸检测demo" class="hash-link" aria-label="Direct link to 6.3.1 人脸检测demo" title="Direct link to 6.3.1 人脸检测demo">​</a></h3>
<p>人脸检测是指对于任意一幅给定的图像，采用一定的策略对其进行搜索以确定其中是否含有人脸，如果有则返回人脸检测框、五官关键点。参考链接：<a href="https://github.com/biubug6/Pytorch_Retinaface" target="_blank" rel="noopener noreferrer">biubug6/Pytorch_Retinaface</a></p>
<p><img decoding="async" loading="lazy" alt="face_detection_result.jpg" src="/assets/images/face_detection_result-840ef2b05b98206ba13a6efd4c299979.jpg" width="1024" height="624" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6311-pytorch到onnx转换">6.3.1.1 PyTorch到ONNX转换<a href="#6311-pytorch到onnx转换" class="hash-link" aria-label="Direct link to 6.3.1.1 PyTorch到ONNX转换" title="Direct link to 6.3.1.1 PyTorch到ONNX转换">​</a></h4>
<p>选择人脸检测模型时，一般应选择轻量化的模型，backbone一般小于resnet50参数量较好。因此我们选择基于MobileNetV1的RetinaFace 作为人脸检测模型。</p>
<ul>
<li>加载pth或ckpt模型到cpu</li>
<li>构建随机模型输入</li>
<li>导出onnx模型</li>
</ul>
<p><strong>注</strong>：pth、onnx都支持动态输入，而K230的模型暂时不支持动态输入，所以导出onnx时，onnx输入shape固定。</p>
<p><img decoding="async" loading="lazy" alt="image-20240116180710999" src="/assets/images/image-20240116180710999-57d192c3d18e775d7a6405d763ad51a1.png" width="1351" height="749" class="img_ev3q"></p>
<p><strong>执行步骤：</strong></p>
<p>将<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/" target="_blank" rel="noopener noreferrer">代码</a>clone到pc上，安装依赖库，执行转onnx脚本。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd K230_AI_Demo_Development_Process_Analysis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd onnx_related/onnx_export</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/biubug6/Pytorch_Retinaface</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cp face_detection_convert_to_onnx.py Pytorch_Retinaface/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd Pytorch_Retinaface</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#根据Pytorch_Retinaface说明文档下载预训练模型</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python face_detection_convert_to_onnx.py</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6312-使用onnxruntime进行推理">6.3.1.2 使用ONNXRuntime进行推理<a href="#6312-使用onnxruntime进行推理" class="hash-link" aria-label="Direct link to 6.3.1.2 使用ONNXRuntime进行推理" title="Direct link to 6.3.1.2 使用ONNXRuntime进行推理">​</a></h4>
<p>为了验证onnx正确性，我们需要使用ONNXRuntime对onnx进行推理，推理时保证读取图片、预处理、run、后处理、显示结果与pth/ckpt的推理流程一致。</p>
<p><img decoding="async" loading="lazy" alt="pytorch2onnx.png" src="/assets/images/pytorch2onnx-d701975b88e58de7fab601d8e6e6061d.png" width="819" height="191" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63121-读取图像">6.3.1.2.1 读取图像<a href="#63121-读取图像" class="hash-link" aria-label="Direct link to 6.3.1.2.1 读取图像" title="Direct link to 6.3.1.2.1 读取图像">​</a></h5>
<p><img decoding="async" loading="lazy" alt="image-20240116182914501" src="/assets/images/image-20240116182914501-a0a655500852bf26e82bd652f1281d40.png" width="269" height="310" class="img_ev3q"></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#ori_img（1024,624,3）,opencv读入图片的默认格式为hwc,bgr</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ori_img = cv2.imread(&#x27;bin/test.jpg&#x27;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63122-图像预处理">6.3.1.2.2 图像预处理<a href="#63122-图像预处理" class="hash-link" aria-label="Direct link to 6.3.1.2.2 图像预处理" title="Direct link to 6.3.1.2.2 图像预处理">​</a></h5>
<p>预处理构建（常用的方法：padding_resize，crop_resize，resize，affine、normalization）：参考train.py，test.py、predict.py、现成的onnx推理脚本。</p>
<p><strong>构建人脸检测预处理代码：</strong></p>
<p><img decoding="async" loading="lazy" alt="image-20240116181759199" src="/assets/images/image-20240116181759199-af7b64514a4aa63460f577c0d6e9146e.png" width="1538" height="902" class="img_ev3q"></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#face_detector.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def pre_process(self,ori_img):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_ori_img = max(ori_img.shape[1], ori_img.shape[0])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    self.scale = [max_ori_img] * 4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    self.scale1 = [max_ori_img] * 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # (1) padding：将原图padding为正方形，pad_img(1024,1024,3)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pad_img = pad_to_square(ori_img,self.normalize_mean,True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # (2) resize+tranpose+normalization：将padding之后的图像缩放到640，hwc转chw，并归一化，resize_img(3,640,640)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    resize_img = resize_subtract_mean(pad_img,self.in_size,self.normalize_mean)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # (3) dequantize：将缩放的图像转换为float32,resize_img_float(3,640,640)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    resize_img_float = np.float32(resize_img)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    #（4）3维扩张为4维：input_data(1,3,640,640)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_data = np.expand_dims(resize_img_float, 0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return input_data</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>**参考：（与pth预处理流程一致）**人脸检测预处理代码参考train.py（k230模型的输入shape目前只支持固定输入，训练时都是批量固定输入的，因此可以借鉴）中调用的预处理，去掉不适合推理使用的crop、distort、mirror（数据增强），只留下onnx推理时必要的pad_to_square、resize_subact_mean处理，保证onnx与pth预处理一致。</p>
<p><img decoding="async" loading="lazy" alt="image-20240116184823495" src="/assets/images/image-20240116184823495-973d390bc49a523e6e0f5fce8ef75846.png" width="1540" height="1073" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63123-onnx-run">6.3.1.2.3 onnx run<a href="#63123-onnx-run" class="hash-link" aria-label="Direct link to 6.3.1.2.3 onnx run" title="Direct link to 6.3.1.2.3 onnx run">​</a></h5>
<p>将预处理好的数据，喂给模型，得到onnx推理结果</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#onnx_model.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def forward(self, image_tensor):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &#x27;&#x27;&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    image_tensor = image.transpose(2, 0, 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    image_tensor = image_tensor[np.newaxis, :]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    onnx_session.run([output_name], {input_name: x})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    :param image_tensor:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    :return:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &#x27;&#x27;&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_feed = self.get_input_feed(image_tensor)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    output = self.sess.run(self.out_names, input_feed=input_feed)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#face_detector.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loc,conf,landms = self.model.forward(input_data)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63124-后处理">6.3.1.2.4 后处理<a href="#63124-后处理" class="hash-link" aria-label="Direct link to 6.3.1.2.4 后处理" title="Direct link to 6.3.1.2.4 后处理">​</a></h5>
<p>后处理构建（常用的方法：softmax、loc解码、nms等）：参考test.py或predict.py等测试脚本、现成的onnx推理脚本。</p>
<p><strong>构建人脸检测后处理代码</strong>：包括解码、nms等，由于后处理较多，我们只截取部分代码进行说明，具体实现参考<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/" target="_blank" rel="noopener noreferrer">源码</a>。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#face_detector.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def post_process(self,loc,conf,landms):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    loc, conf, landms = loc[0],conf[0],landms[0]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    boxes = decode(loc, self.priors_numpy, self.cfg[&#x27;variance&#x27;])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    boxes = boxes * self.scale / 1                     #右、下padding</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ......</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>**参考：**人脸检测repo的detect.py，对模型输入结果：loc（检测框）、conf（得分）、landms（关键点）进行后处理，进而得到人脸检测框、得分、五官点。 <img decoding="async" loading="lazy" alt="image-20240116190012087" src="/assets/images/image-20240116190012087-664bbd7bfb5c80ce4099444172b8c9c2.png" width="1493" height="686" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63125-显示结果">6.3.1.2.5 显示结果<a href="#63125-显示结果" class="hash-link" aria-label="Direct link to 6.3.1.2.5 显示结果" title="Direct link to 6.3.1.2.5 显示结果">​</a></h5>
<p>显示结果：将后处理之后的结果画到原图，具体实现参考<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/" target="_blank" rel="noopener noreferrer">源码</a>。</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63126-编译执行">6.3.1.2.6 编译执行<a href="#63126-编译执行" class="hash-link" aria-label="Direct link to 6.3.1.2.6 编译执行" title="Direct link to 6.3.1.2.6 编译执行">​</a></h5>
<p>将<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/" target="_blank" rel="noopener noreferrer">源码</a>clone到pc上，安装依赖库，执行人脸检测推理流程，若是检测效果正确，则说明使用ONNXRuntime推理人脸检测的流程是正确的，转换的onnx也是正确的。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#若已下载code过，请忽略clone步骤</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd K230_AI_Demo_Development_Process_Analysis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd onnx_related/onnx_inference/face_detection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python face_detector.py</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="face_detection_result.jpg" src="/assets/images/face_detection_result-1721612048481-49-840ef2b05b98206ba13a6efd4c299979.jpg" width="1024" height="624" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6313-onnx到kmodel转换">6.3.1.3 ONNX到kmodel转换<a href="#6313-onnx到kmodel转换" class="hash-link" aria-label="Direct link to 6.3.1.3 ONNX到kmodel转换" title="Direct link to 6.3.1.3 ONNX到kmodel转换">​</a></h4>
<p>人脸检测onnx模型经过nncase编译之后，可以生成在k230上推理的模型kmodel，生成kmodel需要调用nncase的<strong>编译模型APIs(Python)</strong>。</p>
<p><strong>编译模型API</strong>的接口如下图所示。若是在github无法看到<a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/ai/K230_nncase_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md" target="_blank" rel="noopener noreferrer">K230_nncase_开发指南.md</a>文档中目录结构，可以下载到本地，使用Typora工具打开。</p>
<p><img decoding="async" loading="lazy" src="https://developer.canaan-creative.com/ai_docs/zh/main/_images/image-20240221130451008.png" alt="image-20240221130451008" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63131-配置生成kmodel参数">6.3.1.3.1 配置生成kmodel参数<a href="#63131-配置生成kmodel参数" class="hash-link" aria-label="Direct link to 6.3.1.3.1 配置生成kmodel参数" title="Direct link to 6.3.1.3.1 配置生成kmodel参数">​</a></h5>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="1编译参数compileoptions">1.编译参数：CompileOptions<a href="#1编译参数compileoptions" class="hash-link" aria-label="Direct link to 1.编译参数：CompileOptions" title="Direct link to 1.编译参数：CompileOptions">​</a></h6>
<p>编译参数包括编译目标参数、预处理参数、后处理参数，编译目标参数指定编译目标, 如’cpu’, ‘k230’；常用预处理参数由Transpose参数、SwapRB参数、Dequantize参数、Normalization参数构成；后处理参数目前只支持Transpose参数。</p>
<table><thead><tr><th>参数类别</th><th>参数名称</th></tr></thead><tbody><tr><td>编译目标参数</td><td>target</td></tr><tr><td>预处理参数</td><td>input_shape、input_layout、 swapRB、input_type、input_range、mean、std等</td></tr><tr><td>后处理参数</td><td>output_layout</td></tr></tbody></table>
<p><strong>编译目标参数：</strong></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 指定编译目标, 如&#x27;cpu&#x27;, &#x27;k230&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.target = args.target</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>（1）target = “cpu”，生成cpu上推理的kmodel，此时不进行量化；</p>
<p>（2）target = “k230”，生成在k230(kpu)上推理的kmodel，此时模型进行量化（默认uint8量化）；</p>
<p><strong>预处理参数</strong>：由于预处理参数比较复杂，接下来我们着重介绍下常用预处理参数。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 是否开启前处理，默认为False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.preprocess = True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>（1）预处理参数（preprocess = False时，不进行任何预处理，kmodel ≈ onnx）</p>
<p>（2）预处理参数（preprocess = True时，kmodel ≈ 预处理 + onnx，此时kmodel包含设置的预处理，这些预处理会在KPU计算，KPU计算较快，因此最好将尽可能多预处理放到kmodel上）</p>
<table><thead><tr><th>预处理操作类型</th><th>相关参数</th></tr></thead><tbody><tr><td>Transpose</td><td>input_shape、input_layout</td></tr><tr><td>SwapRB</td><td>swapRB</td></tr><tr><td>Dequantize</td><td>input_type、input_range</td></tr><tr><td>Normalization</td><td>mean、std</td></tr></tbody></table>
<p>【onnx输入数据】的格式决定了【新的输入】的格式；</p>
<p>【kmodel实际输入】的格式决定了【kmodel输入】的格式；</p>
<p><img decoding="async" loading="lazy" alt="image-20240220135401913" src="/assets/images/image-20240220135401913-58dc8bad06cad4f090c2fc22a3295bd9.png" width="717" height="463" class="img_ev3q"></p>
<p><strong>Transpose参数</strong>：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 指定输入数据的shape，input_shape的layout需要与input layout保持一致</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.input_shape = [1, 3, 640, 640]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 当按照字符串（`&quot;NHWC&quot;`、`&quot;NCHW&quot;`）形式配置 `input_layout`时，表示新的输入数据的layout</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.input_layout = &quot;NCHW&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>
<p>相关参数：</p>
<ul>
<li><code>input_shape</code>：  输入数据的shape，input_shape的layout需要与<code>input_layout</code>保持一致；<strong>当 preprocess为 True时，必须指定</strong>。</li>
<li><code>input_layout</code>：支持字符串（<code>&quot;NHWC&quot;</code>、<code>&quot;NCHW&quot;</code>）和index。当按照字符串（<code>&quot;NHWC&quot;</code>、<code>&quot;NCHW&quot;</code>）形式配置 <code>input_layout</code>时，表示新的输入数据的layout；当按照index形式配置 <code>input_layout</code>时，表示输入数据会按照当前配置的 <code>input_layout</code>进行数据转置，即 <code>input_layout</code>为 <code>Transpose</code>的 <code>perm</code>参数；<strong>当 preprocess为 True时，必须指定</strong>。</li>
</ul>
</li>
<li>
<p>分析说明（以字符串配置格式为例）：</p>
<ul>
<li>
<p>新的输入layout与input_layout一致；新的输入layout与onnx输入layout一致；<strong>因此input_layout与onnx输入layout一致</strong>；</p>
</li>
<li>
<p>当input_layout与kmodel输入layout一致时，kmodel输入经过transpose之后，生成的新的输入仍是与kmodel输入layout一致；</p>
</li>
<li>
<p>当input_layout与kmodel输入layout不一致时，kmodel输入经过transpose之后，变成与input_layout一致的新的输入。</p>
</li>
<li>
<p><img decoding="async" loading="lazy" alt="image-20240220135401914" src="/assets/images/image-20240220135401914-a0ef63a5bc0e30e3d8e56809580fb957.png" width="603" height="270" class="img_ev3q"></p>
<p><strong>实际推理时</strong>，人脸检测onnx输入layout：<code>NCHW</code>，shape是<code>[1, 3, 640, 640]</code>，所以<code>input_layout = &quot;NCHW&quot;,input_shape=[1, 3, 640, 640]</code></p>
</li>
</ul>
</li>
</ul>
<p><strong>SwapRB参数：</strong></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.swapRB = True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>相关参数：<!-- -->
<ul>
<li><code>swapRB</code>：是否在 <code>channel</code>维度反转数据，默认为False</li>
</ul>
</li>
<li>分析说明：<!-- -->
<ul>
<li><strong>实际推理时</strong>，人脸检测kmodel输入：<code>rgb</code>、onnx输入（新的输入）：<code>bgr</code>，两者顺序<strong>不同</strong>，所以需要反转<code>channel</code>维度，故<code>swapRB = True</code></li>
</ul>
</li>
</ul>
<p><strong>Dequantize参数：</strong></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 当preprocess为 True时，必须指定为&quot;uint8&quot;或者&quot;float32&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.input_type = &#x27;uint8&#x27;            </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># input_type=‘uint8’时反量化有效，反量化之后的数据范围</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.input_range = [0, 255]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>相关参数：<!-- -->
<ul>
<li><code>input_type</code>：与kmodel实际输入数据类型一致；<strong>当 preprocess为 True时，必须指定为”uint8”或者”float32</strong>。</li>
<li><code>input_range</code>：指定输入数据反量化后的<strong>浮点数范围</strong>；<strong>当 <code>preprocess</code>为 <code>True</code>且 <code>input_type</code>为 <code>uint8</code>时，必须指定</strong>。</li>
</ul>
</li>
<li>分析说明：<!-- -->
<ul>
<li>若kmodel <code>input_type</code>为float32，不进行反量化</li>
<li>若kmodel <code>input_type</code>为uint8，range为[0,255]，当<code>input_range</code>为[0,255]时，则反量化的作用只是进行类型转化，将uint8的数据转化为float32</li>
<li>若kmodel <code>input_type</code>为uint8，range为[0,255]，当<code>input_range</code>为[0,1]，则反量化会将定点数转化为[0.0,1.0]的浮点数</li>
<li><strong>实际推理时</strong>，人脸检测kmodel实际输入从sensor中获取，数据类型为<code>uint8</code>，所以<code>input_type = &#x27;uint8&#x27;,input_range = [0,255]或[0,1]均可</code></li>
</ul>
</li>
</ul>
<p><strong>Normalization参数</strong>：</p>
<ul>
<li>相关参数<!-- -->
<ul>
<li><code>mean</code>：预处理标准 化参数均值，默认为[0,0,0]</li>
<li><code>std</code>：预处理标准化参数方差，默认为[1,1,1]</li>
</ul>
</li>
<li><img decoding="async" loading="lazy" alt="image-20240220135401915" src="/assets/images/image-20240220135401915-a3419867ac1d24bd3438d09ca23ff3cd.png" width="442" height="477" class="img_ev3q"></li>
<li><strong>实际推理时</strong>，人脸检测onnx的<code>mean = [104,117,123],std = [1, 1, 1]</code>；显然上图左边的设置更加简洁，人脸检测kmodel的<code>input_range = [0,255],mean = [104,117,123],std = [1, 1, 1]</code>。</li>
</ul>
<p><strong>后处理参数</strong>：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 后处理</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.output_layout = &quot;NCHW&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>相关参数：<!-- -->
<ul>
<li><code>output_layout</code>：指定输出数据的layout, 如’NCHW’, ‘NHWC’，默认为“”，不进行transpose。</li>
</ul>
</li>
</ul>
<p>与预处理参数的<code>input_layout</code>类似，若模型本身输出（oldKmodelOutput）的layout与<code>output_layout</code>相同，则transpose之后，newKmodelOutput layout仍与oldKmodelOutput layout一致；若模型本身输出（oldKmodelOutput）的layout与<code>output_layout</code>不同，则transpose之后，newKmodelOutput layout将变为与<code>output_layout</code>一致。</p>
<p><img decoding="async" loading="lazy" alt="image-20240304191018189" src="/assets/images/image-20240304191018189-be16f3a88b1aa61c7aaa9250018026f4.png" width="564" height="318" class="img_ev3q"></p>
<p><strong>生成的人脸检测kmodel：</strong></p>
<p><img decoding="async" loading="lazy" alt="image-2024030135401913" src="/assets/images/image-2024030135401913-d4694b8c7dbef2953a49509abc93b0e1.png" width="318" height="612" class="img_ev3q"></p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="2导入参数importoptions">2.导入参数：ImportOptions<a href="#2导入参数importoptions" class="hash-link" aria-label="Direct link to 2.导入参数：ImportOptions" title="Direct link to 2.导入参数：ImportOptions">​</a></h6>
<p>ImportOptions类, 用于配置nncase导入选项，很少单独设置，使用默认参数即可。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 2. 设置导入参数，import_options（一般默认即可）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import_options = nncase.ImportOptions()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_file = onnx_simplify(args.model, dump_dir)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_content = read_model_file(model_file)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compiler.import_onnx(model_content, import_options)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="3训练后量化参数ptqtensoroptions">3.训练后量化参数：PTQTensorOptions<a href="#3训练后量化参数ptqtensoroptions" class="hash-link" aria-label="Direct link to 3.训练后量化参数：PTQTensorOptions" title="Direct link to 3.训练后量化参数：PTQTensorOptions">​</a></h6>
<p>训练后量化参数(Post Training Quantization，PTQ)，PTQ是一种通过将模型权重从float32映射uint8或int16方法，保持模型的准确性的同时，减少推理所需的计算资源；当target = “k230”，PTQ是必选参数，默认uint8量化。</p>
<p>使用uint8量化可以满足人脸检测精度要求，故使用默认uint8量化；校正集个数为100；假设使用100个校正集生成kmodel的时间很久，可以适当的减少校正集。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 3. 设置训练后量化参数，ptq_options</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options = nncase.PTQTensorOptions()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.samples_count = 100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.set_tensor_data(generate_data(input_shape, ptq_options.samples_count, args.dataset))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compiler.use_ptq(ptq_options)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63132-校正集准备">6.3.1.3.2 校正集准备<a href="#63132-校正集准备" class="hash-link" aria-label="Direct link to 6.3.1.3.2 校正集准备" title="Direct link to 6.3.1.3.2 校正集准备">​</a></h5>
<p>因为生成kmodel时，使用了后处理量化，因此需要准备校正集。使用少量校正集计算量化因子，可以快速得到量化模型。使用该量化模型进行预测，可在保证模型准确性的同时，减少计算量、降低计算内存、减小模型大小。</p>
<p><strong>校正集</strong>一般选用<strong>验证集</strong>的<strong>100张图片</strong>即可，<a href="https://github.com/biubug6/Pytorch_Retinaface" target="_blank" rel="noopener noreferrer">人脸检测模型</a>的<strong>验证集</strong><code>WIDER_val</code>，故选用<code>WIDER_val</code>的100张图像作为校正集。</p>
<p><strong>注：</strong></p>
<p>（1）若是kmodel<strong>生成时间很久</strong>或者验证集数据很少，也可尝试少于100个数据</p>
<p>（2）<code>generate_data</code>函数，生成的数据格式，需要<strong>尽量保证</strong>与实际推理时喂给kmodel的数据格式一致，否则会导致生成kmodel有问题。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">def generate_data(shape, batch, calib_dir):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    #获取所有校正集图片名称</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    img_paths = [os.path.join(calib_dir, p) for p in os.listdir(calib_dir)]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for i in range(batch):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        assert i &lt; len(img_paths), &quot;calibration images not enough.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        #生成的数据需要做的预处理 ≈ onnx预处理 - 根据预处理参数设置的，包含在kmodel中预处理</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        #onnx预处理：bgr,padding,reisze,transpose,normalization,dequantize,3维度转4维度</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        #kmodel中包含的预处理：rgb-&gt;bgr,dequantize,normalization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        img_data = Image.open(img_paths[i]).convert(&#x27;RGB&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        #为了省事，这里没有用padding</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        img_data = img_data.resize((shape[3], shape[2]), Image.BILINEAR)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        img_data = np.asarray(img_data, dtype=np.uint8)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        img_data = np.transpose(img_data, (2, 0, 1))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        data.append([img_data[np.newaxis, ...]])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return np.array(data)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_shape = [1, 3, 640, 640]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">......</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options = nncase.PTQTensorOptions()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ptq_options.samples_count = 100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 校正集数据预处理，将原图处理为kmodel需要数据</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ptq_options.set_tensor_data(generate_data(input_shape, ptq_options.samples_count, args.dataset))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 使用100个校准数据计算量化因子</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    compiler.use_ptq(ptq_options)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">......</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63133-生成kmodel">6.3.1.3.3 生成kmodel<a href="#63133-生成kmodel" class="hash-link" aria-label="Direct link to 6.3.1.3.3 生成kmodel" title="Direct link to 6.3.1.3.3 生成kmodel">​</a></h5>
<p>生成人脸检测kmodel完整代码示例：<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/blob/main/kmodel_related/kmodel_export/face_detection/mobile_retinaface_data_100_640.py" target="_blank" rel="noopener noreferrer">mobile_retinaface_data_100_640.py</a></p>
<p><strong>生成环境</strong>：6.2.2 构建的编译环境</p>
<p><strong>生成步骤</strong>：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd src/reference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#若已下载code过，请忽略clone步骤</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd K230_AI_Demo_Development_Process_Analysis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd kmodel_related/kmodel_export</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./build_model.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r--r-- 1 root root  715216 Feb 28 16:08 face_detect_640.kmodel     #人脸检测kmodel</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>温馨提示</strong>：生成kmodel时需要配置多个参数，正确理解和配置这些参数是确保成功生成kmodel的<strong>关键</strong>。我们深知参数配置的复杂性，但是为了给用户提供正确的参数配置，我们一次性提供了所有正确的配置，但对于不太熟悉kmodel生成的用户来说，仍然存在配置错误的可能性。错误的参数配置将导致生成的kmodel存在问题。</p>
<p>为了帮助大家更好地理解这一过程，<strong>建议</strong>尝试修改配置参数为不同值，观察生成的kmodel的变化和对最终推理结果的影响。通过这样的实践，可以更深入地理解各参数的作用和相互关系。这种方式将使用户更熟悉kmodel生成的流程，有助于更准确地配置参数以获得所需的结果。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6314-使用k230runtime进行推理">6.3.1.4 使用K230Runtime进行推理<a href="#6314-使用k230runtime进行推理" class="hash-link" aria-label="Direct link to 6.3.1.4 使用K230Runtime进行推理" title="Direct link to 6.3.1.4 使用K230Runtime进行推理">​</a></h4>
<p>为了验证kmodel正确性，我们需要使用K230Runtime对kmodel进行推理，推理时保证读取图片、预处理、run、后处理、显示结果与onnx的对应流程一致。</p>
<p><img decoding="async" loading="lazy" alt="onnx2kmodel.png" src="/assets/images/onnx2kmodel-35ba62e24e4606c98d1c3f2deef8f265.png" width="819" height="201" class="img_ev3q"></p>
<p>由于K230开发板调试起来比较复杂，因此我们提供一些辅助工具，并分享相关经验来帮助用户验证K230端推理的正确性。由于推理过程中，主要的部分是run、预处理、  后处理，接下来我们分别对这3个部分调试的常用方法进行说明。</p>
<p><strong>run：</strong></p>
<ul>
<li>Simulator：在PC端模拟kmodel在k230的推理过程，用于对比kmodel和onnx输出是否一致；</li>
<li>main_nncase：在K230端推理kmodel，用于对比模拟推理kmodel与实际推理kmodel结果是否一致；</li>
<li>若是两者都没有问题，则说明生成kmodel是正确的。</li>
</ul>
<p><strong>预处理：</strong></p>
<ul>
<li>原图预处理之后，dump预处理后的图像，查看预处理是否正确。</li>
</ul>
<p><strong>后处理：</strong></p>
<ul>
<li>在Simulator正确的情况下，将Simulator输出bin文件作为kmodel输出，喂给后处理，看后处理结果是否与ONNX后处理结果是否一致。</li>
</ul>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63141-使用simulator验证kmodel">6.3.1.4.1 使用Simulator验证kmodel<a href="#63141-使用simulator验证kmodel" class="hash-link" aria-label="Direct link to 6.3.1.4.1 使用Simulator验证kmodel" title="Direct link to 6.3.1.4.1 使用Simulator验证kmodel">​</a></h5>
<p>Simulator：在PC端模拟kmodel在k230的推理过程，用于对比kmodel和onnx输出是否一致；</p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="1生成inputbin">1.生成input.bin<a href="#1生成inputbin" class="hash-link" aria-label="Direct link to 1.生成input.bin" title="Direct link to 1.生成input.bin">​</a></h6>
<p>在使用Simulator验证kmodel之前，需要先准备好输入文件。由于kmodel包括部分预处理，因此对于同一张图片，需要分别利用不同预处理生成<code>onnx_input.bin、kmodel_input.bin</code>。</p>
<table><thead><tr><th>名称</th><th>onnx_input.bin构建流程</th><th>kmodel_input.bin构建流程</th></tr></thead><tbody><tr><td><strong>源-&gt;目标</strong></td><td><strong>（uint8,hwc,bgr-&gt;float32,nchw,bgr）</strong></td><td><strong>（uint8,hwc,bgr-&gt;uint8,nchw,rgb）</strong></td></tr><tr><td>原图</td><td>（1024,624,3），uint8，hwc，bgr</td><td>（1024,624,3），uint8，hwc，bgr</td></tr><tr><td>padding</td><td>（1024,1024,3）, uint8，hwc，bgr</td><td>（1024,1024,3）, uint8，hwc，bgr</td></tr><tr><td>resize</td><td>（640,640,3）, uint8，hwc，bgr</td><td>（640,640,3）, uint8，hwc，bgr</td></tr><tr><td>dequantize</td><td>（640,640,3）, float32，hwc，bgr</td><td>—</td></tr><tr><td>normalization</td><td>（640,640,3），float32，hwc，bgr</td><td>—</td></tr><tr><td>bgr-&gt;rgb</td><td>—</td><td>（640,640,3）, uint8，hwc，rgb</td></tr><tr><td>transpose</td><td>（3,640,640），float32，chw，bgr</td><td>（3,640,640），uint8，chw，rgb</td></tr><tr><td>维度扩展（非必须）</td><td>（1,3,640,640），float32，chw，bgr</td><td>（1,3,640,640），uint8，chw，rgb</td></tr></tbody></table>
<p><strong>注</strong>：由于生成的kmodel中包含部分预处理，生成kmodel_input.bin需要的预处理 ≈ 生成onnx_input.bin需要的预处理 - kmodel中包含的预处理（人脸检测kmodel中预处理transpose、dequantize、normalization、swapRB）</p>
<p>（1）维度扩展可以省略（读取时bin文件可以用reshape，生成bin时可以省略）。</p>
<p>（2）kmodel_input.bin为什么无需进行dequantize、normalization操作？dequantize、normalization已放到kmodel中。</p>
<p>（3）为什么需要生成kmodel_input.bin需要bgr-&gt;rgb？生成人脸检测kmode时，由于实际需要，预处理打开了swapRB开关，用于rgb-&gt;bgr，对应的，生成kmodel_input.bin时，则需要先将数据转成rgb顺序；</p>
<p>（4）transpose也放到kmodel中，为什么生成kmodel_input.bin仍需transpose？由于生成kmodel，若是打开了预处理开关，transpose的相关参数必须设置，我们人脸检测kmodel的实际输入是<code>NCHW</code>，input_layout设置为<code>NCHW</code>，两者是一致的，因此transpose是NCHW2NCHW，实际上并没有转换。</p>
<p><strong>生成input.bin的过程</strong>：（放在onnx推理的预处理方法中）</p>
<p><img decoding="async" loading="lazy" alt="image-20240219144839973" src="/assets/images/image-20240219144839973-65970ff5149bad25ee038e1d9870cac2.png" width="1184" height="771" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="image-20240220185134172" src="/assets/images/image-20240220185134172-5311dddd53ffaa64fe402f926c95cf46.png" width="1439" height="821" class="img_ev3q"></p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="2simulator验证">2.Simulator验证<a href="#2simulator验证" class="hash-link" aria-label="Direct link to 2.Simulator验证" title="Direct link to 2.Simulator验证">​</a></h6>
<p><strong>模拟器APIs</strong>的接口如下图所示。若是在github无法看到<a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/ai/K230_nncase_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md" target="_blank" rel="noopener noreferrer">K230_nncase_开发指南.md</a>文档中目录结构，可以下载到本地，使用Typora工具打开。</p>
<p><img decoding="async" loading="lazy" alt="image-20240221140036235" src="/assets/images/image-20240221140036235-b0b2651bf7161275f33256cb4a84bf24.png" width="255" height="431" class="img_ev3q"></p>
<p><strong>Simulator流程：</strong></p>
<p>对于同一张图片，分别利用不同预处理生成不同的onnx_input.bin、kmodel_input.bin，</p>
<ul>
<li>将onnx_input.bin喂给onnx，经过onnx推理得cpu_results；</li>
<li>将kmodel_input.bin喂给kmodel，经过Simulator推理得到nncase_results；</li>
<li>计算cpu_results和nncase_results的余弦相似度，通过相似度的大小来判断生成的kmodel是否正确。</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># mobile_retinaface_onnx_simu_640.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import copy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import argparse</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import onnx</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import onnxruntime as ort</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import nncase</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def read_model_file(model_file):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    with open(model_file, &#x27;rb&#x27;) as f:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        model_content = f.read()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return model_content</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def cosine(gt, pred):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return (gt @ pred) / (np.linalg.norm(gt, 2) * np.linalg.norm(pred, 2))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def main():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parser = argparse.ArgumentParser(prog=&quot;nncase&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parser.add_argument(&quot;--target&quot;, type=str, help=&#x27;target to run&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parser.add_argument(&quot;--model&quot;, type=str, help=&#x27;original model file&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parser.add_argument(&quot;--model_input&quot;, type=str, help=&#x27;input bin file for original model&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parser.add_argument(&quot;--kmodel&quot;, type=str, help=&#x27;kmodel file&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parser.add_argument(&quot;--kmodel_input&quot;, type=str, help=&#x27;input bin file for kmodel&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    args = parser.parse_args()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 1. onnx推理，得到cpu_results</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ort_session = ort.InferenceSession(args.model)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    output_names = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_outputs = ort_session.get_outputs()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for i in range(len(model_outputs)):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        output_names.append(model_outputs[i].name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_input = ort_session.get_inputs()[0]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_input_name = model_input.name</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_input_type = np.float32</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_input_shape = model_input.shape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(&#x27;onnx_input：&#x27;,model_input_shape)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_input_data = np.fromfile(args.model_input, model_input_type).reshape(model_input_shape)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cpu_results = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cpu_results = ort_session.run(output_names, { model_input_name : model_input_data })</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 2. Simulator推理，得到nncase_results</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # create Simulator</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sim = nncase.Simulator()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # read kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    kmodel = read_model_file(args.kmodel)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # load kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sim.load_model(kmodel)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # read input.bin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_shape = [1, 3, 640, 640]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    dtype = sim.get_input_desc(0).dtype</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input = np.fromfile(args.kmodel_input, dtype).reshape(input_shape)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # set input for Simulator</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sim.set_input_tensor(0, nncase.RuntimeTensor.from_numpy(input))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Simulator inference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    nncase_results = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sim.run()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for i in range(sim.outputs_size):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        nncase_result = sim.get_output_tensor(i).to_numpy()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # print(&quot;nncase_result:&quot;,nncase_result)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        input_bin_file = &#x27;bin/face_det_{}_{}_simu.bin&#x27;.format(i,args.target)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        nncase_result.tofile(input_bin_file)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        nncase_results.append(copy.deepcopy(nncase_result))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 3. 计算onnx和Simulator相似度</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for i in range(sim.outputs_size):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cos = cosine(np.reshape(nncase_results[i], (-1)), np.reshape(cpu_results[i], (-1)))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print(&#x27;output {0} cosine similarity : {1}&#x27;.format(i, cos))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &#x27;__main__&#x27;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    main()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>上边的脚本可以满足大部分onnx及其kmodel的对比验证，一般不用太多修改。只需根据模型实际输入大小修改<code>input_shape</code>即可。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">python mobile_retinaface_onnx_simu_640.py \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        --target k230 --model onnx/FaceDetector.onnx \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        --model_input bin/face_det_0_640x640_float32.bin \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        --kmodel onnx/k230_face_detection_data_100_640.kmodel \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        --kmodel_input bin/face_det_0_640x640_uint8.bin</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#若已下载code过，请忽略clone步骤</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd K230_AI_Demo_Development_Process_Analysis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd kmodel_related/kmodel_export</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./build_model.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>onnx和Simulator余弦相似度越高越好，一般0.99以上即可满足条件；若  是达不到0.99，但是在0.95以上，可以通过进一步<strong>上板验证</strong>来判断生成的kmodel是否满足实际需求。</p>
<p><img decoding="async" loading="lazy" alt="image-20240220191227828" src="/assets/images/image-20240220191227828-0b2ae93f44b3bb75a2c4f86539c4b238.png" width="1462" height="525" class="img_ev3q"></p>
<p>**注：**在执行simulator时，必须先添加以下环境变量（build_model.sh文件其中含有）</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">export NNCASE_PLUGIN_PATH=$NNCASE_PLUGIN_PATH:/usr/local/lib/python3.8/dist-packages/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export PATH=$PATH:/usr/local/lib/python3.8/dist-packages/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source /etc/profile</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63142-使用main_nncase验证kmodel">6.3.1.4.2 使用main_nncase验证kmodel<a href="#63142-使用main_nncase验证kmodel" class="hash-link" aria-label="Direct link to 6.3.1.4.2 使用main_nncase验证kmodel" title="Direct link to 6.3.1.4.2 使用main_nncase验证kmodel">​</a></h5>
<p>Simulator推理kmodel和上板推理kmodel一般来说是一致的，但是不排除个别情况下Simulator与实际上板仍有一定差异，为了验证两者是否一致，需要使用main_nncase工具辅助验证Simulator推理kmodel与实际推理kmodel结果是否一致；使用这个工具需要调用nncase的<strong>KPU运行时APIs(C++)</strong>。</p>
<p>KPU运行时APIs提供kmodel上板推理的各种接口 ，接口如下图所示。若是在github无法看到<a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/ai/K230_nncase_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md" target="_blank" rel="noopener noreferrer">K230_nncase_开发指南.md</a>文档中目录结构，可以下载到本地，使用Typora工具打开。</p>
<p><img decoding="async" loading="lazy" alt="image-20240221141307953" src="/assets/images/image-20240221141307953-25e55837f9bff0dfa5a023c8d1c91f9d.png" width="310" height="356" class="img_ev3q"></p>
<p><strong>main_nncase验证流程</strong>（对K230的KPU调用有个大概的印象）：</p>
<ul>
<li>加载kmodel</li>
<li>设置kmodel输入：读取kmodel_input.bin文件</li>
<li>设置kmodel输出</li>
<li>推理kmodel</li>
<li>获取kmodel输出</li>
<li>对比Simulator推理kmodel、上板推理kmodel结果相似性</li>
</ul>
<p><strong>注</strong>：main_nncase工具可以适配所有kmodel的验证，无需自己修改。只需执行时，修改命令行的对应参数即可。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">//main_nncase.cc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;chrono&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;fstream&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;iostream&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;nncase/runtime/runtime_tensor.h&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;nncase/runtime/interpreter.h&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;nncase/runtime/runtime_op_utility.h&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">using namespace nncase;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">using namespace nncase::runtime;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">using namespace nncase::runtime::detail;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#define USE_CACHE 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">template &lt;class T&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">std::vector&lt;T&gt; read_binary_file(const char *file_name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::ifstream ifs(file_name, std::ios::binary);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.seekg(0, ifs.end);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    size_t len = ifs.tellg();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::vector&lt;T&gt; vec(len / sizeof(T), 0);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.seekg(0, ifs.beg);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.read(reinterpret_cast&lt;char *&gt;(vec.data()), len);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.close();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return vec;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void read_binary_file(const char *file_name, char *buffer)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::ifstream ifs(file_name, std::ios::binary);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.seekg(0, ifs.end);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    size_t len = ifs.tellg();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.seekg(0, ifs.beg);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.read(buffer, len);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.close();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">template &lt;typename T&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">double dot(const T *v1, const T *v2, size_t size)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    double ret = 0.f;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (size_t i = 0; i &lt; size; i++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ret += v1[i] * v2[i];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return ret;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">template &lt;typename T&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">double cosine(const T *v1, const T *v2, size_t size)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return dot(v1, v2, size) / ((sqrt(dot(v1, v1, size)) * sqrt(dot(v2, v2, size))));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void dump(const std::string &amp;info, volatile float *p, size_t size)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::cout &lt;&lt; info &lt;&lt; &quot; dump: p = &quot; &lt;&lt; std::hex &lt;&lt; (void *)p &lt;&lt; std::dec &lt;&lt; &quot;, size = &quot; &lt;&lt; size &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    volatile unsigned int *q = reinterpret_cast&lt;volatile unsigned int *&gt;(p);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (size_t i = 0; i &lt; size; i++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if ((i != 0) &amp;&amp; (i % 4 == 0))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::cout &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::cout &lt;&lt; std::hex &lt;&lt; q[i] &lt;&lt; &quot; &quot;;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::cout &lt;&lt; std::dec &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">int main(int argc, char *argv[])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::cout &lt;&lt; &quot;case &quot; &lt;&lt; argv[0] &lt;&lt; &quot; build &quot; &lt;&lt; __DATE__ &lt;&lt; &quot; &quot; &lt;&lt; __TIME__ &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if (argc &lt; 4)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::cerr &lt;&lt; &quot;Usage: &quot; &lt;&lt; argv[0] &lt;&lt; &quot; &lt;kmodel&gt; &lt;input_0.bin&gt; &lt;input_1.bin&gt; ... &lt;input_N.bin&gt; &lt;output_0.bin&gt; &lt;output_1.bin&gt; ... &lt;output_N.bin&gt;&quot; &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return -1;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    interpreter interp;                             </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 1. load model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::ifstream in_before_load_kmodel(&quot;/proc/media-mem&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::string line_before_load_kmodel;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 逐行读取文件内容，查看MMZ使用情况</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    while (std::getline(in_before_load_kmodel, line_before_load_kmodel)) { </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::cout &lt;&lt; line_before_load_kmodel &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::ifstream ifs(argv[1], std::ios::binary);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    interp.load_model(ifs).expect(&quot;Invalid kmodel&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::ifstream in_after_load_kmodel(&quot;/proc/media-mem&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::string line_after_load_kmodel;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 逐行读取文件内容，查看MMZ使用情况</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    while (std::getline(in_after_load_kmodel, line_after_load_kmodel)) {  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::cout &lt;&lt; line_after_load_kmodel &lt;&lt; std::endl;  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 2. set inputs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (size_t i = 2, j = 0; i &lt; 2 + interp.inputs_size(); i++, j++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto desc = interp.input_desc(j);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto shape = interp.input_shape(j);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto tensor = host_runtime_tensor::create(desc.datatype, shape, hrt::pool_shared).expect(&quot;cannot create input tensor&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto mapped_buf = std::move(hrt::map(tensor, map_access_::map_write).unwrap());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#if USE_CACHE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        read_binary_file(argv[i], reinterpret_cast&lt;char *&gt;(mapped_buf.buffer().data()));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto vec = read_binary_file&lt;unsigned char&gt;(argv[i]);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        memcpy(reinterpret_cast&lt;void *&gt;(mapped_buf.buffer().data()), reinterpret_cast&lt;void *&gt;(vec.data()), vec.size());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // dump(&quot;app dump input vector&quot;, (volatile float *)vec.data(), 32);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#endif</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto ret = mapped_buf.unmap();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ret = hrt::sync(tensor, sync_op_t::sync_write_back, true);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (!ret.is_ok())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::cerr &lt;&lt; &quot;hrt::sync failed&quot; &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::abort();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // dump(&quot;app dump input block&quot;, (volatile float *)block.virtual_address, 32);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        interp.input_tensor(j, tensor).expect(&quot;cannot set input tensor&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 3. set outputs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (size_t i = 0; i &lt; interp.outputs_size(); i++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto desc = interp.output_desc(i);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto shape = interp.output_shape(i);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto tensor = host_runtime_tensor::create(desc.datatype, shape, hrt::pool_shared).expect(&quot;cannot create output tensor&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        interp.output_tensor(i, tensor).expect(&quot;cannot set output tensor&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 4. run</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    auto start = std::chrono::steady_clock::now();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    interp.run().expect(&quot;error occurred in running model&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    auto stop = std::chrono::steady_clock::now();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    double duration = std::chrono::duration&lt;double, std::milli&gt;(stop - start).count();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::cout &lt;&lt; &quot;interp run: &quot; &lt;&lt; duration &lt;&lt; &quot; ms, fps = &quot; &lt;&lt; 1000 / duration &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 5. get outputs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (int i = 2 + interp.inputs_size(), j = 0; i &lt; argc; i++, j++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto out = interp.output_tensor(j).expect(&quot;cannot get output tensor&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto mapped_buf = std::move(hrt::map(out, map_access_::map_read).unwrap());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto expected = read_binary_file&lt;unsigned char&gt;(argv[i]);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 6. compare</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        int ret = memcmp((void *)mapped_buf.buffer().data(), (void *)expected.data(), expected.size());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (!ret)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::cout &lt;&lt; &quot;compare output &quot; &lt;&lt; j &lt;&lt; &quot; Pass!&quot; &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            auto cos = cosine((const float *)mapped_buf.buffer().data(), (const float *)expected.data(), expected.size()/sizeof(float));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::cerr &lt;&lt; &quot;compare output &quot; &lt;&lt; j &lt;&lt; &quot; Fail: cosine similarity = &quot; &lt;&lt; cos &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>编译上述c++代码，将<code>k230_bin</code>目录下的<code>debug</code>目录拷贝到k230开发板。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#docker容器中，若已下载code过，请忽略clone步骤</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec -it v1.3_0219_lj /bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd src/reference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis.git</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd K230_AI_Demo_Development_Process_Analysis/kmodel_related/kmodel_inference/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./build_app.sh debug</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 在小核上：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 大小核共用/sharefs/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /sharefs/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#示例：实际执行时，将源目录替换为自己的目录</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scp liujie@10.10.1.22:/xxx/k230_bin/debug /sharefs/ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 大核上</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /sharefs/k230_bin/debug</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#./face_detect_main_nncase.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./main_nncase.elf face_detect_640.kmodel face_det_0_640x640_uint8.bin face_det_0_k230_simu.bin face_det_1_k230_simu.bin face_det_2_k230_simu.bin</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="image-20240221112222263" src="/assets/images/image-20240221112222263-de777f8d8fc1a6c7e449ed17afa5c4e7.png" width="1242" height="489" class="img_ev3q"></p>
<p>通过执行结果，可以发现：</p>
<ul>
<li>人脸检测kmodel<strong>内存</strong>：大概占用1M左右</li>
<li>人脸检测kmodel<strong>推理速度</strong>：26.6ms</li>
<li>人脸检测<strong>Simulator和上板推理相似度</strong>：输出0,2 pass，byte级别完全一致；输出1 fail，float级别余弦相似度为1。一般0.99以上即可以满足要求</li>
</ul>
<p>人脸检测simulator结果大致满足要求，main_nncase的结果也满足要求，因此生成的人脸检测kmodel大概率是没有问题的。</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63143-使用k230runtime进行推理">6.3.1.4.3 使用K230Runtime进行推理<a href="#63143-使用k230runtime进行推理" class="hash-link" aria-label="Direct link to 6.3.1.4.3 使用K230Runtime进行推理" title="Direct link to 6.3.1.4.3 使用K230Runtime进行推理">​</a></h5>
<p><img decoding="async" loading="lazy" alt="image-20240223100614823" src="/assets/images/image-20240223100614823-5ef5a319f999e6cca78230a91065c00e.png" width="631" height="781" class="img_ev3q"></p>
<p><a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/tree/main/kmodel_related/kmodel_inference/face_detection" target="_blank" rel="noopener noreferrer">face_detection code</a></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">├── ai_base.cc                  #AI基类，封装KPU(K230)运行时API，简化kmodel相关操作</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── ai_base.h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├  ── anchors_640.cc              #人脸检测640分辨率输入对应anchor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── CMakeLists.txt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── face_detection.cc           #人脸检测demo，预处理，kmodel推理、后处理</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── face_detection.h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── main.cc                     #人脸检测demo主流程</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── README.md</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── scoped_timing.hpp           #计时类</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── utils.cc                    #工具类，封装常用函数及AI2D运行时APIs，简化预处理操作</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── utils.h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└── vi_vo.h                     #封装sensor、display操作</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>使用K230Runtime推理kmodel需要详细了解K230Runtime的说明文档，为了简化推理流程，对K230Runtime的接口进行封装，其中<code>ai_base.cc、scoped_timing.hpp、utils.cc、vi_vo.h</code>是封装好的方法，无需修改；对于不同模型，用户无需关心K230Runtime相关操作，只需将<code>face_detection.cc</code>、<code>main.cc</code>拷贝一份，只修改对应构造函数、预处理（pre_process）、后处理（post_process）即可。</p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="1读取图片或视频帧">1.读取图片或视频帧<a href="#1读取图片或视频帧" class="hash-link" aria-label="Direct link to 1.读取图片或视频帧" title="Direct link to 1.读取图片或视频帧">​</a></h6>
<p>（1）<strong>读取图片</strong></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cv::Mat ori_img = cv::imread(xxx);</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>（2）<strong>读取视频帧</strong></p>
<p><strong>背景知识</strong>：</p>
<p>（1）<strong>vi_vo.h简介</strong>：<code>vi_vo.h</code>主要封装了视频输入、视频输出相关配置。我们根据<code>vi_vo.h</code>构建了<code>test_vi_vo</code>示例，示例中讲解了如何使用vi，vo部分。</p>
<p>vi：视频输入，与sensor相关，详细介绍见<a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/mpp/K230_VICAP_API%E5%8F%82%E8%80%83.md" target="_blank" rel="noopener noreferrer">K230_VICAP_API参考.md</a>、<a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/mpp/K230_VICAP_SENSOR_%E5%8F%82%E6%95%B0%E5%88%86%E5%8C%BA%E5%8F%82%E8%80%83.md" target="_blank" rel="noopener noreferrer">K230_VICAP_SENSOR_参数分区参考.md</a>、<a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/mpp/K230_Camera_Sensor%E9%80%82%E9%85%8D%E6%8C%87%E5%8D%97.md" target="_blank" rel="noopener noreferrer">K230_Camera_Sensor适配指南.md</a>。</p>
<ul>
<li>sensor启动</li>
<li>从sensor中dump一帧数据</li>
<li>将sensor中数据保存为png</li>
<li>释放sensor当前帧</li>
<li>sensor停止</li>
</ul>
<p>vo：视频输出，与display相关，详细介绍见<a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/mpp/K230_%E8%A7%86%E9%A2%91%E8%BE%93%E5%87%BA_API%E5%8F%82%E8%80%83.md" target="_blank" rel="noopener noreferrer">K230_视频输出_API参考.md</a></p>
<ul>
<li>将框或文字画到cv::Mat，并插入到vo osd对应通道中</li>
<li>释放osd block</li>
</ul>
<p>（2）<strong>读取视频帧示例</strong>：<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/tree/main/kmodel_related/kmodel_inference/test_demo/test_vi_vo" target="_blank" rel="noopener noreferrer">test_vi_vo demo</a></p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="2预处理">2.预处理<a href="#2预处理" class="hash-link" aria-label="Direct link to 2.预处理" title="Direct link to 2.预处理">​</a></h6>
<p><strong>背景知识</strong>：</p>
<p>（1）<strong>Uitls简介</strong>：Uitls主要封装了常用函数、nncase AI2D相关操作，AI2D相关部分包括Affine、Crop、Resize、Padding预处理操作，可以加速图像的预处理操作。</p>
<p>（2）<strong>预处理示例</strong>：<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/tree/main/kmodel_related/kmodel_inference/test_demo/test_utils" target="_blank" rel="noopener noreferrer">test_utils demo</a></p>
<p>若是<strong>对AI2D 运行时APIs</strong>感兴趣，详情请查看<code>K230_nncase_开发指南.md</code>，若是在github无法看到<a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/ai/K230_nncase_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md" target="_blank" rel="noopener noreferrer">K230_nncase_开发指南.md</a>文档中目录结构，可以下载到本地，使用Typora工具打开。</p>
<p><img decoding="async" loading="lazy" alt="image-20240222134841039" src="/assets/images/image-20240222134841039-e84496b001d1bb47dbb20797dda5b896.png" width="347" height="501" class="img_ev3q"></p>
<p><strong>人脸检测预处理</strong>：</p>
<p><strong>背景知识</strong>：参数不变的情况下，<code>ai2d_builder_</code>可以反复调用；参数改变则需要创建新的<code>ai2d_builder_</code>。</p>
<p>对于图像预处理：由于不同图像的尺寸不同，对于padding_resize方法来说，AI2D的参数每次都会改变，需要重新调用Utils::padding_resize_one_side创建新的<code>ai2d_builder_</code>来进行预处理。</p>
<p><img decoding="async" loading="lazy" alt="padding_resize.png" src="/assets/images/padding_resize-59bd856168818fa7c15752ea30e1e236.png" width="461" height="132" class="img_ev3q"></p>
<p>对于视频流预处理：由于不同帧的尺寸相同，padding的数值也未改变；故对于<code>padding_resize</code>方法来说，AI2D的参数一直不变，将新一帧的图像拷贝给<code>ai2d_in_tensor_</code>后，只需<code>ai2d_builder_-&gt;invoke</code>（人脸构造函数中已经构造好<code>ai2d_builder_</code>）调用。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">//face_detection.cc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// ai2d for image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceDetection::pre_process(cv::Mat ori_img)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ScopedTiming st(model_name_ + &quot; pre_process image&quot;, debug_mode_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::vector&lt;uint8_t&gt; chw_vec;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Utils::bgr2rgb_and_hwc2chw(ori_img, chw_vec);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Utils::padding_resize_one_side({ori_img.channels(), ori_img.rows, ori_img.cols}, chw_vec, {input_shapes_[0][3], input_shapes_[0][2]}, ai2d_out_tensor_, cv::Scalar(123, 117, 104));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if (debug_mode_ &gt; 1)  //验证预处理是否正确，看当前预处理与onnx预处理是否一致：dump预处理之后图像</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto vaddr_out_buf = ai2d_out_tensor_.impl()-&gt;to_host().unwrap()-&gt;buffer().as_host().unwrap().map(map_access_::map_read).unwrap().buffer();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        unsigned char *output = reinterpret_cast&lt;unsigned char *&gt;(vaddr_out_buf.data());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Utils::dump_color_image(&quot;FaceDetection_input_padding.png&quot;,{input_shapes_[0][3],input_shapes_[0][2]},output);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// ai2d for video</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceDetection::pre_process()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ScopedTiming st(model_name_ + &quot; pre_process video&quot;, debug_mode_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    size_t isp_size = isp_shape_.channel * isp_shape_.height * isp_shape_.width;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    auto buf = ai2d_in_tensor_.impl()-&gt;to_host().unwrap()-&gt;buffer().as_host().unwrap().map(map_access_::map_write).unwrap().buffer();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    memcpy(reinterpret_cast&lt;char *&gt;(buf.data()), (void *)vaddr_, isp_size);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    hrt::sync(ai2d_in_tensor_, sync_op_t::sync_write_back, true).expect(&quot;sync write_back failed&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ai2d_builder_-&gt;invoke(ai2d_in_tensor_, ai2d_out_tensor_).expect(&quot;error occurred in ai2d running&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if (debug_mode_ &gt; 1)  //验证预处理是否正确，看当前预处理与onnx预处理是否一致：dump预处理之后图像</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto vaddr_out_buf = ai2d_out_tensor_.impl()-&gt;to_host().unwrap()-&gt;buffer().as_host().unwrap().map(map_access_::map_read).unwrap().buffer();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        unsigned char *output = reinterpret_cast&lt;unsigned char *&gt;(vaddr_out_buf.data());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Utils::dump_color_image(&quot;FaceDetection_input_padding.png&quot;,{input_shapes_[0][3],input_shapes_[0][2]},output);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="3kmodel-run">3.kmodel run<a href="#3kmodel-run" class="hash-link" aria-label="Direct link to 3.kmodel run" title="Direct link to 3.kmodel run">​</a></h6>
<p><strong>背景知识</strong>：</p>
<p>（1）<strong>AIBase简介</strong>：AIBase主要封装了KPU相关操作，包括在AI设备（如k230）加载kmodel，设置kmodel输入数据，执行kpu/cpu计算， 获取kmodel输出数据等，AIBase的封装简化了KPU调用过程。</p>
<p>（2）<strong>kmodel推理示例</strong>（main_nncase修改为基于AIBase类的demo）：<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/tree/main/kmodel_related/kmodel_inference/test_demo/test_aibase" target="_blank" rel="noopener noreferrer">test_aibase demo</a>。</p>
<p>**KPU运行时APIs（KPU Runtime AIPS）**接口如下图所示。详情请查看<code>K230_nncase_开发指南.md</code>，若是在github无法看到<a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/ai/K230_nncase_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md" target="_blank" rel="noopener noreferrer">K230_nncase_开发指南.md</a>文档中目录结构，可以下载到本地，使用Typora工具打开。</p>
<p><img decoding="async" loading="lazy" alt="image-20240223100614822" src="/assets/images/image-20240223100614822-c9031675c976b9efc6c11f66a11db7a6.png" width="306" height="350" class="img_ev3q"></p>
<p><strong>人脸检测kmode推理</strong>：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">//ai_base.cc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void AIBase::run()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ScopedTiming st(model_name_ + &quot; run&quot;, debug_mode_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    kmodel_interp_.run().expect(&quot;error occurred in running model&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void AIBase::get_output()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ScopedTiming st(model_name_ + &quot; get_output&quot;, debug_mode_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    p_outputs_.clear();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (int i = 0; i &lt; kmodel_interp_.outputs_size(); i++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto out = kmodel_interp_.output_tensor(i).expect(&quot;cannot get output tensor&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto buf = out.impl()-&gt;to_host().unwrap()-&gt;buffer().as_host().unwrap().map(map_access_::map_read).unwrap().buffer();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float *p_out = reinterpret_cast&lt;float *&gt;(buf.data());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        p_outputs_.push_back(p_out);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//face_detection.cc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceDetection::inference()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    this-&gt;run();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    this-&gt;get_output();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//main.cc，验证kmodel推理是否正确：我们使用simulator和main_nncase已经验证过</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">......</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FaceDetection fd;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fd.inference();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">......</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="4后处理">4.后处理<a href="#4后处理" class="hash-link" aria-label="Direct link to 4.后处理" title="Direct link to 4.后处理">​</a></h6>
<p><strong>onnx后处理：</strong></p>
<p><img decoding="async" loading="lazy" alt="image-20240223153101754.png" src="/assets/images/image-20240223153101754-56c24c152c5398ce6dd1dbbe947d1809.png" width="1149" height="1115" class="img_ev3q"></p>
<p><strong>c++后处理（详情见代码）</strong>：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">//face_detection.cc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceDetection::post_process(FrameSize frame_size, vector&lt;FaceDetectionInfo&gt; &amp;results)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ScopedTiming st(model_name_ + &quot; post_process&quot;, debug_mode_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if (debug_mode_ &gt; 3)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //验证后处理流程是否正确：排除预处理、模型推理，直接拿Simulator kmodel数据，判断后处理代码正确性。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ......</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        filter_confs(p_outputs_[1]);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        filter_locs(p_outputs_[0]);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        filter_landms(p_outputs_[2]);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::sort(confs_.begin(), confs_.end(), nms_comparator);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    nms(results);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    transform_result_to_src_size(frame_size, results);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<table><thead><tr><th>onnx后处理流程</th><th>kmodel后处理流程</th></tr></thead><tbody><tr><td>1.解码loc、landms</td><td>1.过滤conf、loc、landms（数量级：16800-&gt;数百）</td></tr><tr><td>2.过滤conf、loc、landms</td><td>2.根据conf对conf、loc、landms进行排序（降低排序耗时）</td></tr><tr><td>3.根据conf对conf、loc、landms进行排序</td><td>3.nms + 解码loc、landms</td></tr><tr><td>4.nms</td><td>4.将人脸检测结果变换到原图大小</td></tr><tr><td>5.top_k</td><td></td></tr></tbody></table>
<p>调整顺序之后的kmodel推理流程，更适合c++代码。</p>
<p><strong>人脸检测后处理代码</strong>：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">//face_detection.cc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceDetection::post_process(FrameSize frame_size, vector&lt;FaceDetectionInfo&gt; &amp;results)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ScopedTiming st(model_name_ + &quot; post_process&quot;, debug_mode_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if (debug_mode_ &gt; 2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //验证后处理流程是否正确：排除预处理、模型推理，直接拿Simulator kmodel数据，判断后处理代码正确性。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        vector&lt;float&gt; out0 = Utils::read_binary_file&lt;float&gt;(&quot;../debug/face_det_0_k230_simu.bin&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        vector&lt;float&gt; out1 = Utils::read_binary_file&lt;float&gt;(&quot;../debug/face_det_1_k230_simu.bin&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        vector&lt;float&gt; out2 = Utils::read_binary_file&lt;float&gt;(&quot;../debug/face_det_2_k230_simu.bin&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        filter_confs(out1.data());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        filter_locs(out0.data());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        filter_landms(out2.data());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        filter_confs(p_outputs_[1]);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        filter_locs(p_outputs_[0]);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        filter_landms(p_outputs_[2]);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::sort(confs_.begin(), confs_.end(), nms_comparator);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    nms(results);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    transform_result_to_src_size(frame_size, results);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">/********************根据检测阈值kmodel数据结果***********************/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceDetection::filter_confs(float *conf)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    NMSRoiObj inter_obj;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    confs_.clear();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (uint32_t roi_index = 0; roi_index &lt; objs_num_; roi_index++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float score = conf[roi_index * CONF_SIZE + 1];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (score &gt; obj_thresh_)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            inter_obj.ori_roi_index = roi_index;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            inter_obj.before_sort_conf_index = confs_.size();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            inter_obj.confidence = score;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            confs_.push_back(inter_obj);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceDetection::filter_locs(float *loc)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    boxes_.clear();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    boxes_.resize(confs_.size());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int roi_index = 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (uint32_t conf_index = 0; conf_index &lt; boxes_.size(); conf_index++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        roi_index = confs_[conf_index].ori_roi_index;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        int start = roi_index * LOC_SIZE;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for (int i = 0; i &lt; LOC_SIZE; ++i)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            boxes_[conf_index][i] = loc[start + i];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceDetection::filter_landms(float *landms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    landmarks_.clear();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    landmarks_.resize(confs_.size());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int roi_index = 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (uint32_t conf_index = 0; conf_index &lt; boxes_.size(); conf_index++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        roi_index = confs_[conf_index].ori_roi_index;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        int start = roi_index * LAND_SIZE;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for (int i = 0; i &lt; LAND_SIZE; ++i)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            landmarks_[conf_index][i] = landms[start + i];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">/********************根据anchor解码检测框、五官点***********************/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Bbox FaceDetection::decode_box(int obj_index)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float cx, cy, w, h;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int box_index = confs_[obj_index].before_sort_conf_index;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int anchor_index = confs_[obj_index].ori_roi_index;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cx = boxes_[box_index][0];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cy = boxes_[box_index][1];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    w = boxes_[box_index][2];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    h = boxes_[box_index][3];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cx = g_anchors[anchor_index][0] + cx * 0.1 * g_anchors[anchor_index][2];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cy = g_anchors[anchor_index][1] + cy * 0.1 * g_anchors[anchor_index][3];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    w = g_anchors[anchor_index][2] * std::exp(w * 0.2);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    h = g_anchors[anchor_index][3] * std::exp(h * 0.2);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Bbox box;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    box.x = cx - w / 2;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    box.y = cy - h / 2;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    box.w = w;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    box.h = h;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return box;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SparseLandmarks FaceDetection::decode_landmark(int obj_index)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    SparseLandmarks landmark;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int landm_index = confs_[obj_index].before_sort_conf_index;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int anchor_index = confs_[obj_index].ori_roi_index;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (uint32_t ll = 0; ll &lt; 5; ll++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        landmark.points[2 * ll + 0] = g_anchors[anchor_index][0] + landmarks_[landm_index][2 * ll + 0] * 0.1 * g_anchors[anchor_index][2];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        landmark.points[2 * ll + 1] = g_anchors[anchor_index][1] + landmarks_[landm_index][2 * ll + 1] * 0.1 * g_anchors[anchor_index][3];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return landmark;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">/********************iou计算***********************/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">float FaceDetection::overlap(float x1, float w1, float x2, float w2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float l1 = x1 - w1 / 2;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float l2 = x2 - w2 / 2;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float left = l1 &gt; l2 ? l1 : l2;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float r1 = x1 + w1 / 2;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float r2 = x2 + w2 / 2;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float right = r1 &lt; r2 ? r1 : r2;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return right - left;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">float FaceDetection::box_intersection(Bbox a, Bbox b)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float w = overlap(a.x, a.w, b.x, b.w);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float h = overlap(a.y, a.h, b.y, b.h);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if (w &lt; 0 || h &lt; 0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return w * h;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">float FaceDetection::box_union(Bbox a, Bbox b)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float i = box_intersection(a, b);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float u = a.w * a.h + b.w * b.h - i;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return u;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">float FaceDetection::box_iou(Bbox a, Bbox b)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return box_intersection(a, b) / box_union(a, b);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">/********************nms***********************/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceDetection::nms(vector&lt;FaceDetectionInfo&gt; &amp;results)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // nms</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (int conf_index = 0; conf_index &lt; confs_.size(); ++conf_index)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (confs_[conf_index].confidence &lt; 0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            continue;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        FaceDetectionInfo obj;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        obj.bbox = decode_box(conf_index);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        obj.sparse_kps = decode_landmark(conf_index);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        obj.score = confs_[conf_index].confidence;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        results.push_back(obj);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for (int j = conf_index + 1; j &lt; confs_.size(); ++j)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if (confs_[j].confidence &lt; 0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                continue;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            Bbox b = decode_box(j);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if (box_iou(obj.bbox, b) &gt;= nms_thresh_) // iou大于nms阈值的，之后循环将会忽略</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                confs_[j].confidence = -1;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">/********************将人脸检测结果变换到原图***********************/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceDetection::transform_result_to_src_size(FrameSize &amp;frame_size, vector&lt;FaceDetectionInfo&gt; &amp;results)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // transform result to dispaly size</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int max_src_size = std::max(frame_size.width, frame_size.height);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (int i = 0; i &lt; results.size(); ++i)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto &amp;l = results[i].sparse_kps;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for (uint32_t ll = 0; ll &lt; 5; ll++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            l.points[2 * ll + 0] = l.points[2 * ll + 0] * max_src_size;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            l.points[2 * ll + 1] = l.points[2 * ll + 1] * max_src_size;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto &amp;b = results[i].bbox;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float x0 = b.x * max_src_size;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float x1 = (b.x + b.w) * max_src_size;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float y0 = b.y * max_src_size;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float y1 = (b.y + b.h) * max_src_size;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x0 = std::max(float(0), std::min(x0, float(frame_size.width)));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x1 = std::max(float(0), std::min(x1, float(frame_size.width)));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        y0 = std::max(float(0), std::min(y0, float(frame_size.height)));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        y1 = std::max(float(0), std::min(y1, float(frame_size.height)));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        b.x = x0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        b.y = y0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        b.w = x1 - x0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        b.h = y1 - y0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>扩展：</strong></p>
<p>检测后处理写起来比价复杂，因此对于常见的检测模型，我们给出了一些示例代码。</p>
<ul>
<li><strong>retinaface</strong>：<a href="https://github.com/kendryte/k230_sdk/blob/main/src/reference/ai_poc/face_detection/face_detection.cc" target="_blank" rel="noopener noreferrer">人脸检测post_process</a></li>
<li><strong>yolov5</strong>：<a href="https://github.com/kendryte/k230_sdk/blob/main/src/reference/ai_poc/falldown_detect/falldown_detect.cc" target="_blank" rel="noopener noreferrer">摔倒检测post_process</a></li>
<li><strong>yolov8</strong>：<a href="https://github.com/kendryte/k230_sdk/blob/main/src/reference/ai_poc/head_detection/head_detection.cc" target="_blank" rel="noopener noreferrer">人头检测post_process</a></li>
</ul>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="5显示结果">5.显示结果<a href="#5显示结果" class="hash-link" aria-label="Direct link to 5.显示结果" title="Direct link to 5.显示结果">​</a></h6>
<p><strong>显示结果示例</strong>：<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/tree/main/kmodel_related/kmodel_inference/test_demo/test_vi_vo" target="_blank" rel="noopener noreferrer">test_vi_vo demo</a></p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="6编译执行">6.编译、执行<a href="#6编译执行" class="hash-link" aria-label="Direct link to 6.编译、执行" title="Direct link to 6.编译、执行">​</a></h6>
<p>将代码clone到已启动docker容器<code>src/reference/</code>目录，执行<code>build_app.sh</code>。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker exec -it v1.3_0219_lj /bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd src/reference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis.git</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd K230_AI_Demo_Development_Process_Analysis/kmodel_related/kmodel_inference/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./build_app.sh debug         #若是无需debug目录，执行./build_app.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>将<code>k230_bin</code>目录下的<code>face_detect</code>目录拷贝到k230开发板小核<code>/sharefs</code>目录。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">k230_bin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── debug            #调试用到的文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_det_0_640x640_uint8.bin    #人脸检测kmodel输入文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_det_0_k230_simu.bin        #人脸检测simulator第1个输出文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_det_1_k230_simu.bin        #人脸检测simulator第2个输出文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_det_2_k230_simu.bin        #人脸检测simulator第3个输出文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_detect_640.kmodel          #人脸检测kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_detect.jpg                 #人脸检测基于图像推理时的输入图像</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_detect_main_nncase.sh      #人脸检测kmodel上板验证运行脚本</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_detect_main_nncase_with_aibase.sh #人脸检测kmodel上板验证运行脚本</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_recg_0_112x112_uint8.bin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_recg_0_k230_simu.bin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_recognize.kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_recognize_main_nncase.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── main_nncase.elf                 #人脸检测kmodel上板验证可执行文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── test_aibase.elf                 #test_aibase demo生成可执行文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── test_scoped_timing.elf          #test_scoped_timing demo生成可执行文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── test_utils.elf                  #test_utils demo生成可执行文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └── test_vi_vo.elf                  #test_vi_vo demo生成可执行文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── face_detect     #人脸检测</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_detect_640.kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_detect_image.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_detection.elf</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── face_detect_isp.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └── face_detect.jpg</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└── face_recognize   #人脸识别，人脸检测可以不关注</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ├── db</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ├── face_detect_640.kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ├── face_recognition.elf</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ├── face_recognize_isp.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    └── face_recognize.kmodel</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>(1) 预处理是否正确</li>
</ul>
<p>将debug_mode设置为2，即可保存预处理之后的图像。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 大小核共用/sharefs/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 在小核上</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /sharefs/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#示例：实际执行时，将源目录替换为自己的目录</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scp liujie@10.10.1.22:/xxx/k230_bin /sharefs/ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#在大核上（若是刚启动，先按q+Enter退去自启动程序）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /sharefs/k230_bin/face_detect</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./face_detection.elf face_detect_640.kmodel 0.5 0.2 face_detect.jpg 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#在小核上</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd  /sharefs/k230_bin/face_detect</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scp FaceDetection_input_padding.png username@ip:dir</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>将生成<code>FaceDetection_input_padding.png</code>，拷贝到pc查看，预处理代码是否正确。若是有问题，则需要看sensor原图有没有问题，设置的预处理参数是否正确。</p>
<p><img decoding="async" loading="lazy" alt="FaceDetection_input_padding" src="/assets/images/FaceDetection_input_padding-182f85288cc3c277330686e805181d5f.png" width="640" height="640" class="img_ev3q"></p>
<ul>
<li>(2) 后处理是否正确</li>
</ul>
<p>将debug_mode设置为3，即可验证后处理正确。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 大小核共用/sharefs/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 在小核上</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /sharefs/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#示例：实际执行时，将源目录替换为自己的目录</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scp liujie@10.10.1.22:/xxx/k230_bin /sharefs/ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#在大核上（先按q+Enter退去自启动程序）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /sharefs/k230_bin/face_detect</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./face_detection.elf face_detect_640.kmodel 0.5 0.2 face_detect.jpg 3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#在小核上</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd  /sharefs/k230_bin/face_detect</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scp face_detection_result.jpg username@ip:dir</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>将生成<code>face_detection_result.jpg</code>，拷贝到pc查看，预处理代码是否正确。若是不正确就需要对后处理部分代码进行仔细检查，打印调试。</p>
<p><img decoding="async" loading="lazy" alt="face_detection_result.jpg" src="/assets/images/face_detection_result-1721612140878-88-840ef2b05b98206ba13a6efd4c299979.jpg" width="1024" height="624" class="img_ev3q"></p>
<ul>
<li>(3) 执行 在大核上执行<code>face_detect_isp.sh</code>即可执行基于视频流的推理流程。</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#在大核上</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /sharefs/k230_bin/face_detect</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./face_detect_isp.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="632-人脸识别demo">6.3.2 人脸识别demo<a href="#632-人脸识别demo" class="hash-link" aria-label="Direct link to 6.3.2 人脸识别demo" title="Direct link to 6.3.2 人脸识别demo">​</a></h3>
<p>人脸识别是广泛使用的人脸任务，它将当前人脸与已知的人脸身份库进行比较，判断是否认识当前人脸。 人脸识别一般包含2个步骤：人脸注册和人脸识别，人脸注册用于构建人脸数据库，人脸识别用于识别存在数据库中的人脸。 <strong>人脸注册</strong>：图像采集-&gt;人脸定位-&gt;人脸对齐-&gt;特征提取-&gt;数据库保存 <strong>人脸识别</strong>：图像采集-&gt;人脸定位-&gt;人脸对齐-&gt;特征提取-&gt;特征比对-&gt;给出识别结果 <strong>人脸对齐</strong>：对于一张图像，人脸检测模型输出人脸目标框坐标和5个人脸关键点，在进行人脸识别前，需要对检测得到的人脸框进行对齐；即在2D平面将人脸转正，减少人脸旋转造成的差异，以便于后续更准确的人脸识别。</p>
<p><img decoding="async" loading="lazy" alt="image-20240227110308196" src="/assets/images/image-20240227110308196-86cd67f7a867f1e8f935dba1b8f49545.png" width="904" height="407" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6321-pytorch到onnx转换">6.3.2.1 PyTorch到ONNX转换<a href="#6321-pytorch到onnx转换" class="hash-link" aria-label="Direct link to 6.3.2.1 PyTorch到ONNX转换" title="Direct link to 6.3.2.1 PyTorch到ONNX转换">​</a></h4>
<p>选择人脸识别模型时，一般应选择轻量化的模型，backbone一般小于resnet50参数量较好。因此我们选择基于MobileNet且精度较高MobileFaceNet作为我们的人脸识别模型。参考链接：<a href="https://github.com/Xiaoccer/MobileFaceNet_Pytorch" target="_blank" rel="noopener noreferrer">Xiaoccer/MobileFaceNet_Pytorch</a></p>
<ul>
<li>加载pth或ckpt模型到cpu</li>
<li>构建随机模型输入</li>
<li>导出onnx模型</li>
</ul>
<p><strong>注</strong>：pth、onnx都支持动态输入，而K230的模型暂时不支持动态输入，所以导出onnx时，onnx输入shape固定。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#convert_to_onnx.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from core import model               #因模型而不同</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def convert_onnx(net, path_module, output, opset=11):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    assert isinstance(net, torch.nn.Module)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    img = np.random.randint(0, 255, size=(112, 112, 3), dtype=np.int32)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    img = img.astype(np.float)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    img = (img / 255. - 0.5) / 0.5  # torch style norm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    img = img.transpose((2, 0, 1))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    img = torch.from_numpy(img).unsqueeze(0).float()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ckpt = torch.load(path_module,map_location=&#x27;cpu&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    net.load_state_dict(ckpt[&#x27;net_state_dict&#x27;],strict=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    net.eval()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    torch.onnx.export(net, img, output, input_names=[&quot;data&quot;], keep_initializers_as_inputs=False, verbose=False,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                      opset_version=opset)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &#x27;__main__&#x27;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    net = model.MobileFacenet()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_file = &#x27;model/best/068.ckpt&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    output_file = &#x27;model/best/MobileFaceNet.onnx&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    convert_onnx(net, input_file, output_file)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>执行步骤：</strong></p>
<p>将<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/" target="_blank" rel="noopener noreferrer">代码</a>clone到pc上，安装依赖库，执行转onnx脚本。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd K230_AI_Demo_Development_Process_Analysis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd onnx_related/onnx_export</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/Xiaoccer/MobileFaceNet_Pytorch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cp face_recognition_convert_to_onnx.py MobileFaceNet_Pytorch/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd MobileFaceNet_Pytorch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#安装依赖库</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python face_recognition_convert_to_onnx.py</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6322-使用onnxruntime进行推理">6.3.2.2 使用ONNXRuntime进行推理<a href="#6322-使用onnxruntime进行推理" class="hash-link" aria-label="Direct link to 6.3.2.2 使用ONNXRuntime进行推理" title="Direct link to 6.3.2.2 使用ONNXRuntime进行推理">​</a></h4>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63221-人脸对齐">6.3.2.2.1 人脸对齐<a href="#63221-人脸对齐" class="hash-link" aria-label="Direct link to 6.3.2.2.1 人脸对齐" title="Direct link to 6.3.2.2.1 人脸对齐">​</a></h5>
<p>常用人脸识别训练集主要有：MS1MV2、MS1MV3、Glint360K，制作这些数据集一般需要对完整的人脸原图进行预处理，即先进行人脸检测，然后对每个人脸进行人脸对齐，然后保存对齐后的人脸图片。</p>
<p><strong>人脸对齐</strong>：对于一张图像，人脸检测模型输出人脸目标框坐标和5个人脸关键点，在进行人脸识别前，需要对检测得到的人脸进行对齐；即在2D平面将人脸转正，减少人脸旋转造成  的差异，以便于后续更准确的人脸识别。</p>
<p>x.png：原始图片，x_affine.png：对齐后的人脸</p>
<p><img decoding="async" loading="lazy" alt="image-20240226154210101" src="/assets/images/image-20240226154210101-d4f15939b8f4c224c2235d1c07f29402.png" width="331" height="180" class="img_ev3q"></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">def st_image(ori_image, landmarks):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    #标准正脸人脸五官位置（112x112分辨率）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    le_g = [38.2946, 51.6963]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    re_g = [73.5318, 51.5014]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    nose_g = [56.0252, 71.7366]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    l_mouth_g = [41.5493, 92.3655]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    r_mouth_g = [70.7299, 92.2041]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    #实际人脸五官位置</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    le = landmarks[0, :]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    re = landmarks[1, :]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    nose = landmarks[2, :]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    l_mouth = landmarks[3, :]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    r_mouth = landmarks[4, :]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    landmark_get = np.float32([le, re, nose, l_mouth, r_mouth])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    landmark_golden = np.float32([le_g, re_g, nose_g, l_mouth_g, r_mouth_g])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    #计算从实际人脸-&gt;标准正脸需要经过的变换</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tform = trans.SimilarityTransform()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tform.estimate(np.array(landmark_get), landmark_golden)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    M = tform.params[0:2, :]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    #得到变换后的人脸</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    affine_output = cv2.warpAffine(ori_image, M, (112, 112), borderValue=0.0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return affine_output</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63222-图像预处理">6.3.2.2.2 图像预处理<a href="#63222-图像预处理" class="hash-link" aria-label="Direct link to 6.3.2.2.2 图像预处理" title="Direct link to 6.3.2.2.2 图像预处理">​</a></h5>
<p>预处理构建（常用的方法：padding_resize，crop_resize，resize，affine、normalization）：参考train.py，test.py、predict.py、现成的onnx推理脚本。</p>
<p><strong>构建人脸识别预处理代码：</strong></p>
<p><img decoding="async" loading="lazy" alt="image-20240226160055218" src="/assets/images/image-20240226160055218-e0d7e67e81ebe4e38f4f90ad9e4b6664.png" width="1091" height="899" class="img_ev3q"></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#mobile_face_net.py：MobileFaceNet</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def pre_process(self,img,to_bin = True):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # bgr-&gt;rgb,uint8,(112,112,3)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    img = img[..., ::-1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Dequantize,float32,(112,112,3)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    img = np.array(img, dtype=&#x27;float32&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    #Normalization ，float32,(112,112,3)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for i in range(3):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        img[:, :, i] -= self.normalize_mean</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        img[:, :, i] /= self.normalize_std</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # transpose，hcw-&gt;chw,float32,(3,112,112)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    img = np.transpose(img, [2, 0, 1])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 3维扩张为4维，input_data,float32,(1,3,112,112)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_data = np.expand_dims(img, 0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return input_data</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>**参考：**人脸识别预处理代码参考train.py中调用的dataloader，去掉不适合推理使用的flip（数据增强），只留下onnx推理时必要的bgr-&gt;rgb（<a href="https://so.csdn.net/so/search?q=scipy&amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener noreferrer">scipy</a>.misc.imread 读取的图片数据是 RGB 格式）、Normalization（减mean除std）、hwc-&gt;chw（transpose）。</p>
<p><img decoding="async" loading="lazy" alt="image-20240226160816525" src="/assets/images/image-20240226160816525-b554acafd31afe88749be19866d3ed84.png" width="1805" height="814" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63123-onnx-run-1">6.3.1.2.3 onnx run<a href="#63123-onnx-run-1" class="hash-link" aria-label="Direct link to 6.3.1.2.3 onnx run" title="Direct link to 6.3.1.2.3 onnx run">​</a></h5>
<p>将预处理好的数据，喂给模型，得到onnx推理结果</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#onnx_model.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def forward(self, image_tensor):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &#x27;&#x27;&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    image_tensor = image.transpose(2, 0, 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    image_tensor = image_tensor[np.newaxis, :]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    onnx_session.run([output_name], {input_name: x})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    :param image_tensor:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    :return:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &#x27;&#x27;&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_feed = self.get_input_feed(image_tensor)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    output = self.sess.run(self.out_names, input_feed=input_feed)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#mobile_face_net.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def farward(self, input_data):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    embedding = self.model.forward(input_data)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return embedding[0]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63124-后处理-1">6.3.1.2.4 后处理<a href="#63124-后处理-1" class="hash-link" aria-label="Direct link to 6.3.1.2.4 后处理" title="Direct link to 6.3.1.2.4 后处理">​</a></h5>
<p>模型提取完特征后，放到数据库中，以备后续人脸对比使用。为了简化代码，我们暂时不写准备数据库的过程了，把它放在人脸对比的过程中。</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63125-人脸对比结果">6.3.1.2.5 人脸对比结果<a href="#63125-人脸对比结果" class="hash-link" aria-label="Direct link to 6.3.1.2.5 人脸对比结果" title="Direct link to 6.3.1.2.5 人脸对比结果">​</a></h5>
<p>读取多张人脸，对每个人脸提取特征，并将Normalization之后的特征保存到列表中。最后对比当前列表的第一个人脸和列表的相似度。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">face_recg = MobileFaceNet()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">embeddings = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for i,img_file in enumerate(img_lists):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ori_img = cv2.imread(img_file)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_data = face_recg.pre_process(ori_img)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    embedding = face_recg.farward(input_data)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 模型特征归一化，然后放到数据库中</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    embedding_norm = preprocessing.normalize(embedding)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    embeddings.append(embedding_norm)       #模拟构建数据库过程</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 获取第一个人脸特征，和其它人脸特征进行对比   </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">embedding_one = embeddings[0]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scores = np.array([np.sum(embedding_one * emb_database) / 2 + 0.5 for emb_database in embeddings])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;scores:&quot;,scores)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><code>img_lists</code>：</p>
<p><img decoding="async" loading="lazy" alt="image-20240304105854986" src="/assets/images/image-20240304105854986-193dbd701ca93ab22d623340f173cf1d.png" width="459" height="150" class="img_ev3q"></p>
<p>假如阈值设置为0.75的话，说明第0、1是同一个人脸，第0、2是不同人。</p>
<p><img decoding="async" loading="lazy" alt="image-20240227130213074" src="/assets/images/image-20240227130213074-3cbe94dfcec478d1793dacc2631f5f61.png" width="1465" height="176" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6323-onnx到kmodel转换">6.3.2.3 ONNX到kmodel转换<a href="#6323-onnx到kmodel转换" class="hash-link" aria-label="Direct link to 6.3.2.3 ONNX到kmodel转换" title="Direct link to 6.3.2.3 ONNX到kmodel转换">​</a></h4>
<p><img decoding="async" loading="lazy" alt="image-20240226162226960.png" src="/assets/images/image-20240226162226960-ab5af5aa5899ffcacc528c6ecb17b806.png" width="705" height="458" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63231-配置kmodel生成参数">6.3.2.3.1 配置kmodel生成参数<a href="#63231-配置kmodel生成参数" class="hash-link" aria-label="Direct link to 6.3.2.3.1 配置kmodel生成参数" title="Direct link to 6.3.2.3.1 配置kmodel生成参数">​</a></h5>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="1编译参数compileoptions-1">1.编译参数：CompileOptions<a href="#1编译参数compileoptions-1" class="hash-link" aria-label="Direct link to 1.编译参数：CompileOptions" title="Direct link to 1.编译参数：CompileOptions">​</a></h6>
<p>具体为什么这样设置，请参照6.3.1.3.1中的编译参数设置方法。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 1. 设置编译参数，compile_options</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options = nncase.CompileOptions()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 指定编译目标, 如&#x27;cpu&#x27;, &#x27;k230&#x27;,cpu生成cpu上推理的kmodel,k230生成在k230(kpu)上推理的kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.target = args.target</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 预处理</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.preprocess = True</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># （1）预处理---Transpose相关参数</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 当 preprocess为 True时，必须指定</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_shape = [1, 3, 112, 112]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.input_shape = input_shape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 输入数据的layout，默认为&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># compile_options.input_layout = &quot;NCHW&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.input_layout = &quot;0,1,2,3&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># （2）预处理---SwapRB相关参数</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.swapRB = False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># （3）预处理---Dequantize（反量化）相关参数</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 开启预处理时指定输入数据类型，默认为&quot;float&quot;；当 preprocess为 True时，必须指定为&quot;uint8&quot;或者&quot;float32&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.input_type = &#x27;uint8&#x27;            </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># input_type=‘uint8’时反量化有效，反量化之后的数据范围</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.input_range = [0, 255]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># （4）预处理---Normalization相关参数</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.mean = [ 127.5,127.5,127.5]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.std = [128.0, 128.0, 128.0]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 后处理</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># compile_options.output_layout = &quot;NCHW&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#Compiler类, 根据编译参数配置Compiler，用于编译神经网络模型</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compiler = nncase.Compiler(compile_options)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="2导入参数importoptions-1">2.导入参数：ImportOptions<a href="#2导入参数importoptions-1" class="hash-link" aria-label="Direct link to 2.导入参数：ImportOptions" title="Direct link to 2.导入参数：ImportOptions">​</a></h6>
<p>ImportOptions类, 用于配置nncase导入选项，很少单独设置，使用默认参数即可。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 2. 设置导入参数，import_options（一般默认即可）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import_options = nncase.ImportOptions()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_file = onnx_simplify(args.model, dump_dir)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_content = read_model_file(model_file)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compiler.import_onnx(model_content, import_options)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="3训练后量化参数ptqtensoroptions-1">3.训练后量化参数：PTQTensorOptions<a href="#3训练后量化参数ptqtensoroptions-1" class="hash-link" aria-label="Direct link to 3.训练后量化参数：PTQTensorOptions" title="Direct link to 3.训练后量化参数：PTQTensorOptions">​</a></h6>
<p>训练后量化参数(Post Training Quantization，PTQ)，PTQ是一种通过将模型权重从float32映射uint8或int16方法，保持模型的准确性的同时，减少推理所需的计算资源；当target = “k230”，PTQ是必选参数，默认uint8量化。</p>
<p>使用uint8量化可以满足人脸识别精度要求，故使用默认uint8量化；校正集个数为100；假设使用100个校正集生成kmodel的时间很久，可以适当的减少校正集。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 3. 设置量化参数，ptq_options</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options = nncase.PTQTensorOptions()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.samples_count = 100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.set_tensor_data(generate_data(input_shape, ptq_options.samples_count, args.dataset))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compiler.use_ptq(ptq_options)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63232-校正集准备">6.3.2.3.2 校正集准备<a href="#63232-校正集准备" class="hash-link" aria-label="Direct link to 6.3.2.3.2 校正集准备" title="Direct link to 6.3.2.3.2 校正集准备">​</a></h5>
<p>使用少量校正集计算量化因子，可以快速得到量化模型。使用该量化模型进行预测，可以减少计算量、降低计算内存、减小模型大小。</p>
<p><strong>校正集</strong>一般选用<strong>验证集</strong>的<strong>100张图片</strong>即可。该<a href="https://github.com/Xiaoccer/MobileFaceNet_Pytorch" target="_blank" rel="noopener noreferrer">人脸识别模型</a>的验证集为<code>LFW</code>，故选用<code>LFW</code>的100张图像作为校正集。</p>
<p><strong>注：</strong></p>
<p>（1）若是kmodel<strong>生成时间很久</strong>或者验证集数据很少，也可尝试少于100个数据</p>
<p>（2）<code>generate_data</code>函数，生成的数据格式，需要<strong>大致保证</strong>与实际推理时喂给kmodel的数据格式一致，否则会导致生成kmodel有问题。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">def generate_data(shape, batch, calib_dir):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 生成的数据和实际kmodel输入数据保持 一致，因为生成kmodel时，只会做参数中设置的预处理</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 生成的校正集数据需要做的预处理 ≈ onnx预处理 - 根据预处理参数设置的，包含在kmodel中预处理</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # onnx预处理：bgr-&gt;rgb,transpose,normalization,dequantize,3维度转4维度</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # kmodel中包含的预处理：dequantize,normalization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    img_paths = [os.path.join(calib_dir, p) for p in os.listdir(calib_dir)]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for i in range(batch):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        assert i &lt; len(img_paths), &quot;calibration images not enough.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # 读取图像，并转为RGB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        img_data = Image.open(img_paths[i]).convert(&#x27;RGB&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # transpose </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        img_data = np.transpose(img_data, (2, 0, 1))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        data.append([img_data[np.newaxis, ...]])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return np.array(data)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_shape = [1, 3, 112, 112]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">......</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options = nncase.PTQTensorOptions()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ptq_options.samples_count = 100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 校正集数据预处理，将原图处理为kmodel需要数据</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ptq_options.set_tensor_data(generate_data(input_shape, ptq_options.samples_count, args.dataset))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 使用samples_count个校准数据计算量化因子</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    compiler.use_ptq(ptq_options)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">......</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63233-生成kmodel">6.3.2.3.3 生成kmodel<a href="#63233-生成kmodel" class="hash-link" aria-label="Direct link to 6.3.2.3.3 生成kmodel" title="Direct link to 6.3.2.3.3 生成kmodel">​</a></h5>
<p><strong>生成环境</strong>：6.2.2 构建的编译环境</p>
<p><strong>生成步骤</strong>：</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd k230_sdk/src/reference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#若已下载code过，请忽略clone步骤</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd K230_AI_Demo_Development_Process_Analysis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd kmodel_related/kmodel_export</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#python mobile_face.py --target k230 --model onnx/MobileFaceNet.onnx --dataset lfw</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./build_model.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r--r--+ 1 root root 1319744 Feb 29 14:56 face_recognize.kmodel</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="6324-使用k230runtime进行推理">6.3.2.4 使用K230Runtime进行推理<a href="#6324-使用k230runtime进行推理" class="hash-link" aria-label="Direct link to 6.3.2.4 使用K230Runtime进行推理" title="Direct link to 6.3.2.4 使用K230Runtime进行推理">​</a></h4>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63241-simulator验证kmodel">6.3.2.4.1 Simulator验证kmodel<a href="#63241-simulator验证kmodel" class="hash-link" aria-label="Direct link to 6.3.2.4.1 Simulator验证kmodel" title="Direct link to 6.3.2.4.1 Simulator验证kmodel">​</a></h5>
<p>生成人脸识别kmodel之后，为了验证kmodel的准确性，需要在使用Simulator对比kmodel的输出和onnx的输出是否一致，这时就需要调用<strong>模拟器APIs(Python)</strong>。</p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="1生成inputbin-1">1.生成input.bin<a href="#1生成inputbin-1" class="hash-link" aria-label="Direct link to 1.生成input.bin" title="Direct link to 1.生成input.bin">​</a></h6>
<p>使用simulator验证kmodel之前，需要先准备好输入文件。由于kmodel包括部分预处理，因此对于同一张图片，需要分别利用不同预处理生成不同的onnx_input.bin、kmodel_input.bin。</p>
<table><thead><tr><th>名称</th><th>onnx_input.bin构建流程</th><th>kmodel_input.bin构建流程</th></tr></thead><tbody><tr><td><strong>源-&gt;目标</strong></td><td><strong>（uint8,hwc,bgr-&gt;float32,nchw,bgr）</strong></td><td><strong>（uint8,hwc,bgr-&gt;uint8,nchw,rgb）</strong></td></tr><tr><td>原图</td><td>(112,112,3) ,uint8, hwc,bgr</td><td>(112,112,3) ,uint8,hwc,bgr</td></tr><tr><td>bgr-&gt;rgb</td><td>（112,112,3），uint8，hwc，rgb</td><td>（112,112,3），uint8，hwc，rgb</td></tr><tr><td>dequantize</td><td>（112,112,3），float32，hwc，rgb</td><td>—</td></tr><tr><td>normalization</td><td>（112,112,3），float32，hwc，rgb</td><td>—</td></tr><tr><td>transpose</td><td>（3,112,112），float32，chw，rgb</td><td>（3,112,112），uint8，chw，rgb</td></tr><tr><td>维度扩展（非必须）</td><td>（1,3,112,112），uint8，chw，rgb</td><td>（1,3,112,112），uint8，chw，rgb</td></tr></tbody></table>
<p><strong>注</strong>：生成的kmodel中包含部分预处理，生成kmodel_input.bin需要的预处理 ≈ 生成onnx_input.bin需要的预处理 - kmodel中包含的预处理（人脸识别kmodel中预处理transpose、dequantize、normalization）</p>
<p>（1）维度扩展可以省略（读取时bin文件可以用reshape，生成bin时可以省略）</p>
<p>（2）transpose也放到kmodel中，为什么生成kmodel_input.bin仍需transpose？由于生成kmodel，若是打开了预处理开关，transpose的相关参数必须设置，我们人脸识别kmodel的实际输入是<code>NCHW</code>，input_layout设置为<code>NCHW</code>，两者是一致的，因此transpose是NCHW2NCHW，实际上并没有转换。</p>
<p><img decoding="async" loading="lazy" alt="image-20240226174214155" src="/assets/images/image-20240226174214155-28b923a8f0141ab52e9e2dbfb0fbcdc9.png" width="1637" height="920" class="img_ev3q"></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r--r-- 1 root root 147K Feb 26 16:37 face_recg_0_112x112_float32.bin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r--r-- 1 root root  37K Feb 26 16:37 face_recg_0_112x112_uint8.bin</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="2simulator验证-1">2.Simulator验证<a href="#2simulator验证-1" class="hash-link" aria-label="Direct link to 2.Simulator验证" title="Direct link to 2.Simulator验证">​</a></h6>
<p>模拟器APIs的接口如下图所示。若是在github无法看到<a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/ai/K230_nncase_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md" target="_blank" rel="noopener noreferrer">K230_nncase_开发指南.md</a>文档中目录结构，可以下载到本地，使用Typora工具打开。</p>
<p><img decoding="async" loading="lazy" alt="image-20240221140036235" src="/assets/images/image-20240221140036235-1721612171285-107-b0b2651bf7161275f33256cb4a84bf24.png" width="255" height="431" class="img_ev3q"></p>
<p><strong>Simulator流程</strong>：（与人脸检测流程基本一致，只需修改input_shape、input_bin_file即可）</p>
<ul>
<li>对于同一张图片，分别利用不同预处理生成不同的onnx_input.bin、kmodel_input.bin；</li>
<li>将onnx_input.bin喂给onnx，经过onnx推理得cpu_results；</li>
<li>将kmodel_input.bin喂给kmodel，经过Simulator推理得到nncase_results；</li>
<li>计算cpu_results和nncase_results的余弦相似度，通过相似度的大小判断kmodel的模拟推理和onnx的推理结果是否一致。</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import copy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import argparse</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import onnx</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import onnxruntime as ort</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import nncase</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def read_model_file(model_file):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    with open(model_file, &#x27;rb&#x27;) as f:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        model_content = f.read()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return model_content</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def cosine(gt, pred):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return (gt @ pred) / (np.linalg.norm(gt, 2) * np.linalg.norm(pred, 2))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def main():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parser = argparse.ArgumentParser(prog=&quot;nncase&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parser.add_argument(&quot;--target&quot;, type=str, help=&#x27;target to run&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parser.add_argument(&quot;--model&quot;, type=str, help=&#x27;original model file&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parser.add_argument(&quot;--model_input&quot;, type=str, help=&#x27;input bin file for original model&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parser.add_argument(&quot;--kmodel&quot;, type=str, help=&#x27;kmodel file&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    parser.add_argument(&quot;--kmodel_input&quot;, type=str, help=&#x27;input bin file for kmodel&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    args = parser.parse_args()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 1. onnx推理，得到cpu_results</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ort_session = ort.InferenceSession(args.model)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    output_names = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_outputs = ort_session.get_outputs()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for i in range(len(model_outputs)):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        output_names.append(model_outputs[i].name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_input = ort_session.get_inputs()[0]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_input_name = model_input.name</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_input_type = np.float32</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_input_shape = model_input.shape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(&#x27;onnx_input：&#x27;,model_input_shape)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_input_data = np.fromfile(args.model_input, model_input_type).reshape(model_input_shape)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cpu_results = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cpu_results = ort_session.run(output_names, { model_input_name : model_input_data })</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 2. Simulator推理，得到nncase_results</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # create Simulator</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sim = nncase.Simulator()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # read kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    kmodel = read_model_file(args.kmodel)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # load kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sim.load_model(kmodel)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # read input.bin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_shape = [1, 3, 112, 112]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    dtype = sim.get_input_desc(0).dtype</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input = np.fromfile(args.kmodel_input, dtype).reshape(input_shape)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # set input for Simulator</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sim.set_input_tensor(0, nncase.RuntimeTensor.from_numpy(input))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Simulator inference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    nncase_results = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sim.run()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for i in range(sim.outputs_size):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        nncase_result = sim.get_output_tensor(i).to_numpy()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # print(&quot;nncase_result:&quot;,nncase_result)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        input_bin_file = &#x27;bin/face_recg_{}_{}_simu.bin&#x27;.format(i,args.target)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        nncase_result.tofile(input_bin_file)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        nncase_results.append(copy.deepcopy(nncase_result))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 3. 计算onnx和Simulator相似度</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for i in range(sim.outputs_size):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cos = cosine(np.reshape(nncase_results[i], (-1)), np.reshape(cpu_results[i], (-1)))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print(&#x27;output {0} cosine similarity : {1}&#x27;.format(i, cos))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &#x27;__main__&#x27;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    main()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>上边的脚本可以满足大部分onnx及其kmodel的对比验证，一般不用太多修改。只需根据模型实际输入大小修改<code>input_shape</code>即可。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">python mobile_face_onnx_simu.py --target k230 --model onnx/MobileFaceNet.onnx --model_input bin/face_recg_0_112x112_float32.bin --kmodel onnx/k230_mobile_face.kmodel --kmodel_input bin/face_recg_0_112x112_uint8.bin</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#若已下载code过，请忽略clone步骤</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd K230_AI_Demo_Development_Process_Analysis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd kmodel_related/kmodel_export</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#上述命令行已经放到build_model.sh </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./build_model.sh            </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>一般onnx和Simulator余弦相似度越高越好，一般0.99以上即可满足条件；若是达不到0.99，但是在0.96以上，可以通过进一步<strong>上板推理验证</strong>生成的kmodel是否满足实际效果需求。</p>
<p><img decoding="async" loading="lazy" alt="image-20240226175528723" src="/assets/images/image-20240226175528723-ef71af28b1ac6ebf37fe67cc8587782c.png" width="1457" height="125" class="img_ev3q"></p>
<p>**注：**在执行Simulator时，必须先添加以下环境变量（build_model.sh文件其中含有）</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">export NNCASE_PLUGIN_PATH=$NNCASE_PLUGIN_PATH:/usr/local/lib/python3.8/dist-packages/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export PATH=$PATH:/usr/local/lib/python3.8/dist-packages/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source /etc/profile</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63242-使用main_nncase验证kmodel">6.3.2.4.2 使用main_nncase验证kmodel<a href="#63242-使用main_nncase验证kmodel" class="hash-link" aria-label="Direct link to 6.3.2.4.2 使用main_nncase验证kmodel" title="Direct link to 6.3.2.4.2 使用main_nncase验证kmodel">​</a></h5>
<p>Simulator推理kmodel和上板推理kmodel一般来说是一致的，但是不排除个别情况下Simulator与实际上板仍有一定差异，为了验证两者是否一致，需要使用main_nncase工具辅助验证Simulator推理kmodel与上板实际推理kmodel结果是否一致；使用这个工具需要调用nncase的<strong>KPU运行时APIs(C++)</strong>。</p>
<p>KPU运行时APIs提供kmodel上板推理的各种接口 ，接口如下图所示。若是在github无法看到<a href="https://github.com/kendryte/k230_docs/blob/main/zh/01_software/board/ai/K230_nncase_%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md" target="_blank" rel="noopener noreferrer">K230_nncase_开发指南.md</a>文档中目录结构，可以下载到本地，使用Typora工具打开。</p>
<p><img decoding="async" loading="lazy" alt="image-20240221141307953" src="/assets/images/image-20240221141307953-1721612179148-112-25e55837f9bff0dfa5a023c8d1c91f9d.png" width="310" height="356" class="img_ev3q"></p>
<p><strong>main_nncase验证流程：</strong></p>
<ul>
<li>加载kmodel</li>
<li>设置kmodel输入：读取kmodel_input.bin文件</li>
<li>设置kmodel输出</li>
<li>推理kmodel</li>
<li>获取kmodel输出</li>
<li>对比Simulator推理kmodel、上板推理kmodel结果相似性</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">//main_nncase</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;chrono&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;fstream&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;iostream&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;nncase/runtime/runtime_tensor.h&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;nncase/runtime/interpreter.h&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#include &lt;nncase/runtime/runtime_op_utility.h&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">using namespace nncase;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">using namespace nncase::runtime;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">using namespace nncase::runtime::detail;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#define USE_CACHE 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">template &lt;class T&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">std::vector&lt;T&gt; read_binary_file(const char *file_name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::ifstream ifs(file_name, std::ios::binary);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.seekg(0, ifs.end);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    size_t len = ifs.tellg();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::vector&lt;T&gt; vec(len / sizeof(T), 0);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.seekg(0, ifs.beg);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.read(reinterpret_cast&lt;char *&gt;(vec.data()), len);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.close();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return vec;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void read_binary_file(const char *file_name, char *buffer)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::ifstream ifs(file_name, std::ios::binary);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.seekg(0, ifs.end);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    size_t len = ifs.tellg();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.seekg(0, ifs.beg);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.read(buffer, len);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ifs.close();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">template &lt;typename T&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">double dot(const T *v1, const T *v2, size_t size)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    double ret = 0.f;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (size_t i = 0; i &lt; size; i++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ret += v1[i] * v2[i];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return ret;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">template &lt;typename T&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">double cosine(const T *v1, const T *v2, size_t size)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return dot(v1, v2, size) / ((sqrt(dot(v1, v1, size)) * sqrt(dot(v2, v2, size))));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void dump(const std::string &amp;info, volatile float *p, size_t size)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::cout &lt;&lt; info &lt;&lt; &quot; dump: p = &quot; &lt;&lt; std::hex &lt;&lt; (void *)p &lt;&lt; std::dec &lt;&lt; &quot;, size = &quot; &lt;&lt; size &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    volatile unsigned int *q = reinterpret_cast&lt;volatile unsigned int *&gt;(p);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (size_t i = 0; i &lt; size; i++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if ((i != 0) &amp;&amp; (i % 4 == 0))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::cout &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::cout &lt;&lt; std::hex &lt;&lt; q[i] &lt;&lt; &quot; &quot;;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::cout &lt;&lt; std::dec &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">int main(int argc, char *argv[])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::cout &lt;&lt; &quot;case &quot; &lt;&lt; argv[0] &lt;&lt; &quot; build &quot; &lt;&lt; __DATE__ &lt;&lt; &quot; &quot; &lt;&lt; __TIME__ &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if (argc &lt; 4)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::cerr &lt;&lt; &quot;Usage: &quot; &lt;&lt; argv[0] &lt;&lt; &quot; &lt;kmodel&gt; &lt;input_0.bin&gt; &lt;input_1.bin&gt; ... &lt;input_N.bin&gt; &lt;output_0.bin&gt; &lt;output_1.bin&gt; ... &lt;output_N.bin&gt;&quot; &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return -1;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    interpreter interp;                             </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 1. load model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::ifstream in_before_load_kmodel(&quot;/proc/media-mem&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::string line_before_load_kmodel;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 逐行读取文件内容，查看MMZ使用情况</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    while (std::getline(in_before_load_kmodel, line_before_load_kmodel)) { </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::cout &lt;&lt; line_before_load_kmodel &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::ifstream ifs(argv[1], std::ios::binary);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    interp.load_model(ifs).expect(&quot;Invalid kmodel&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::ifstream in_after_load_kmodel(&quot;/proc/media-mem&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::string line_after_load_kmodel;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 逐行读取文件内容，查看MMZ使用情况</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    while (std::getline(in_after_load_kmodel, line_after_load_kmodel)) {  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        std::cout &lt;&lt; line_after_load_kmodel &lt;&lt; std::endl;  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 2. set inputs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (size_t i = 2, j = 0; i &lt; 2 + interp.inputs_size(); i++, j++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto desc = interp.input_desc(j);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto shape = interp.input_shape(j);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto tensor = host_runtime_tensor::create(desc.datatype, shape, hrt::pool_shared).expect(&quot;cannot create input tensor&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto mapped_buf = std::move(hrt::map(tensor, map_access_::map_write).unwrap());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#if USE_CACHE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        read_binary_file(argv[i], reinterpret_cast&lt;char *&gt;(mapped_buf.buffer().data()));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto vec = read_binary_file&lt;unsigned char&gt;(argv[i]);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        memcpy(reinterpret_cast&lt;void *&gt;(mapped_buf.buffer().data()), reinterpret_cast&lt;void *&gt;(vec.data()), vec.size());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // dump(&quot;app dump input vector&quot;, (volatile float *)vec.data(), 32);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#endif</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto ret = mapped_buf.unmap();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ret = hrt::sync(tensor, sync_op_t::sync_write_back, true);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (!ret.is_ok())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::cerr &lt;&lt; &quot;hrt::sync failed&quot; &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::abort();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // dump(&quot;app dump input block&quot;, (volatile float *)block.virtual_address, 32);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        interp.input_tensor(j, tensor).expect(&quot;cannot set input tensor&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 3. set outputs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (size_t i = 0; i &lt; interp.outputs_size(); i++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto desc = interp.output_desc(i);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto shape = interp.output_shape(i);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto tensor = host_runtime_tensor::create(desc.datatype, shape, hrt::pool_shared).expect(&quot;cannot create output tensor&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        interp.output_tensor(i, tensor).expect(&quot;cannot set output tensor&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 4. run</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    auto start = std::chrono::steady_clock::now();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    interp.run().expect(&quot;error occurred in running model&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    auto stop = std::chrono::steady_clock::now();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    double duration = std::chrono::duration&lt;double, std::milli&gt;(stop - start).count();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::cout &lt;&lt; &quot;interp run: &quot; &lt;&lt; duration &lt;&lt; &quot; ms, fps = &quot; &lt;&lt; 1000 / duration &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 5. get outputs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (int i = 2 + interp.inputs_size(), j = 0; i &lt; argc; i++, j++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto out = interp.output_tensor(j).expect(&quot;cannot get output tensor&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto mapped_buf = std::move(hrt::map(out, map_access_::map_read).unwrap());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto expected = read_binary_file&lt;unsigned char&gt;(argv[i]);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 6. compare</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        int ret = memcmp((void *)mapped_buf.buffer().data(), (void *)expected.data(), expected.size());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (!ret)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::cout &lt;&lt; &quot;compare output &quot; &lt;&lt; j &lt;&lt; &quot; Pass!&quot; &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            auto cos = cosine((const float *)mapped_buf.buffer().data(), (const float *)expected.data(), expected.size()/sizeof(float));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            std::cerr &lt;&lt; &quot;compare output &quot; &lt;&lt; j &lt;&lt; &quot; Fail: cosine similarity = &quot; &lt;&lt; cos &lt;&lt; std::endl;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>编译上述c++代码，将生成的k230_bin目录拷贝到CanMV-K230开发板。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#docker容器中，若已下载code过，请忽略clone步骤</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker exec -it v1.3_0219_lj /bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd src/reference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis.git</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd K230_AI_Demo_Development_Process_Analysis/kmodel_related/kmodel_inference/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./build_app.sh debug</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 在小核上：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 大小核共用/sharefs/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /sharefs/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#示例：实际执行时，将源目录替换为自己的目录</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scp liujie@10.10.1.22:/xxx/k230_bin/debug /sharefs/ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 大核上</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /sharefs/k230_bin/debug</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># face_recognize_main_nncase.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./main_nncase.elf face_recognize.kmodel face_recg_0_112x112_uint8.bin face_recg_0_k230_simu.bin</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img decoding="async" loading="lazy" alt="image-20240226185940457" src="/assets/images/image-20240226185940457-76a43f26d9746cfe2aa2e0155b2662bd.png" width="1463" height="344" class="img_ev3q"></p>
<p>通过执行结果，可以发现：</p>
<ul>
<li>人脸识别kmodel<strong>内存</strong>：大概占用2M左右</li>
<li>人脸识别kmodel<strong>推理速度</strong>：1.21ms</li>
<li>人脸识别<strong>Simulator和上板推理相似度</strong>：输出完全一致（byte级别一致）</li>
</ul>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="63243-使用k230runtime进行推理">6.3.2.4.3 使用K230Runtime进行推理<a href="#63243-使用k230runtime进行推理" class="hash-link" aria-label="Direct link to 6.3.2.4.3 使用K230Runtime进行推理" title="Direct link to 6.3.2.4.3 使用K230Runtime进行推理">​</a></h5>
<p><strong>整体流程：</strong></p>
<p><img decoding="async" loading="lazy" alt="image-20240226185940459.png" src="/assets/images/image-20240226185940459-46a632740a827c596bed68ff1d6c2a6c.png" width="1002" height="918" class="img_ev3q"></p>
<p><strong>识别流程：</strong></p>
<p><img decoding="async" loading="lazy" alt="image-20240226185940458.png" src="/assets/images/image-20240226185940458-324a22e05a928f140b23216151637412.png" width="688" height="857" class="img_ev3q"></p>
<p><a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/tree/main/kmodel_related/kmodel_inference/face_recognition" target="_blank" rel="noopener noreferrer">face_recognition code</a></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">├── ai_base.cc                  #AI基类，封装KPU运行时API，简化kmodel相关操作</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── ai_base.h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── anchors_640.cc              #人脸检测640分辨率输入对应anchor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── CMakeLists.txt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── face_detection.cc           #人脸检测，预处理，kmodel推理、后处理</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── face_detection.h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── face_recognition.cc         #人脸识别，预处理，kmodel推理、数据库比对</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── face_recognition.h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── main.cc                     #人脸识别demo主流程</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── README.md</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── scoped_timing.hpp           #计时类</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── utils.cc                    #工具类，封装常用函数及AI2D 运行时APIs，简化预处理操作</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── utils.h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└── vi_vo.h                     #封装sensor、display操作</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>使用K230Runtime推理kmodel需要详细了解K230Runtime的说明文档，为了简化推理流程，对K230Runtime的接口进行封装，其中<code>ai_base.cc、scoped_timing.hpp、utils.cc、vi_vo.h</code>是封装好的方法，无需修改；<code>face_detection.cc</code>已经在人脸检测demo中实现，直接拷贝即可；<code>face_recognition.cc</code>只需将<code>face_detection.cc</code>拷贝一份，修改对应构造函数、预处理（pre_process）、后处理（post_process）即可。</p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="1读取图片或视频帧-1">1.读取图片或视频帧<a href="#1读取图片或视频帧-1" class="hash-link" aria-label="Direct link to 1.读取图片或视频帧" title="Direct link to 1.读取图片或视频帧">​</a></h6>
<p>（1）<strong>读取图片</strong></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cv::Mat ori_img = cv::imread(xxx);</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>（2）<strong>读取视频帧</strong></p>
<p><strong>读取视频帧示例</strong>：<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/tree/main/kmodel_related/kmodel_inference/test_demo/test_vi_vo" target="_blank" rel="noopener noreferrer">test_vi_vo demo</a></p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="2预处理-1">2.预处理<a href="#2预处理-1" class="hash-link" aria-label="Direct link to 2.预处理" title="Direct link to 2.预处理">​</a></h6>
<p><strong>背景知识</strong>：参数不变的情况下，<code>ai2d_builder_</code>可以反复调用；参数改变则需要创建新的<code>ai2d_builder_</code>。</p>
<p><strong>人脸识别图像预处理</strong>：由于输入的人脸五官点位置不同，计算得到仿射变换也不同；人脸对齐（affine）时需要用生成的仿射变换作为参数来设置AI2D，AI2D的参数每次都会改变，需要重新调用Utils::affine创建新的<code>ai2d_builder_</code>来进行预处理。</p>
<p><strong>人脸识别视频流预处理</strong>：同理，由于不同帧的人脸五官点位置不同，也需要重新调用Utils::affine创建新的<code>ai2d_builder_</code>来进行预处理。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">// ai2d for image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceRecognition::pre_process(cv::Mat ori_img, float *sparse_points)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ScopedTiming st(model_name_ + &quot; pre_process image&quot;, debug_mode_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    get_affine_matrix(sparse_points);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std::vector&lt;uint8_t&gt; chw_vec;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Utils::bgr2rgb_and_hwc2chw(ori_img, chw_vec);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Utils::affine({ori_img.channels(), ori_img.rows, ori_img.cols}, chw_vec, matrix_dst_, ai2d_out_tensor_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if (debug_mode_ &gt; 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto vaddr_out_buf = ai2d_out_tensor_.impl()-&gt;to_host().unwrap()-&gt;buffer().as_host().unwrap().map(map_access_::map_read).unwrap().buffer();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        unsigned char *output = reinterpret_cast&lt;unsigned char *&gt;(vaddr_out_buf.data());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Utils::dump_color_image(&quot;FaceRecognition_input_affine.png&quot;,{input_shapes_[0][3],input_shapes_[0][2]},output);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// ai2d for video</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceRecognition::pre_process(float *sparse_points)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ScopedTiming st(model_name_ + &quot; pre_process_video&quot;, debug_mode_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    get_affine_matrix(sparse_points);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    size_t isp_size = isp_shape_.channel * isp_shape_.height * isp_shape_.width;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    auto buf = ai2d_in_tensor_.impl()-&gt;to_host().unwrap()-&gt;buffer().as_host().unwrap().map(map_access_::map_write).unwrap().buffer();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    memcpy(reinterpret_cast&lt;char *&gt;(buf.data()), (void *)vaddr_, isp_size);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    hrt::sync(ai2d_in_tensor_, sync_op_t::sync_write_back, true).expect(&quot;sync write_back failed&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Utils::affine(matrix_dst_, ai2d_builder_, ai2d_in_tensor_, ai2d_out_tensor_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if (debug_mode_ &gt; 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto vaddr_out_buf = ai2d_out_tensor_.impl()-&gt;to_host().unwrap()-&gt;buffer().as_host().unwrap().map(map_access_::map_read).unwrap().buffer();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        unsigned char *output = reinterpret_cast&lt;unsigned char *&gt;(vaddr_out_buf.data());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Utils::dump_color_image(&quot;FaceRecognition_input_affine.png&quot;,{input_shapes_[0][3],input_shapes_[0][2]},output);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>sparse_point（人脸五官点）的获取方式：先进行人脸检测，人脸检测结果中包含sparse_point。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">//main.cc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">......</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//人脸检测、人脸识别示例创建时都共享同一块地址vaddr</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FaceDetection face_det(argv[1], atof(argv[2]),atof(argv[3]), {SENSOR_CHANNEL, SENSOR_HEIGHT, SENSOR_WIDTH}, reinterpret_cast&lt;uintptr_t&gt;(vaddr), reinterpret_cast&lt;uintptr_t&gt;(paddr), atoi(argv[8]));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FaceRecognition face_recg(argv[4],atoi(argv[5]),recg_thres, {SENSOR_CHANNEL, SENSOR_HEIGHT, SENSOR_WIDTH}, reinterpret_cast&lt;uintptr_t&gt;(vaddr), reinterpret_cast&lt;uintptr_t&gt;(paddr), atoi(argv[8]));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//每从sensor读取一帧图像，都会将数据拷贝到vaddr</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">while (!isp_stop)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ScopedTiming st(&quot;total time&quot;, 1);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 每从sensor读取一帧图像</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ScopedTiming st(&quot;read capture&quot;, atoi(argv[8]));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        memset(&amp;dump_info, 0, sizeof(k_video_frame_info));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ret = kd_mpi_vicap_dump_frame(vicap_dev, VICAP_CHN_ID_1, VICAP_DUMP_YUV, &amp;dump_info, 1000);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (ret)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            printf(&quot;sample_vicap...kd_mpi_vicap_dump_frame failed.\n&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            continue;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 将从sensor中读取数据拷贝到vaddr</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ScopedTiming st(&quot;isp copy&quot;, atoi(argv[8]));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto vbvaddr = kd_mpi_sys_mmap_cached(dump_info.v_frame.phys_addr[0], size);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        memcpy(vaddr, (void *)vbvaddr, SENSOR_HEIGHT * SENSOR_WIDTH * 3);  // 这里以后可以去掉，不用copy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        kd_mpi_sys_munmap(vbvaddr, size);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    det_results.clear();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // 将vaddr数据拷贝给人脸检测ai2d输入，预处理后，预处理结果会放到ai2d输出;ai2d输出，其实是指向人脸检测kmodel输入的</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    face_det.pre_process();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    face_det.inference();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    face_det.post_process({SENSOR_WIDTH, SENSOR_HEIGHT}, det_results);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    cv::Mat osd_frame(osd_height, osd_width, CV_8UC4, cv::Scalar(0, 0, 0, 0));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (int i = 0; i &lt; det_results.size(); ++i)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        //***for face recg***</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 将vaddr数据拷贝给人脸识别ai2d输入，预处理后，预处理结果会放到ai2d输出;ai2d输出，其实是指向人脸识别kmodel输入的</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        face_recg.pre_process(det_results[i].sparse_kps.points);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        face_recg.inference();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        FaceRecognitionInfo recg_result;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        face_recg.database_search(recg_result); </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        face_recg.draw_result(osd_frame,det_results[i].bbox,recg_result,false);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ScopedTiming st(&quot;osd copy&quot;, atoi(argv[8]));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        memcpy(pic_vaddr, osd_frame.data, osd_width * osd_height * 4);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        // 显示通道插入帧</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        kd_mpi_vo_chn_insert_frame(osd_id + 3, &amp;vf_info); // K_VO_OSD0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ret = kd_mpi_vicap_dump_release(vicap_dev, VICAP_CHN_ID_1, &amp;dump_info);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (ret)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            printf(&quot;sample_vicap...kd_mpi_vicap_dump_release failed.\n&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">......</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="3kmodel-run-1">3.kmodel run<a href="#3kmodel-run-1" class="hash-link" aria-label="Direct link to 3.kmodel run" title="Direct link to 3.kmodel run">​</a></h6>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">//ai_base.cc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void AIBase::run()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ScopedTiming st(model_name_ + &quot; run&quot;, debug_mode_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    kmodel_interp_.run().expect(&quot;error occurred in running model&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void AIBase::get_output()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ScopedTiming st(model_name_ + &quot; get_output&quot;, debug_mode_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    p_outputs_.clear();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (int i = 0; i &lt; kmodel_interp_.outputs_size(); i++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto out = kmodel_interp_.output_tensor(i).expect(&quot;cannot get output tensor&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        auto buf = out.impl()-&gt;to_host().unwrap()-&gt;buffer().as_host().unwrap().map(map_access_::map_read).unwrap().buffer();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float *p_out = reinterpret_cast&lt;float *&gt;(buf.data());</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        p_outputs_.push_back(p_out);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//face_recognition.cc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceRecognition::inference()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    this-&gt;run();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    this-&gt;get_output();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">//main.cc，验证kmodel推理是否正确：我们使用simulator和main_nncase已经验证过</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">......</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FaceRecognition face_recg;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">face_recg.inference();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">......</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="4后处理-1">4.后处理<a href="#4后处理-1" class="hash-link" aria-label="Direct link to 4.后处理" title="Direct link to 4.后处理">​</a></h6>
<p>拿到人脸识别kmodel推理结果embeding后，需要将当前embeding与数据库中embedding进行对比，若对比结果大于某一阈值，则识别成功，说明该人脸已注册；否则，识别失败。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">//face_recognition.cc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceRecognition::l2_normalize(float *src, float *dst, int len)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float sum = 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (int i = 0; i &lt; len; ++i)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sum += src[i] * src[i];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sum = sqrtf(sum);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (int i = 0; i &lt; len; ++i)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        dst[i] = src[i] / sum;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">float FaceRecognition::cal_cosine_distance(float *feature_0, float *feature_1, int feature_len)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float cosine_distance = 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // calculate the sum square</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (int i = 0; i &lt; feature_len; ++i)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float p0 = *(feature_0 + i);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        float p1 = *(feature_1 + i);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cosine_distance += p0 * p1;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // cosine distance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return (0.5 + 0.5 * cosine_distance) * 100;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void FaceRecognition::database_search(FaceRecognitionInfo &amp;result)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int i;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int v_id = -1;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float v_score;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float v_score_max = 0.0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    float basef[feature_num_], testf[feature_num_];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // current frame</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    l2_normalize(p_outputs_[0], testf, feature_num_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for (i = 0; i &lt; valid_register_face_; i++)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        l2_normalize(feature_database_ + i * feature_num_, basef, feature_num_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        v_score = cal_cosine_distance(testf, basef, feature_num_);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if (v_score &gt; v_score_max)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            v_score_max = v_score;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            v_id = i;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if (v_id == -1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        result.id = v_id;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        result.name = &quot;unknown&quot;;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        result.score = 0;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        result.id = v_id;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        result.name = names_[v_id];</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        result.score = v_score_max;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="5显示结果-1">5.显示结果<a href="#5显示结果-1" class="hash-link" aria-label="Direct link to 5.显示结果" title="Direct link to 5.显示结果">​</a></h6>
<p><strong>显示结果示例</strong>：<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/tree/main/kmodel_related/kmodel_inference/test_demo/test_vi_vo" target="_blank" rel="noopener noreferrer">test_vi_vo demo</a></p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="6编译执行-1">6.编译、执行<a href="#6编译执行-1" class="hash-link" aria-label="Direct link to 6.编译、执行" title="Direct link to 6.编译、执行">​</a></h6>
<p>将代码clone到已启动docker容器<code>src/reference/</code>目录，执行<code>build_app.sh</code>，将<code>k230_bin</code>目录拷贝到k230开发板小核。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker exec -it v1.3_0219_lj /bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd src/reference</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis.git</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd K230_AI_Demo_Development_Process_Analysis/kmodel_related/kmodel_inference/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./build_app.sh debug         #若是无需debug目录，执行./build_app.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>将<code>k230_bin</code>目录拷贝到k230开发板/sharefs/。</p>
<ul>
<li>(1) 预处理是否正确</li>
</ul>
<p>将debug_mode设置为2，即可保存预处理之后的图像。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 大小核共用/sharefs/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 在小核上</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /sharefs/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#示例：实际执行时，将源目录替换为自己的目录</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scp liujie@10.10.1.22:/xxx/k230_bin /sharefs/ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#在大核上（先按q+Enter退去自启动程序）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /sharefs/k230_bin/face_recognize</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./face_recognition.elf face_detect_640.kmodel 0.6 0.2 face_recognize.kmodel 100 75 None 2 db</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#在小核上</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd  /sharefs/k230_bin/face_recognize</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scp FaceRecognition_input_affine.png username@ip:dir</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>将生成<code>FaceDetection_input_padding.png</code>，拷贝到pc查看，预处理代码是否正确。若是有问题，则需要看sensor原图有没有问题，设置的预处理参数是否正确。</p>
<p><img decoding="async" loading="lazy" alt="FaceRecognition_input_affine.png" src="/assets/images/FaceRecognition_input_affine-8118a5be0537f25c0c5bc8a1c4c0f473.png" width="112" height="112" class="img_ev3q"></p>
<ul>
<li>(2) 后处理是否正确</li>
</ul>
<p>人脸识别的后处理比较简单，比较当前人脸和数据库人脸的相似度即可，这里我们就不单独进行验证。</p>
<ul>
<li>(3) 执行</li>
</ul>
<p>在大核上执行<code>face_recognize_isp.sh</code>即可执行基于视频流的推理流程。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 大小核共用/sharefs/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#大核上</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /sharefs/k230_bin/face_recognize</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./face_recognize_isp.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#按‘i’键开始注册当前帧最大人脸，输入注册人脸名称：eg:aaa</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#下一帧开始就可以识别已注册人脸</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#按‘Esc’推理当前程序</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="64-常用调试技巧">6.4 常用调试技巧<a href="#64-常用调试技巧" class="hash-link" aria-label="Direct link to 6.4 常用调试技巧" title="Direct link to 6.4 常用调试技巧">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="641-技巧一target--cpu">6.4.1 技巧一：target = ‘cpu’<a href="#641-技巧一target--cpu" class="hash-link" aria-label="Direct link to 6.4.1 技巧一：target = ‘cpu’" title="Direct link to 6.4.1 技巧一：target = ‘cpu’">​</a></h3>
<p>当<code>target = &#x27;k230&#x27;</code>时，生成kmodel，验证发现kmodel推理结果不对，怎么办？</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">compile_options.target = &#x27;k230&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options = nncase.PTQTensorOptions()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.samples_count = 100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.set_tensor_data(generate_data(input_shape, ptq_options.samples_count, args.dataset))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compiler.use_ptq(ptq_options)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>修改target设置，<code>target = &#x27;cpu&#x27;</code>，重新生成cpu_xxx.kmodel，此时生成的kmodel没有量化；若cpu_xxx.kmodel推理正确，而k230_xxx.kmodel推理错误，说明kmodel的解析没有问题，跟量化有关，可以检查校正集数量（数量少?）、校正集内容（<code>generate_data</code>的格式是否和实际kmodel输入一致）、修改量化方法、量化类型来修正。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="642-技巧二int16量化">6.4.2 技巧二：int16量化<a href="#642-技巧二int16量化" class="hash-link" aria-label="Direct link to 6.4.2 技巧二：int16量化" title="Direct link to 6.4.2 技巧二：int16量化">​</a></h3>
<p>当<code>target = &#x27;k230&#x27;</code>时，生成kmodel，使用K230Runtime进行推理时，发现有效果，但精度还有待提高，怎么办？</p>
<p>有效果，但精度还有待提高时，说明校正集大概率是没有问题的，可以修改量化方法、量化类型来优化。</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># int16量化（量化参数配置）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import nncase</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options = nncase.PTQTensorOptions()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.samples_count = 100                #量化数量一般是100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.set_tensor_data(generate_data(input_shape, ptq_options.samples_count, args.dataset))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 四种option可以根据需要选用，暂不支持w_quant_type、quant_type【同时】int16量化</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># option 1：使用&#x27;Noclip&#x27;的int16量化，权重：float32-&gt;int16</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.calibrate_method = &#x27;NoClip&#x27;      #量化方法，及变换方法，比较典型的是最大最小值量化</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.w_quant_type = &#x27;int16&#x27;           #指定权重（Weights）量化类型，&#x27;int16&#x27;或&#x27;uint8&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># option 2：使用&#x27;Noclip&#x27;的int16量化，数据：float32-&gt;int16</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.calibrate_method = &#x27;NoClip&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.quant_type = &#x27;int16&#x27;               #指定数据（data）量化类型，&#x27;int16&#x27;或&#x27;uint8&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># option 3：使用&#x27;Kld&#x27;的int16量化，权重：float32-&gt;int16</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.w_quant_type = &#x27;int16&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># option 4：使用&#x27;Kld&#x27;的int16量化，数据：float32-&gt;int16</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ptq_options.quant_type = &#x27;int16&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">compiler.use_ptq(ptq_options)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>人脸检测option 1量化示例</strong>：<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/blob/main/kmodel_related/kmodel_export/face_detection/mobile_retinaface_data_100_640_uint16_option_1.py" target="_blank" rel="noopener noreferrer">mobile_retinaface_data_100_640_uint16_option_1.py</a></p>
<p><strong>人脸检测option 2量化示例</strong>：<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/blob/main/kmodel_related/kmodel_export/face_detection/mobile_retinaface_data_100_640_uint16_option_2.py" target="_blank" rel="noopener noreferrer">mobile_retinaface_data_100_640_uint16_option_2.py</a></p>
<p><strong>人脸检测option 3量化示例</strong>：<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/blob/main/kmodel_related/kmodel_export/face_detection/mobile_retinaface_data_100_640_uint16_option_3.py" target="_blank" rel="noopener noreferrer">mobile_retinaface_data_100_640_uint16_option_3.py</a></p>
<p><strong>人脸检测option 4量化示例</strong>：<a href="https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis/blob/main/kmodel_related/kmodel_export/face_detection/mobile_retinaface_data_100_640_uint16_option_4.py" target="_blank" rel="noopener noreferrer">mobile_retinaface_data_100_640_uint16_option_4.py</a></p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#生成环境：6.2.2中构建的编译环境</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/JayL323/K230_AI_Demo_Development_Process_Analysis.git</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd K230_AI_Demo_Development_Process_Analysis/kmodel_related/kmodel_export</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./build_model_int16.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r--r--  1 root root 1.2M Mar  1 11:48 face_detect_int16_opt1.kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r--r--  1 root root 960K Mar  1 11:50 face_detect_int16_opt2.kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r--r--  1 root root 1.7M Mar  1 11:52 face_detect_int16_opt3.kmodel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r--r--  1 root root 960K Mar  1 11:54 face_detect_int16_opt4.kmodel</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><code>./build_model_int16.sh</code>后，会在生成4个模型；生成kmodel的同时，使用Simulator进行验证，输出验证的相似度，根据相似度的高低选择模型。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="643-技巧三inputbin生成">6.4.3 技巧三：input.bin生成<a href="#643-技巧三inputbin生成" class="hash-link" aria-label="Direct link to 6.4.3 技巧三：input.bin生成" title="Direct link to 6.4.3 技巧三：input.bin生成">​</a></h3>
<p>当生成kmodel时，配置预处理参数为True，可以简单的认为：</p>
<p>kmodel ≈ 配置的kmodel预处理 + onnx；</p>
<p>对于同一张图片，kmodel输入需要的预处理 ≈ onnx输入需要的预处理 - 配置的kmodel预处理 ；即kmodel_input.bin ≈ onnx_input.bin - 配置的kmodel预处理。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/CanaanK230/part4/06-In-depthanalysisoftheAIdevelopmentprocess.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/CanaanK230/part4/Getstartedquicklyk230AIInferenceflow"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">5. 快速入门k230 AI推理流程</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/CanaanK230/part4/Introductiontodevelopmenttools"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">7. 开发工具简介</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#61-概述" class="table-of-contents__link toc-highlight">6.1 概述</a><ul><li><a href="#1常规ai开发流程" class="table-of-contents__link toc-highlight">1.常规AI开发流程</a></li><li><a href="#2基于k230的ai开发流程" class="table-of-contents__link toc-highlight">2.基于K230的AI开发流程</a></li></ul></li><li><a href="#62-环境搭建" class="table-of-contents__link toc-highlight">6.2 环境搭建</a><ul><li><a href="#621-快速上手" class="table-of-contents__link toc-highlight">6.2.1 快速上手</a></li><li><a href="#622-编译环境搭建" class="table-of-contents__link toc-highlight">6.2.2 编译环境搭建</a></li></ul></li><li><a href="#63-demo构建流程解析" class="table-of-contents__link toc-highlight">6.3 demo构建流程解析</a><ul><li><a href="#631-人脸检测demo" class="table-of-contents__link toc-highlight">6.3.1 人脸检测demo</a></li><li><a href="#632-人脸识别demo" class="table-of-contents__link toc-highlight">6.3.2 人脸识别demo</a></li></ul></li><li><a href="#64-常用调试技巧" class="table-of-contents__link toc-highlight">6.4 常用调试技巧</a><ul><li><a href="#641-技巧一target--cpu" class="table-of-contents__link toc-highlight">6.4.1 技巧一：target = ‘cpu’</a></li><li><a href="#642-技巧二int16量化" class="table-of-contents__link toc-highlight">6.4.2 技巧二：int16量化</a></li><li><a href="#643-技巧三inputbin生成" class="table-of-contents__link toc-highlight">6.4.3 技巧三：input.bin生成</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://dongshanpi.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">DongshanPI<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://canaan-docs.100ask.net/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Canaan-Docs<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://renesas-docs.100ask.net/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Renesas-Docs<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://rtos.100ask.net/" target="_blank" rel="noopener noreferrer" class="footer__link-item">RTOS<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://tina.100ask.net/" target="_blank" rel="noopener noreferrer" class="footer__link-item">TinaSDK-Docs<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://allwinner-docs.100ask.net/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Allwinner-Docs<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://aw-r128.100ask.net/" target="_blank" rel="noopener noreferrer" class="footer__link-item">R128-Docs<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://space.bilibili.com/275908810" target="_blank" rel="noopener noreferrer" class="footer__link-item">BiliBili<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://forums.100ask.net" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://video.100ask.net/" target="_blank" rel="noopener noreferrer" class="footer__link-item">VideoCenter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/dongshanpi" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://weidongshan.coding.net/public/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Coding<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/100askTeam" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://gitee.com/weidongshan" target="_blank" rel="noopener noreferrer" class="footer__link-item">Gitee<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>